---
title: "fi_vs_fp elsa"
output: html_document
date: "2023-06-10"
---

Glen Pridham, June 2023

Start with CART imputed

```{r}
outputDir = "/home/glen/analysis/fi_vs_fp"
gRootDir = "/home/glen/Documents/r" #where scripts are
#gFab5Name = "NPheno5"
#gFab5NameNoN = "Pheno5"
gFab5Name = "NFPFP5"
gFab5NameNoN = "FPFP5"

setwd(outputDir)
print(getwd())

source(sprintf("%s/nhanes.R",gRootDir),verbose=0)
source(sprintf("%s/goodness_of_fit.R",gRootDir),verbose=0)
source(sprintf("%s/pca.R",gRootDir),verbose=0)
source(sprintf("%s/pca_fi.R",gRootDir),verbose=0)
source(sprintf("%s/roc.R",gRootDir),verbose=0)
source(sprintf("%s/survival.R",gRootDir),verbose=0)
```
```{r}
gTextSize = 20
gAxisTextSize = 12
gPointSize = 4
gLineWidth = 1.5
#gColours = function(n,space="ag_GrnYl") return(colorspace::sequential_hcl(n,space))
gColours = function(n) 
{
    hues = seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 90)[1:n]
}
```

```{r}
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}
SummaryNfp = function(data,lev=NULL,model=NULL)
{
  #based on defaultSummary()
  #no assumptions on data
  
  #continuous metrics:
  prnum = as.numeric(as.character(data[,"pred"]))
  gtnum = as.numeric(as.character(data[,"obs"]))
  rmse = sqrt(mean((gtnum-prnum)^2,na.rm=T))
  mae = mean(abs(gtnum-prnum),na.rm=T)
  
  contMetrics = c(rmse,mae)
  names(contMetrics) =   c("RMSE","MAE")
  
  #discrete metrics:
  prin = round(as.numeric(as.character(data[,"pred"])))
  prin[prin < 0] = 0
  prin[prin > 5] = 5
  prin = ordered(prin,0:5)
  gtin = round(as.numeric(as.character(data[,"obs"])))
  gtin = ordered(gtin,0:5)
  
  #C = xtabs(~gtin+prin)
  #multiClassSummary uses sens/spec of pairs then averages together
  discMetrics = multiClassSummary(data=data.frame(obs=gtin,pred=prin),lev=lev,model=model)
  
  youden = discMetrics["Mean_Sensitivity"] + discMetrics["Mean_Specificity"] - 1
  names(youden) = "Mean_Youden"
  
  gtfact = factor(as.integer(gtnum >= 2.99),c(0,1))
  prfact = factor(as.integer(prnum >= 2.99),c(0,1))
  binMetrics = twoClassSummary(data=data.frame(obs=gtfact,pred=prfact),lev=c(0,1),model=NULL) #can't compute AUC since it'll spit out non-binary data so set model=NULL
  binMetrics =  c(binMetrics,binMetrics["Sens"]+binMetrics["Spec"]-1) #add Youden
  names(binMetrics)[length(binMetrics)] = "Youden"
  
  names(binMetrics) = sprintf("%s_fp",names(binMetrics))
  
  
  metrics = c(contMetrics,discMetrics,youden,binMetrics)
  
  return(metrics)
}
```

```{r}
elsa = readRDS(sprintf("%s/data/elsa_fi_vs_fp.rds",outputDir)) #this is from elsa_fi_vs_fp_preprocessing.ipyn
m = readRDS(sprintf("%s/data/elsa_fi_vs_fp_mice_cart.rds",outputDir))
codex = read.csv(sprintf("%s/elsa_fivar.csv",outputDir),row.names=1)
```



```{r}
# narrow down variables
adlVar = c("mob_walk100yards",
"mob_sit2hours",
"mob_situp",
"mob_climbflights",
"mob_climb1flight",
"mob_stoop",
"mob_armsup",
"mob_pushpull",
"mob_liftcarry",
"pick_up_coin",
"dress",
"adl_walkroom",
"adl_bathe",
"adl_eat",
"adl_bed",
"adl_toilet",
"iadl_map",
"iadl_makemeal",
"iadl_groceries",
"iadl_phone",
"iadl_meds",
"iadl_housework",
"iadl_money"
)

genVar = c('general','eye','hear')

lungVar = c('lung_disease',
           'asthma',
           'arthritis',
           'osteoporosis',
           'cancer',
           'parkinsons',
           'psychiatric_problem',
           'alzheimers',
           'dementia'
            )

heartVar = c('hyptertension',
           'angina',
           'heart_attack',
           'heart_failure',
           'heart_murmur',
           'abnormal_heart',
           'diabetes',
           'stroke'
            )

disVar = c(lungVar,heartVar)

fiVar = c(adlVar,genVar,disVar)

fpVar = c('fp1_weight','fp2_grip','fp3_gait','fp4_exhaustion','fp5_low_activity')
names(fpVar) = c("Weight loss","Weakness","Slow gait","Exhaustion","Low activity")
```


# Reshape into Markovian

Wave 4 vs wave 6

```{r}
data = list()
for (i in 1:m$m)
{
  long = mice::complete(m,i)
  wave4 = subset(long,wave=="wave4")
  rownames(wave4)=wave4[,"id"]
  wave6 = subset(long,wave=="wave6")
  rownames(wave6)=wave6[,"id"]
  
  
    #cuts
      #I figure that gait and grip have plenty of overlap and could both reasonably be MAR, so better to impute
    logiCut = apply(!m$where[long[,"wave"]=="wave4",c("fp1_weight","fp4_exhaustion", "fp5_low_activity")],1,all) & (!m$where[long[,"wave"]=="wave4","fp2_grip"] | !m$where[long[,"wave"]=="wave4","fp3_gait"]) #must have weight, exhaustion and low activity AND grip OR gait
    wave4 = wave4[logiCut,]
    logiCut = apply(!m$where[long[,"wave"]=="wave6",c("fp1_weight","fp4_exhaustion", "fp5_low_activity")],1,all) & (!m$where[long[,"wave"]=="wave6","fp2_grip"] | !m$where[long[,"wave"]=="wave6","fp3_gait"]) #must have weight, exhaustion and low activity AND grip OR gait
    wave6 = wave6[logiCut,]
    print(sprintf("Dropping %d due to missingness of grip or gait",sum(!logiCut)))
  
  
  pt = intersect(rownames(wave4),rownames(wave6))
  wave4 = wave4[pt,]
  wave6 = wave6[pt,]
  print(dim(wave4))
  
  #age cut #89 is max
  ageLogi = wave4[,"age"] < 90
  print(sprintf("Dropping %d individuals with top-coded age",sum(!ageLogi)))
  wave4 = wave4[ageLogi,]
  wave6 = wave6[ageLogi,]
  
  wave4[,"Nfp"] = apply(wave4[,fpVar],1,sum,na.rm=F)
  wave6[,"Nfp"] = apply(wave6[,fpVar],1,sum,na.rm=F)
  
  #keepVars = c("age",fpVar,"Nfp")#"fp_robust","fp_prefrail","fp_frail")
  keepVars = c("age",fpVar,fiVar,"Nfp") #update keep fiVar for hclust

  data[[i]] = wave4[,c("id","sex",keepVars)]
  data[[i]][,"fi"] = apply(wave4[,fiVar],1,mean,na.rm=T)
  data[[i]][,"fifp"] = apply(wave4[,c(fiVar,fpVar)],1,mean,na.rm=T)

  data[[i]][,sprintf("%s_next",keepVars)] = wave6[,keepVars]
  data[[i]][,"fi_next"] = apply(wave6[,fiVar],1,mean,na.rm=T)
  
  #Must have all 5 FP in wave 4 AND wave 6
  logi = apply(!is.na(data[[i]][,c(fpVar,sprintf("%s_next",fpVar))]),1,all)
  print(sprintf("dropping %d (%.0f%%) for complete case",sum(!logi),mean(!logi)*100))
  data[[i]] = data[[i]][logi,]
  
  #add ordinal variable
  fpclass = rep(NA,nrow(data[[i]]))
  fpclass[data[[i]][,"Nfp"] < 0.01] = "robust"
  fpclass[data[[i]][,"Nfp"] > 0.01 & data[[i]][,"Nfp"] < 2.99] = "prefrail"
  fpclass[data[[i]][,"Nfp"]>= 2.99] = "frail"
  fpclass = ordered(fpclass,c("robust","prefrail","frail"))
  data[[i]][,"fpclass"] = fpclass
  rm(fpclass)


  fpclass = rep(NA,nrow(data[[i]]))
  fpclass[data[[i]][,"Nfp_next"] < 0.01] = "robust"
  fpclass[data[[i]][,"Nfp_next"] > 0.01 & data[[i]][,"Nfp_next"] < 2.99] = "prefrail"
  fpclass[data[[i]][,"Nfp_next"]>= 2.99] = "frail"
  fpclass = ordered(fpclass,c("robust","prefrail","frail"))
  data[[i]][,"fpclass_next"] = fpclass
  rm(fpclass)
  
  data[[i]][,"fp_frail"] = as.integer(data[[i]][,"Nfp"] > 2.99)
  data[[i]][,"fp_frail_next"] = as.integer(data[[i]][,"Nfp_next"] > 2.99)
  data[[i]][,"newly_frail"] = as.integer(data[[i]][,"Nfp"] < 2.99 & data[[i]][,"Nfp_next"] > 2.99)
  
  data[[i]][,"Nfp_ord"] = ordered(data[[i]][,"Nfp"],0:5)
  data[[i]][,"Nfp_next_ord"] = ordered(data[[i]][,"Nfp_next"],0:5)

}
```

add survival
note: ToStartStop implicitly drops all ages prior to the first measurement (which is right!)
  doesn't seem wrong, but does greatly reduce number of events (I guess people were coming in at wave 2 or earlier)
  tons of people (~25% are just not in s - must be late additions; should check preprocessing)
looks horrible. why? problem between waves? maybe... not sure what's up
```{r}
#option 1 (default) #option doesn't seem to matter which one I use
s = read.csv(sprintf("%s/data/elsa_cleaned_aug3_survival.csv",outputDir),row.names=1)
#option 2
#s = readRDS(sprintf("%s/elsa_s.rds","/home/glen/analysis/markov/data")) #temp
#ids = rownames(readRDS(sprintf("%s/elsa_y_array.rds","/home/glen/analysis/markov/data")) )
#rownames(s) = ids
#warning("temp survival")
#option 3
#this one has more individuals but doesn't fix survival, something is wrong between waves 4 - waves 6
#s = read.csv(sprintf("%s/data/elsa_survival_data_mine.csv",outputDir),row.names=1)[,c("start","stop","status","topcoded")] #ugly top coding / prob shouldn't trust anything topcoded
#s = subset(s,!topcoded)
#ids = rownames(s)
#s = Surv(s[,"start"],s[,"stop"],s[,"status"])
#rownames(s) = ids

#elsa stores by waves so no duplicates
#depricated - not sure if it properly accounts for people dying
#for (i in 1:length(elsa))
#{
#  overlap = intersect(rownames(s),elsa[[i]][,"id"])
#  for (j in 1:ncol(s)) 
#  {
#    elsa[[i]][,colnames(s)[j]] = NA
#    elsa[[i]][overlap,colnames(s)[j]] = s[overlap,j]
#  }
#}

#data stores by imputation so many duplicates
#data stores by imputation so many duplicates
load=T
save=T
file = sprintf("%s/data/elsa_survival_startstop_mice.rds",outputDir)
if(load & file.exists(file))
{
  stst = readRDS(file)
} else
{
  stst = list() #start-stop version of data
  for (i in 1:m$m)
  {
    long = mice::complete(m,i)
    long = subset(long,wave%in%c("wave4","wave6")) #only using waves 4 and 6 above so do that here too
    for (j in 1:ncol(s)) long[,colnames(s)[j]] = NA
    for (ii in 1:nrow(s)) #go through each individual
    {
      logi = long[,"id"] == rownames(s)[ii]
      if(sum(logi) > 0)
      {
         for (j in 1:ncol(s)) long[logi,colnames(s)[j]] = s[ii,j]
      }
    }
  
    logi = long[,"age"] >= 90 #89 is max age
    logi[is.na(logi)] = F
    print(sprintf("dropping %d top-coded individuals",sum(logi)))
    long = long[!logi,]
  
    logi = apply(is.na(long[,colnames(s)]),1,any)
    print("NAs:")
    print(apply(is.na(long[,colnames(s)]),2,mean))
    print(sprintf("dropping %d datapoints from individuals without survival",sum(logi)))
    print(sprintf("(%d individuals / %d)",unlen(long[logi,"id"]),unlen(long[,"id"])))
    long = long[!logi,]
  
    long[,"fi"] = apply(long[,fiVar],1,mean,na.rm=T)
    long[,"fifp"] = apply(long[,c(fiVar,fpVar)],1,mean,na.rm=T)
    long[,"Nfp"] = apply(long[,fpVar],1,sum,na.rm=F)

  
  stst[[i]] = ToStartStop(long)
  }
  
  if(save) saveRDS(stst,file)
}

elsa_surv = s
s = Surv(s[,1],s[,2],s[,3])
rownames(s) = rownames(elsa_surv)
```
#why I don't trust elsa survival
```{r}
plotdata = list()
sf = survfit(s~1)
plotdata[[1]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="All Waves")
sf = survfit(stst[[1]][[2]]~1)
plotdata[[2]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="Waves 4-6")
plotdata =do.call(rbind,plotdata)

g = ggplot(plotdata,aes(x=Age,y=S,ymin=Smin,ymax=Smax,colour=group,fill=group,linetype=group))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    scale_y_continuous(limits=c(0,1))+
    labs(x="Age",y="Survival")+
    theme_minimal()
           
g

save=T
if(save)
{
  ggsave(sprintf("%s/results/s_elsa.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/s_elsa.png",outputDir),g,width=10,height=8,dpi=300)
}
```
Demographic stuff
post imputation, from functional deficit preprocessed data
```{r}
vars = c(Age="age",Females="sex",FI="fi",NFab5="Nfp",FP="fp_frail",fpVar)
prevalence = rep(T,length(vars)) #scale to % 
prevalence[vars %in% c("age","fi","Nfp")] = F
Ndigits = rep(0,length(vars))
Ndigits[vars %in% c("fi","Nfp")] = 2

#prevalence
pr = list()
prse = list()
prsd = list()
for (i in 1:length(data))
{
  pr[[i]] = matrix(NA,nrow=length(vars),ncol=1)
  rownames(pr[[i]]) = names(vars)
  colnames(pr[[i]]) = "Frequency"
  prse[[i]] = pr[[i]]
  prsd[[i]] = pr[[i]]
  for (j in 1:length(vars)) 
  {
    pr[[i]][j,1] = mean(data[[i]][,vars[j]],na.rm=T)
    if(prevalence[j]) #binary variables
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    else  #non-binary
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    
  }
}

pr = RubinMat(pr,prse)
prsd = RubinMat(prsd)

demo = matrix(NA,nrow=nrow(pr[[1]])+2,ncol=2)

colnames(demo) = c("","Frequency/Mean")
demo[1,1] = "Individuals"
demo[1,2] = unlen(data[[1]][,"id"])
demo[2,1] = "Entries"
demo[2,2] = nrow(data[[1]])
skip = 1:2
demo[-skip,1] = rownames(pr[[1]])
demo[-skip,2][prevalence] = sprintf("%.1f%%",100*pr[[1]][prevalence,1]) #,100*prsd[[1]][prevalence,1])  #errors from imputation are small relative to sd so just ignore
demo[-skip,2][!prevalence] = sprintf("%.0f (%.0f)",pr[[1]][!prevalence,1],prsd[[1]][!prevalence,1]) 

demo[-skip,2][Ndigits == 2] = sprintf("%.2f (%.2f)",pr[[1]][Ndigits == 2,1],prsd[[1]][Ndigits == 2,1]) 

save=T
if(save)
{
  write.csv(demo,sprintf("%s/data/demographics_elsa.csv",outputDir),row.names = F)
}
```

#FI vs FP

```{r}
medianBS = function(x,nboot=100)
{
  m = numeric(nboot)
  for (i in 1:nboot)
  {
    m[i] = median(sample(x,length(x),replace=T),na.rm=T)
  }
  return(list(est=mean(m),se=sd(m)))
}

ExpectationPr = function(pr,newdata=NULL) 
{
  #pr: data.frame from predict e.g. pr = predict(rf,newdata=data[[1]],type="prob")
  cl = as.numeric(colnames(pr))
  
  #most likely class
  maxPr = cl[apply(pr,1,which.max)]
  
  #expectation value of classes
  E = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl),1,sum,na.rm=T)
  #second moment
  E2 = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl)^2,1,sum,na.rm=T)  
  #sd
  s = sqrt(E2-E^2)

  if(!is.null(newdata))
  {
  df = matrix(NA,nrow=nrow(pr),ncol=3+ncol(newdata))
  colnames(df) = c(colnames(newdata),"class","Epr","sd")
  df[,1:ncol(newdata)] = as.matrix(newdata)
  df[,1+ncol(newdata)] = maxPr
  df[,2+ncol(newdata)] = E
  df[,3+ncol(newdata)] = s
  }
  else
  {
      df = matrix(NA,nrow=nrow(pr),ncol=3)
    colnames(df) = c("class","Epr","sd")
    df[,1] = maxPr
    df[,2] = E
    df[,3] = s
  }
  return(df)
}
```

# FI and NFP predicting FUTURE NFP
```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  Nfp_pred = data[[i]][,"Nfp_next"]
  un = 0:5 #sort(unique(Nfp_pred))
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    logi = Nfp_pred == un[j]
    if(sum(logi) < 2)
    {
      #problem: NA doesn't work...
      subdata[[j]] = data.frame(Nfp_next=un[j],fi_mean=NA,fi_median=NA,
                              Nfp_mean=NA,Nfp_median=NA)
      subdataSE[[j]] = data.frame(Nfp_next=0,fi_mean=0,fi_median=0,
                                Nfp_mean=0,Nfp_median=0)
      next
    }
    fi = data[[i]][logi,"fi"]
    Nfp = data[[i]][logi,"Nfp"]
    mbs = medianBS(fi,nboot=100)
    mNfp = medianBS(Nfp,nboot=100)
    subdata[[j]] = data.frame(Nfp_next=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]],
                              Nfp_mean=mean(Nfp,na.rm=T),Nfp_median=mNfp[[1]])
    subdataSE[[j]] = data.frame(Nfp_next=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]],
                                Nfp_mean=SEM(Nfp,na.rm=T),Nfp_median=mNfp[[2]])
    rm(logi)
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpNextData = RubinMat(l=fifpData,lse=fifpDataSE,na.rm=T) #na.rm = T not working...
save=T
if(save)
{
  saveRDS(fifpNextData,sprintf("%s/data/fifpData_fp_next_elsa.rds",outputDir))
}
```

```{r}
m1 = lm(Nfp_next~fi_mean,data.frame(fifpNextData[[1]]))
m2 = lm(Nfp_next~Nfp_mean,data.frame(fifpNextData[[1]]))
scale = predict(m1,data.frame(fi_mean=1))/predict(m2,data.frame(Nfp_mean=1))
plotdata = list()
plotdata[[1]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[1]][,"y"] = fifpNextData[[1]][,"fi_mean"]
plotdata[[1]][,"se"] = fifpNextData[[2]][,"fi_mean"]
plotdata[[1]][,"weights"] = 1/plotdata[[1]][,"se"]^2
plotdata[[1]][,"model"] = "FI"
plotdata[[2]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[2]][,"y"] = fifpNextData[[1]][,"Nfp_mean"]/scale
plotdata[[2]][,"se"] = fifpNextData[[2]][,"Nfp_mean"]/scale
plotdata[[2]][,"weights"] = 1/plotdata[[2]][,"se"]^2
plotdata[[2]][,"model"] = "NFab5"
plotdata = do.call(rbind,plotdata)
cols = gg_color_hue(2)
g = ggplot(plotdata,aes(x=Nfp_next,y=y,ymin=y-se,ymax=y+se,colour=model,fill=model,shape=model,linetype=model))+
  geom_pointrange()+
  scale_x_continuous(limits=c(0,5))+
  scale_y_continuous(limits=c(0,NA),
            sec.axis=sec_axis(~ . * scale, name = "Number of fab-5 deficits (NFab5)"))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1),
  #                   sec.axis=sec_axis(~ . * 5, name = "Number of phenotypic deficits (NFP)",breaks=c(.1,1,10)))+
  annotation_logticks(sides = "lr") +
  #geom_smooth(mapping=aes(weight=1/se^2),method="gam",formula=y~s(x,k=3),fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/se^2)) +
  labs(y="FI",x="Number of fab-5 deficits at followup")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.2,.8),
        axis.line.y = element_line(color = cols[1]), 
       axis.ticks.y = element_line(color = cols[1]),
        axis.line.y.right = element_line(color = cols[2]), 
       axis.ticks.y.right = element_line(color = cols[2]))

g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/fp_next_elsa.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_next_elsa.png",outputDir),g,width=10,height=8,dpi=300)
}
```

#hclust

```{r}
d = list()
for (i in 1:m$m)
{

  temp = data[[i]][,c(fpVar,fiVar)]
  for (j in 1:ncol(temp)) temp[,j] = as.integer(as.numeric(as.character(temp[,j])) > .49) #binarize and drop type

  #binary: #https://en.wikipedia.org/wiki/Jaccard_index
    #binary is >= 0 and <= 1
    #sum( (x[x | y] | y[x | y]) & !(x[x | y] & y[x | y]) )/sum(x | y)
    #considers only when at least x or y == 1
      #proportion of the time you have x or y but not x and y
      #This is same is |intersection|/|union|
  d[[i]] = dist(t(temp),"binary") #canberra is for counts, binary is for binary
  d[[i]] = as.matrix(d[[i]])
  
  #could put cluster membership stuff in here to get errorbar
    #both for bootstrap and imputation error
}

d = RubinMat(d)
#d = ListMeanSD(d)
#d = Reduce("+",d)/length(d)
```

```{r}
h = hclust(as.dist(d[[1]]),method="average") #average looks better than default (complete)
plot(h)
```

#ggdendro - for ggplot dendrograms
```{r}
library(ggplot2)
library(ggdendro)
```

```{r}
ggdendrogram(h, rotate = FALSE, size = 2)
```
what is the smallest cluster that contains all 5 FP?
```{r}
library(dendextend)
i = 1
for (i in 1:length(h$labels))
{
  k = length(h$labels)-i+1
  cl = cutree(h, k=k)
  #are all the FP vars in the same cluster?
  if(length(unique(cl[fpVar]))==1)
  {
    print(sprintf("cut at %d",k))
    print("cluster members:")
    clNum = cl[fpVar][1]
    print(cl[cl==clNum]) #who all is in your group
    print("non-cluster members:")
    print(cl[cl!=clNum])
    break
  }
}

plot(color_branches(h, k=k))#leaflab="none")
```
```{r}
#inds = sort.list(cl)
inds = h$labels[h$order]
TilePlot(1-d[[1]][inds,inds])
```

```{r}
ColourLabels = function(labs)
{
  types = codex[labs,"Type"]
  for (j in 1:length(fpVar)) types[labs==fpVar[j]] = "Pheno5"
  types = factor(types)
  cols = gg_color_hue(length(levels(types)))[as.numeric(types)]
  return(data.frame(label=types,colour=cols))
}
```

```{r}
inds = h$labels[h$order]
#ddf = segment(dendro_data(h,type="rectangle"))
ddf = segment(dendro_data(h)) #looks same to me
#ddf[,"colour"] = ordered(cl)
dsort = d[[1]][inds,inds]
nms = rownames(dsort)
nms = codex[rownames(dsort),"Terse"]
for (j in 1:length(fpVar)) nms[rownames(dsort)==fpVar[j]] = tolower(names(fpVar)[j])
rownames(dsort) = nms
colnames(dsort) = nms
diag(dsort) = NA
alpha = 1 #bigger makes it easier to see connections; smaller makes it harder; 1 = default
gamma = 8 #stretches out
g = TilePlot(1-dsort,na.value="grey89",zname="Similarity") +  geom_segment(data=ddf, aes(x=(y)^alpha*gamma+length(h$labels)+.5, y=x, xend=(yend)^alpha*gamma+length(h$labels)+.5, yend=xend),inherit.aes=F) + #theme(panel.background = element_rect(fill='white', colour="white"))
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(),
        legend.background=element_rect(fill="white",colour="grey60"),
        #axis.text.x=element_blank(),
        axis.text.x=element_text(angle=90,vjust=.5,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"]),
        axis.text.y=element_text(angle=0,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"])
        )

#fix legend
g = g + theme(legend.title=element_text())

#donor plot for labels
df = ColourLabels(rownames(d[[1]][inds,inds]))
df[,"x"] = 1
df[,"y"] = 1
gd = ggplot(df,aes(x=x,y=y,colour=label))+geom_point()+theme(legend.title=element_blank())

library(cowplot)
g = list(ggdraw(cowplot::get_legend(gd)),g)

#add box?
#g[[2]] = g[[2]]+annotate("rect",xmin=5.5,ymin=5.5,xmax=36.5,ymax=36.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=36.5,ymin=36.5,xmax=48.5,ymax=48.5,fill=NA,colour="grey50")

#g[[2]] = g[[2]]+annotate("rect",xmin=2.5,ymin=2.5,xmax=14.5,ymax=14.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=14.5,ymin=14.5,xmax=48.5,ymax=48.5,fill=NA,colour="grey50")

marrangeGrob(g,nrow=1,ncol=2,widths=c(.1,.9),top=NULL)

save=T
if(save)
{
  ggsave(sprintf("%s/results/elsa_clustering.pdf",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/elsa_clustering.png",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300)
}
```

```{r}
inds = h$labels[h$order]
#ddf = segment(dendro_data(h,type="rectangle"))
ddf = segment(dendro_data(h)) #looks same to me
#ddf[,"colour"] = ordered(cl)
TilePlot(1-d[[1]][inds,inds]) +  geom_segment(data=ddf, aes(x=y*8+length(h$labels)+.5, y=x, xend=yend*8+length(h$labels)+.5, yend=xend),inherit.aes=F) + #theme(panel.background = element_rect(fill='white', colour="white"))
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())
```

visualize in 2D
not sure what MDS is...
```{r}
fit = isoMDS(as.dist(d[[1]]), k=2) # k is the number of dim
fit # view results

# plot solution
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Nonmetric MDS", type="n")
text(x, y, labels = row.names(d[[1]]),col=1+row.names(d[[1]])%in%fpVar, cex=.7)
```


#correlation matrix
we know it's linear so use pearson
```{r}
BootCor = function(x,nboot=100,...)
{
  C = list()
  for (i in 1:nboot)
  {
    inds = sample(1:nrow(x),replace=T)
    C[[i]] = cor(x[inds,],...)
  }
  C = ListMeanSD(C)
  return(list(C=C[[1]],se=C[[2]]))
}
```

```{r}
C = list()
Cse = list()
vars = c("Nfp","fi","fifp","age")
#method = "pearson"
method = "spearman"
for (i in 1:length(data))
{
  C[[i]] = BootCor(data[[i]][,vars],use='pairwise.complete',method=method) 
  Cse[[i]] = C[[i]][[2]]
  C[[i]] = C[[i]][[1]]
}
C = RubinMat(C,Cse)

save=T
if(save)
{
  write.csv(C[[1]],sprintf("%s/results/%s_elsa.csv",outputDir,method),row.names=T)
  write.csv(C[[2]],sprintf("%s/results/%s_elsa_se.csv",outputDir,method),row.names=T)
}
```

# FI predicting NFP

```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  Nfp_pred = data[[i]][,"Nfp"]
  un = 0:5 #sort(unique(Nfp_pred))
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    logi = Nfp_pred == un[j]
    if(sum(logi) < 2)
    {
      #problem: NA doesn't work...
      subdata[[j]] = data.frame(Nfp=un[j],fi_mean=NA,fi_median=NA,
                              Nfp_mean=NA,Nfp_median=NA)
      subdataSE[[j]] = data.frame(Nfp=0,fi_mean=0,fi_median=0,
                                Nfp_mean=0,Nfp_median=0)
      next
    }
    fi = data[[i]][logi,"fi"]
    Nfp = data[[i]][logi,"Nfp"]
    mbs = medianBS(fi,nboot=100)
    mNfp = medianBS(Nfp,nboot=100)
    subdata[[j]] = data.frame(Nfp=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]],
                              Nfp_mean=mean(Nfp,na.rm=T),Nfp_median=mNfp[[1]])
    subdataSE[[j]] = data.frame(Nfp=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]],
                                Nfp_mean=SEM(Nfp,na.rm=T),Nfp_median=mNfp[[2]])
    rm(logi)
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpData = RubinMat(l=fifpData,lse=fifpDataSE,na.rm=T)
save=T
if(save)
{
  saveRDS(fifpData,sprintf("%s/data/fifpData_elsa.rds",outputDir))
}
```

```{r}
plotdata = data.frame(fifpData[[1]])
plotdata[,"fi_mean_se"] = fifpData[[2]][,"fi_mean"]
plotdata[,"fi_median_se"] = fifpData[[2]][,"fi_median"]
plotdata[,"weights"] = 1/plotdata[,"fi_mean_se"]^2
#ggplot(plotdata,aes(x=Nfp,y=fi_median,ymin=fi_median-fi_median_se,ymax=fi_median+fi_median_se))+
ggplot(plotdata,aes(x=Nfp,y=fi_mean,ymin=fi_mean-fi_mean_se,ymax=fi_mean+fi_mean_se))+
  geom_pointrange()+
  scale_x_continuous(limits=c(0,5))+
  #scale_y_continuous(limits=c(0,1.5))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1))+
  #annotation_logticks(sides = "l") +
  #geom_smooth(mapping=aes(weight=1/fi_mean_se^2),method="gam",formula=y~s(x,k=3),fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/fi_mean_se^2)) +
  labs(y="FI",x="Number of fab-5 deficits (NFab5)")+
  theme_minimal()
```

```{r}
mat = list()
for (i in 1:length(data))
{
  mat[[i]] = as.matrix(data[[i]][,c("fi","Nfp")])
}
mat = do.call(rbind,mat)

plotdata = data.frame(mat)
plotdata[,"Nfp"] = ordered(plotdata[,"Nfp"],0:5)
ggplot(plotdata,aes(x=Nfp,y=fi))+
  geom_boxplot()+
  geom_smooth(method="lm",formula=y~x,fullrange=T,data=as.data.frame(mat),mapping=aes(x=I(Nfp+1),y=fi),inherit.aes=F) +
  labs(y="FI",x="Number of fab-5 deficits (NFab5)")+
  theme_minimal()
```

```{r}
hist(data[[1]][,"age_next"]-data[[1]][,"age"])
print(meansd(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T))
```

### age / sex dependence
```{r}
LogLinEps = function(fi,
                     age,
                     a0=0.065,
                     newdata=data.frame(age=age)
                     )
{
  #fit linear model with skew thing
    #i.e. log(fi+a0) = age
  
  #step 1. find optimal a0 by minimizing residual skew
  obj = function(par)
  {
    mod  = lm(log(fi+par)~age)
    return(abs(skew(mod$residuals)))
  }
  
  op = optim(a0,obj,method="Brent",lower=0.001,upper=.2)
  
  a = op[["par"]]
  
  #step 2. fit model
  mod = lm(log(fi+a)~age)
  
  pr = predict(mod,newdata,se.fit=T)
  pr[[1]] = exp(pr[[1]])-a
  pr[[2]] = (exp(pr[[1]]))*pr[[2]]
  
  return(list(pr=pr,mod=mod,op=op,a=a))
}
```

```{r}
agg = list()
aggse = list()
age_cuts = seq(60,90,by=5)
fimodelM = list()
fimodelseM = list()
fimodelF = list()
fimodelseF = list()
fimodel2M = list()
fimodel2seM = list()
fimodel2F = list()
fimodel2seF = list()
testage = seq(60,90,by=1)
for (i in 1:length(data))
{
  agg[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),mean,na.rm=T)
  aggse[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),SEM,na.rm=T)
   #drop age_cut and clean up type
  agg[[i]]=agg[[i]][,-1]
  aggse[[i]]=aggse[[i]][,-1]
  for (j in 1:ncol(agg[[i]]))
  {
    agg[[i]][,j] = as.numeric(as.character(agg[[i]][,j]))
    aggse[[i]][,j] = as.numeric(as.character(aggse[[i]][,j]))
  }
   
  
  agg[[i]] = as.matrix(agg[[i]])
  aggse[[i]] = as.matrix(aggse[[i]])
  
  fimodelM[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelM[[i]]) = c("age","fi")
  fimodelseM[[i]] = fimodelM[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==0))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelM[[i]][,1] = testage
  fimodelM[[i]][,2] = exp(pr[[1]])
  fimodelseM[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  fimodelF[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelF[[i]]) = c("age","fi")
  fimodelseF[[i]] = fimodelF[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==1))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelF[[i]][,1] = testage
  fimodelF[[i]][,2] = exp(pr[[1]])
  fimodelseF[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  
  fimodel2M[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2M[[i]]) = c("age","fi")
  fimodel2seM[[i]] = fimodel2M[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==0)[,"fi"],age=subset(data[[i]],sex==0)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2M[[i]][,1] = testage
  fimodel2M[[i]][,2] = pr[[1]]
  fimodel2seM[[i]][,2] = pr[[2]]
  
  fimodel2F[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2F[[i]]) = c("age","fi")
  fimodel2seF[[i]] = fimodel2F[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==1)[,"fi"],age=subset(data[[i]],sex==1)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2F[[i]][,1] = testage
  fimodel2F[[i]][,2] = pr[[1]]
  fimodel2seF[[i]][,2] = pr[[2]]
}

ageData = RubinMat(agg,aggse)
ageData[[1]] = data.frame(ageData[[1]])
ageData[[1]][,sprintf("%sse",colnames(ageData[[1]]))] = ageData[[2]]
ageData = ageData[[1]]

fiDataM = RubinMat(fimodelM,fimodelseM)
fiDataM[[1]] = data.frame(fiDataM[[1]])
fiDataM[[1]][,sprintf("%sse",colnames(fiDataM[[1]]))] = fiDataM[[2]]
fiDataM = fiDataM[[1]]
fiDataM[,"sex"] = "Male"
fiDataF = RubinMat(fimodelF,fimodelseF)
fiDataF[[1]] = data.frame(fiDataF[[1]])
fiDataF[[1]][,sprintf("%sse",colnames(fiDataF[[1]]))] = fiDataF[[2]]
fiDataF = fiDataF[[1]]
fiDataF[,"sex"] = "Female"
fiData = rbind(fiDataM,fiDataF)

fiData2M = RubinMat(fimodel2M,fimodel2seM)
fiData2M[[1]] = data.frame(fiData2M[[1]])
fiData2M[[1]][,sprintf("%sse",colnames(fiData2M[[1]]))] = fiData2M[[2]]
fiData2M = fiData2M[[1]]
fiData2M[,"sex"] = "Male"
fiData2F = RubinMat(fimodel2F,fimodel2seF)
fiData2F[[1]] = data.frame(fiData2F[[1]])
fiData2F[[1]][,sprintf("%sse",colnames(fiData2F[[1]]))] = fiData2F[[2]]
fiData2F = fiData2F[[1]]
fiData2F[,"sex"] = "Female"
fiData2 = rbind(fiData2M,fiData2F)

sex = rep("Female",nrow(ageData))
sex[ageData[,"sex"]==0] = "Male"
ageData[,"sex"] = sex

ggplot(ageData,aes(x=age,xmin=age-agese,xmax=age+agese,y=fi,ymin=fi-fise,ymax=fi+fise,colour=sex,fill=sex))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  geom_line(data=fiData)+
  geom_ribbon(data=fiData,alpha=.15,colour=NA)+
  geom_line(data=fiData2)+ #log-linear with intercept #looks same
  geom_ribbon(data=fiData2,alpha=.15,colour=NA)

save=T
if(save)
{
  write.csv(ageData,sprintf("%s/results/age_dependence_elsa.csv",outputDir),row.names=T)
  write.csv(fiData,sprintf("%s/results/age_dependence_elsa_logfi.csv",outputDir),row.names=T)
  write.csv(fiData2,sprintf("%s/results/age_dependence_elsa_logepsfi.csv",outputDir),row.names=T)
}
```

################
# prevalence curves
################
```{r}
fpNames = sprintf("%s_next",c("fp_frail",fpVar))
names(fpNames) = c("FP",names(fpVar))
```


```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - spline
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    b = predict(bMat,data[[ii]][,"fi"])
    temp = data.frame(b)
    colnames(temp) = colnames(bMat)
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~.,data=temp,family=binomial)
    pr = predict(md,testMat,se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]

  plotdata = list(pr_agg,pr_agg_sq)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=names(outcomes)[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/%s_prevalence_elsa_logit_pragg.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/%s_prevalence_elsa_logit_pragg_sq.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(agg,sprintf("%s/data/%s_prevalence_elsa_logit_agg.csv",outputDir,names(outcomes)[i]),row.names=F)
  }
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)



save=T
if(save)
{
  ggsave(sprintf("%s/results/prevalence_elsa.pdf",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/prevalence_elsa.png",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)

}

#if survival is exponential (i.e. no time dependence) then we can get the per year rate using
  #S = 1 - pr; S_peryear = exp(log(S)/dt)
```


```{r}
library(splines2)
include="linear"
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
fi_labs = levels(cut(seq(-1,1,by=.01),fi_cuts))
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
nms = names(fpNames)
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  pr_agg[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_aggF = RubinMat(l,lse)
  pr_aggF[[1]] = data.frame(pr_aggF[[1]])
  pr_aggF[[1]][,sprintf("%sse",colnames(pr_aggF[[2]]))] = pr_aggF[[2]]
  pr_aggF = pr_aggF[[1]]
  pr_aggF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  pr_agg_sq[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sqF = RubinMat(l,lse)
  pr_agg_sqF[[1]] = data.frame(pr_agg_sqF[[1]])
  pr_agg_sqF[[1]][,sprintf("%sse",colnames(pr_agg_sqF[[2]]))] = pr_agg_sqF[[2]]
  pr_agg_sqF = pr_agg_sqF[[1]]
  pr_agg_sqF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    agg = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(agg[,"fi_cut"]),] = agg[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(agg)
    rm(aggse)
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]
  agg[,"sex"] = "Male"

  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    aggtemp = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(aggtemp[,"fi_cut"]),] = aggtemp[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(aggtemp)
    rm(aggse)
  }
  aggF = RubinMat(l,lse)
  for (j in 1:length(aggF)) colnames(aggF[[j]])[2] = "pr"
  aggF[[1]] = data.frame(aggF[[1]])
  aggF[[1]][,sprintf("%sse",colnames(aggF[[2]]))] = aggF[[2]]
  aggF = aggF[[1]]
  aggF[,"sex"] = "Female"
  
  plotdata = list(pr_agg,pr_aggF,pr_agg_sq,pr_agg_sqF)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]][,"model"] = "sqrt"
  plotdata[[4]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%include)
  plotdata[,"sex"] = factor(plotdata[,"sex"],c("Female","Male"))
  
  agg = rbind(agg,aggF)
  
  #frequencies
  if(length(include)>1) 
  {
    g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))
  }   else g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,fill=sex,colour=sex,linetype=sex,shape=sex))
  g[[i]] = g[[i]] + geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=sex,shape=sex),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,colour=sex,shape=sex),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=sprintf("(%s) %s",letters[i], nms[i]))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
  
}

#clean up legends
g[[1]] = g[[1]] + theme(legend.position=c(.25,.8),legend.title=element_blank())
for (i in 2:length(g)) g[[i]] = g[[i]] + theme(legend.position="none")

layout = matrix(1:6,nrow=2,ncol=3)
for (i in 1:nrow(layout)) layout[i,] = 1:ncol(layout)+(i-1)*ncol(layout)
marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout)




save=T
if(save)
{
  ggsave(sprintf("%s/results/prevalence_elsa_sex.pdf",outputDir),marrangeGrob(g,nrow=nrow(layout),ncol=ncol(layout),top=NULL,layout_matrix=layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/prevalence_elsa_sex.png",outputDir),marrangeGrob(g,nrow=nrow(layout),ncol=ncol(layout),top=NULL,layout_matrix=layout),width=16,height=8,dpi=300)
  

}
```

################
# prevalence w.r.t age
################

```{r}
library(splines2)
testage = seq(60,100,by=1)

age_cuts = c(seq(60,90,by=5))
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~age,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,age=testage),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(age=testage,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~sqrt(age),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,age=testage),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(age=testage,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  


  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"age_cut"] = cut(temp[,"age"],age_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("age",outcomes[i])],by=list(age_cut=temp[,"age_cut"]),mean,na.rm=T)[,c("age",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("age",outcomes[i])],by=list(age_cut=temp[,"age_cut"]),SEM,na.rm=T)[,c("age",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]

  plotdata = list(pr_agg,pr_agg_sq)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g[[i]] = ggplot(plotdata,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Prevalence"),title=names(outcomes)[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/%s_age_prevalence_elsa_logit_pragg.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/%s_age_prevalence_elsa_logit_pragg_sq.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(agg,sprintf("%s/data/%s_age_prevalence_elsa_logit_agg.csv",outputDir,names(outcomes)[i]),row.names=F)
  }
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)


save=T
if(save)
{
  ggsave(sprintf("%s/results/age_prevalence_elsa.pdf",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_prevalence_elsa.png",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  

}
```


################
# survival (hazard) curve
################

```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.1),1)
#fi_cuts = c(0,seq(0.01,.6,by=.1),1) #bad idea... very low FI have basically 0 risk


#coxph linear
l = list()
lse = list()
for(ii in 1:length(stst))
{
  md = coxph(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]])
  pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg = RubinMat(l,lse)
pr_agg[[1]] = data.frame(pr_agg[[1]])
pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
pr_agg = pr_agg[[1]]
rm(l)
rm(lse)
  
  
#glm - sqrt
l = list()
lse = list()
for(ii in 1:length(stst))
{
  md = coxph(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]])
  pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg_sq = RubinMat(l,lse)
pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
pr_agg_sq = pr_agg_sq[[1]]
rm(l)
rm(lse)


#glm - spline
l = list()
lse = list()
for(ii in 1:length(stst))
{
  b = predict(bMat,stst[[ii]][[1]][,"fi"])
  temp = data.frame(b)
  colnames(temp) = colnames(bMat)
  
  md = coxph(stst[[ii]][["s"]]~.,data=temp)
  pr = predict(md,testMat,se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg_sp = RubinMat(l,lse)
pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
pr_agg_sp = pr_agg_sp[[1]]
rm(l)
rm(lse)

#population stats
#still has to use coxph because of censorship
l = list()
lse = list()
for(ii in 1:length(stst))
{
  temp = stst[[ii]][[1]]
  temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
  
  md = coxph(stst[[ii]][["s"]]~fi_cut,data=temp)
  
  test = data.frame(y=NA,fi=testfi)
  test[,"fi_cut"] = cut(test[,"fi"],fi_cuts,include.lowest=T)
  test = aggregate(test[,c("y","fi")],by=list(fi_cut=test[,"fi_cut"]),mean,na.rm=T) #compress down into 1 / unique value
  test[,"fise"] = aggregate(test[,c("fi"),drop=F],by=list(fi_cut=test[,"fi_cut"]),SEM,na.rm=T)[,"fi"]
  pr = predict(md,test,se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=test[,"fi"],pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=test[,"fise"],pr=pr[["se.fit"]]))
  
  #l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
  #lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
}
agg = RubinMat(l,lse)
for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
agg[[1]] = data.frame(agg[[1]])
agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
agg = agg[[1]]

plotdata = list(pr_agg,pr_agg_sq,pr_agg_sp) #spline is just overfitting
plotdata[[1]][,"model"] = "linear"
plotdata[[2]][,"model"] = "sqrt"
plotdata[[3]][,"model"] = "spline"
plotdata = do.call(rbind,plotdata)


g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="ELSA")+
  #scale_y_log10()+
  #annotation_logticks(sides="l")+
  theme_minimal()+
  theme()


g

save=T
if(save)
{
  ggsave(sprintf("%s/results/hazard_elsa_coxph.pdf",outputDir),g,width=9,height=8,dpi=300)
  ggsave(sprintf("%s/results/hazard_elsa_coxph.png",outputDir),g,width=9,height=8,dpi=300)
}
```
# Cox assumption
```{r}
prname="fi"
#cuts = c(0,.05,seq(.15,.65,by=.1),1)
cuts = c(seq(0,.65,by=.1),1)
ytest = seq(0,.8,by=.01)
labs = unique(cut(seq(0,1,by=.1),cuts,include.lowest=T))
fitdata = list()
fitdatase = list()
for (i in 1:length(stst))
{
  pr = stst[[i]][[1]][,prname]
  pr = cut(pr,cuts,labels=labs,include.lowest=T)
  #pr = factor(pr,sortedlabs) #refactor so that middle quantile is first
  vals = aggregate(stst[[i]][[1]][,prname],by=list(q=pr),mean,na.rm=T)
  vals_se = aggregate(stst[[i]][[1]][,prname],by=list(q=pr),SEM,na.rm=T)
  
  mod = coxph(stst[[i]][[2]]~pr)
  C = summary(mod)$coefficients
  
  fitdata[[i]] = data.frame(beta=c(0,C[,"coef"]),y=vals[,"x"])
  colnames(fitdata[[i]]) = gsub("y",prname,colnames(fitdata[[i]]))
  #colnames(fitdata[[i]]) = gsub("beta","pr",colnames(fitdata[[i]]))
  fitdata[[i]] = as.matrix(fitdata[[i]])
  
  fitdatase[[i]] = data.frame(beta=c(0,C[,"se(coef)"]),y=vals_se[,"x"])
  colnames(fitdatase[[i]]) = gsub("y",prname,colnames(fitdatase[[i]]))
  #colnames(fitdatase[[i]]) = gsub("beta","pr,colnames(fitdatase[[i]]))
  fitdatase[[i]] = as.matrix(fitdatase[[i]])
  
}
fitdata = RubinMat(fitdata,fitdatase)
fitdata[[1]] = as.data.frame(fitdata[[1]])
fitdata[[1]][,sprintf("%sse",colnames(fitdata[[1]]))] = fitdata[[2]]
fitdata = fitdata[[1]]


save=T
if(save)
{
  write.csv(fitdata,sprintf("%s/data/cox_ph_test_elsa.csv",outputDir))
}
```

Parametric survival
add a bit more flexibility (Sr looks bad, so maybe this will help)
```{r}
library(eha)
mg = phreg(stst[[1]][[2]]~1,dist = "gompertz",param="rate")

```

```{r}
plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(.6,1))
s0 = exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*60))/coef(mg)["rate"]) #looks a little better #we know they survived to 60
#s0 = 1 # looks very similar
curve(exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*x))/coef(mg)["rate"])/s0,add=T,col=2) #using eha fit
curve(exp(-Hgompertz(x,rate=coef(mg)["rate"],shape=exp(coef(mg)["log(level)"]),param="rate")),col=3,lty=3,add=T)
```

```{r}
mgr = phreg(stst[[1]][[2]]~1,dist = "gompertz",param="rate")
mgc = phreg(stst[[1]][[2]]~1,dist = "gompertz",param="canonical")
plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(.6,1))
curve(exp(-Hgompertz(x,rate=coef(mgr)["rate"],shape=exp(coef(mgr)["log(level)"]),param="rate")),col=2,lty=1,add=T)
curve(exp(-Hgompertz(x,scale=exp(coef(mgc)["log(scale)"]),shape=exp(coef(mgc)["log(shape)"]),param="canonical")),col=3,lty=3,add=T)

curve(hgompertz(x,rate=coef(mgr)["rate"],shape=exp(coef(mgr)["log(level)"]),param="rate"),col=2,lty=1,add=F)
curve(hgompertz(x,scale=exp(coef(mgc)["log(scale)"]),shape=exp(coef(mgc)["log(shape)"]),param="canonical"),col=3,lty=3,add=T)
```
to get confidence intervals...
```{r}
library(MASS)
PHConfInt = function(ttest = seq(60,100,by=.1),
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    x=NULL, #named vector
                    t0=ttest[1]
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(ttest))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[names(x)]
      fits[i,] = exp(sum(beta*x))*Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,t=ttest,x=x,t0=t0))
}

PHConfInt2VecX = function(x, #vector of values
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    t0=60
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[1]
      fits[i,] = exp(beta*x)*Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,x=x,ttest=ttest,t0=t0))
}

PHConfInt.hazard = function(x, #matrix or data.frame of covariates
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    param="rate" #phreg lets you fit differently
                    )
{
  x = as.matrix(x)
  param  = tolower(param)

  fits = matrix(NA,nrow=N,ncol=nrow(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(x)) 
    {
      if(param=="rate") fits[i,] = hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
    else 
    {
      #print(par)
      #print(colnames(x))
      beta = par[colnames(x)]
      #print(beta)
      #print(head(x%*%beta))
      #fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      if(param=="rate") fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
  }
  h = apply(fits,2,mean,na.rm=T)
  hsd = apply(fits,2,sd,na.rm=T)
  hmin = h-errorScale*hsd
  hmax = h+errorScale*hsd

    
  return(list(h=h,hsd=hsd,hmin=hmin,hmax=hmax,fit=fit,N=N,x=x,ttest=ttest,t0=t0,param=param))
}

t = PHConfInt(fit=mg)

plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(.6,1))
lines(t[["t"]],t[["S"]],col=2)
lines(t[["t"]],t[["Smin"]],col=2,lty=2)
lines(t[["t"]],t[["Smax"]],col=2,lty=2)
```
survPen is a more user-friendly package
```{r}
library(survPen)
sp = survPen(~1+death,data=stst[[1]][[1]],t0=start,t1=death,event=status)
```

```{r}
plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(.6,1))
#test = data.frame(start=0,death=seq(60,100,by=.1))
test = data.frame(start=60,death=seq(60,100,by=.1)) #looks same
pr = predict(sp,newdata=test)
lines(test[,"death"],pr[["surv"]],col=2)
lines(test[,"death"],pr[["surv.inf"]],col=2,lty=2)
lines(test[,"death"],pr[["surv.sup"]],col=2,lty=2)
```



```{r}
GompertzHazard = function(t,fit)
{
  #survival:
  #plot(s)
  #curve(exp(baselineHazard*exp(beta*x)*(1-exp(alpha*t))/alpha)/s0,add=T,col=2)
  h = exp(coef(fit)["log(level)"])*exp(coef(fit)["rate"]*t)*exp(coef(fit)["rate"])
  return(h)
    
}
```

eha looks better even though it's a pain to use
```{r}
library(eha)
fit = phreg(stst[[1]][[2]]~fi,data=stst[[1]][[1]],dist = "gompertz",param="rate")

```

```{r}
library(scico)
st = stst[[1]][[1]]
sst = stst[[1]][[2]]
conf.int = pnorm(1)-pnorm(-1)
#conf.int = .95
#cuts = c(-Inf,-2:1+.5,Inf)
#zq = cut(st[,"z01"],cuts)
probs = seq(0,1,length=3)
cuts = quantile(st[,"fi"],probs=probs)

zq = cut(st[,"fi"],cuts,labels = sprintf("%.0f%%",round(probs[-1]*100)))
cols = scico(length(levels(zq)), palette = 'roma')
t = seq(60,100,by=1)
fitdata = list()
for (j in 1:length(levels(zq)))
{
  muzq = mean(st[zq==levels(zq)[j],"fi"],na.rm=T)
  H = PHConfInt(ttest=t,N=1000,fit=fit,errorScale=qnorm(.975),x=c(fi=muzq),t0=60)
  
  fitdata[[j]] = data.frame(strata=levels(zq)[j],
                            #t=t,
                            t=H[["t"]],
                            #H=exp(coef(fit)[1]*muzq)*Hgompertz(t,rate=coef(fit)["rate"],shape=exp(coef(fit)["log(level)"]),param="rate")
                            H=H[["H"]],
                            Hmin=H[["Hmin"]],
                            Hmax=H[["Hmax"]],
                            dH=H[["Hsd"]]
                  )
}
fitdata=do.call(rbind,fitdata)
#fitdata[,"dH"] = 0
fitdata[,"S"] = exp(-fitdata[,"H"])
#fitdata[,"dS"] = 0
fitdata[,"Smin"] = exp(-fitdata[,"Hmin"])
fitdata[,"Smax"] = exp(-fitdata[,"Hmax"])
fitdata[,"strata"]= factor(fitdata[,"strata"],levels(zq))

sf = survfit(sst ~ z,data=data.frame(z=zq),conf.int=conf.int)
group = rep("unknown",length(sf$cumhaz))
ind = 0
for (j in 1:length(sf$strata))
{
  group[1:sf$strata[j]+ind] = gsub("z=","",names(sf$strata)[j])
  ind = ind + sf$strata[j]
}
group = factor(group,levels(zq))
  
#survival
logi = !is.na(sf$upper) & !is.na(sf$lower)
g = ggplot(data.frame(t=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,strata=group)[logi,],
       aes(x=t,y=S,ymin=Smin,ymax=Smax,colour=strata,fill=strata))+
  geom_line(lty=2)+
  geom_ribbon(alpha=.5,colour=NA)+
  #scale_colour_manual(breaks=levels(group),values=cols)+
  #scale_fill_manual(breaks=levels(group),values=cols)+
  #scale_colour_discrete_diverging("Blue-Red")+
  #scale_fill_discrete_diverging("Blue-Red")+
  scico::scale_color_scico_d(palette="roma")+
  scico::scale_fill_scico_d(palette="roma")+
  labs(y="Survival",x="Years on dialysis",colour="Percentile",fill="Percentile",linetype="")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
          legend.position= "right", #c(.6,.3), #
          legend.key.size = unit(4,"line"),
          legend.text=element_text(size=gTextSize*.9)#,
          #legend.title=element_blank()
        )


g = g + geom_line(data=fitdata,lwd=1,inherit.aes=F,mapping=aes(x=t,y=S,colour=strata,linetype="Fit"))
g = g + geom_ribbon(data=fitdata,colour=NA,alpha=.15)

g = g + scale_x_continuous(limits=c(60,100))
g = g + scale_y_continuous(limits=c(0.7,1))

g


save = T
if(save)
{
  ggsave(sprintf("%s/results/survival_diagnostic_fi_elsa.pdf",outputDir),
           g,width=8,height=6,dpi=300)
  ggsave(sprintf("%s/results/survival_diagnostic_fi_elsa.png",outputDir),
           g,width=8,height=6,dpi=300)
}

```
```{r}
library(splines2)
ttest = 60
t0 = 60
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.1),1)
#fi_cuts = c(0,seq(0.01,.6,by=.1),1) #bad idea... very low FI have basically 0 risk


#linear
l = list()
lse = list()
param = list()
paramse = list()
paramsemat = list()
for(ii in 1:length(stst))
{
  md = phreg(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]],dist = "gompertz",param="rate")
  #md = phreg(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]],dist = "gompertz",param="canonical") #very similar

  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=data.frame(fi=testfi),param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  
  param[[ii]] = matrix(coef(md),nrow=1,ncol=length(coef(md)))
  colnames(param[[ii]]) = names(coef(md))
  paramse[[ii]] = matrix(diag(md[["var"]]),nrow=1,ncol=length(coef(md)))
  colnames(paramse[[ii]]) = names(coef(md))
  paramsemat[[ii]] = as.matrix(md[["var"]])
}
pr_agg = RubinMat(l,lse)
pr_agg[[1]] = data.frame(pr_agg[[1]])
pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
pr_agg = pr_agg[[1]]
rm(l)
rm(lse)
  
param = RubinMat(param,paramse,checkAlignment = F)
paramsemat = RubinMat(paramsemat)
  
#gompertz - sqrt
l = list()
lse = list()
for(ii in 1:length(stst))
{
  #md = phreg(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]],dist = "gompertz",param="rate") #fails
  md = phreg(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]],dist = "gompertz",param="canonical") #probably wrong

  test = data.frame(testfi)
  colnames(test) = "sqrt(fi)"
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=test,param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
}
pr_agg_sq = RubinMat(l,lse)
pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
pr_agg_sq = pr_agg_sq[[1]]
rm(l)
rm(lse)


#gompertz - spline
l = list()
lse = list()
for(ii in 1:length(stst))
{
  b = predict(bMat,stst[[ii]][[1]][,"fi"])
  temp = data.frame(b)
  colnames(temp) = colnames(bMat)
  
  md = phreg(stst[[ii]][["s"]]~.,data=temp,dist = "gompertz",param="rate")
  #md = phreg(stst[[ii]][["s"]]~.,data=temp,dist = "gompertz",param="canonical") #waaaaaaay off

  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=testMat,param=md[["param"]])

  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
}
pr_agg_sp = RubinMat(l,lse)
pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
pr_agg_sp = pr_agg_sp[[1]]
rm(l)
rm(lse)

#population stats
#still has to use coxph because of censorship
l = list()
lse = list()
for(ii in 1:length(stst))
{
  temp = stst[[ii]][[1]]
  temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
  
  md = phreg(stst[[ii]][["s"]]~fi_cut,data=temp,dist = "gompertz",param="rate")
  #md = phreg(stst[[ii]][["s"]]~fi_cut,data=temp,dist = "gompertz",param="canonical") #very similar
    
  test = data.frame(y=NA,fi=testfi)
  test[,"fi_cut"] = cut(test[,"fi"],fi_cuts,include.lowest=T)
  test = aggregate(test[,c("y","fi")],by=list(fi_cut=test[,"fi_cut"]),mean,na.rm=T) #compress down into 1 / unique value
  test[,"fise"] = aggregate(test[,c("fi"),drop=F],by=list(fi_cut=test[,"fi_cut"]),SEM,na.rm=T)[,"fi"]
  #one-hot:
  beta = coef(md)[!(names(coef(md))%in%c("rate","log(level)","log(scale)","log(shape)"))]
  onehot = matrix(0,nrow=nrow(test),ncol=length(beta))
  nms = character()
  for (jj in 1:length(beta)) nms[jj] = strsplit(names(beta)[jj],"fi_cut")[[1]][2]
  for (jj in 1:nrow(test)) 
  {
      onehot[jj,] = as.integer(nms == test[jj,"fi_cut"])
  }
    
  colnames(onehot) = names(beta)

  
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=onehot,param=md[["param"]])

  l[[ii]] = as.matrix(data.frame(fi=test[,"fi"],pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
}
agg = RubinMat(l,lse)
for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
agg[[1]] = data.frame(agg[[1]])
agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
agg = agg[[1]]

plotdata = list(pr_agg,pr_agg_sq,pr_agg_sp) #spline is just overfitting #
plotdata[[1]][,"model"] = "linear"
plotdata[[2]][,"model"] = "sqrt"
plotdata[[3]][,"model"] = "spline"
plotdata = do.call(rbind,plotdata)


g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="ELSA")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()


g = ggplot(pr_agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="ELSA")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()

g

save=T
if(save)
{
  ggsave(sprintf("%s/results/hazard_elsa_gompertz.pdf",outputDir),g,width=9,height=8,dpi=300)
  ggsave(sprintf("%s/results/hazard_elsa_gompertz.png",outputDir),g,width=9,height=8,dpi=300)
  
  #table of coefficients
  tb = data.frame(beta=sprintf("%.3f pm %.3f",param[[1]][1,"fi"],param[[2]][1,"fi"]),
                  alpha=sprintf("%.3f pm %.3f",param[[1]][1,"rate"],param[[2]][1,"rate"]),
                  lnh0=sprintf("%.3f pm %.3f",param[[1]][1,"log(level)"],param[[2]][1,"log(level)"]),
                  h0=sprintf("%.3f pm %.3f",exp(param[[1]][1,"log(level)"]),exp(param[[1]][1,"log(level)"])*param[[2]][1,"log(level)"])
                  )
  write.csv(tb,sprintf("%s/results/hazard_elsa_gompertz.csv",outputDir))
  write.csv(paramsemat,sprintf("%s/results/hazard_elsa_gompertz_errors.csv",outputDir))
  print("fit parameters:")
  print(tb)
  
  #will load these in elsewhere to compare to HRS 
  write.csv(pr_agg,sprintf("%s/results/hazard_elsa_gompertz_pragg.csv",outputDir),row.names=F)
  write.csv(agg,sprintf("%s/results/hazard_elsa_gompertz_agg.csv",outputDir),row.names=F)
}


```
################
# Cox models for death
################
Could also do Gompertz or spline...
```{r}
preds = c("sex","age","fi",fpVar)

names(preds)=c("Female","Age per 10","FI per 0.1",names(fpVar))
use = list()
use[[1]] = preds %in% c("fi")
use[[2]] = preds %in% c("age","sex")
use[[3]] = preds %in% c("age","sex","fi")
use[[4]] = preds == preds


C = list()
Cse = list()
for (ii in 1:length(stst))
{
  s2 = stst[[ii]][[2]]
  s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]]))
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][[1]][,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10

    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    #Cse[[ii]][j,"p"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
      #print(anova(prevMod,mod))
      #print(C[[ii]][j,"p"])
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2 = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2) = dimnames(C[[1]])
for (j in 1:length(preds)) C2[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2[is.na(C[[1]])] = ""
C2[,"BIC"] = sprintf("%.0f",C[[1]][,"BIC"])
C2[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2)[colnames(C2)==preds[j]] = names(preds)[j]

write.csv(C2,sprintf("%s/results/elsa_cox.csv",outputDir),row.names=FALSE)
```

################
# death prevalence curves
################
probability of dying within the followup time (4 years)

use kaplan-meier non-parametric estimator for points
linear interpolator
problem: apparently the estimator is biased. but forcing gompertz is also biased. only solution is to use survpen and make sure I recover kaplan meier result

```{r}
library(eha)
library(survPen)
```

```{r}
#note: survfit(s~x) is same as just splitting up by x strata
NonParSurv = function(s,t,conf.int=pnorm(1)-pnorm(-1))
{
  sf = survfit(s~1,conf.int=conf.int)
  app = approxfun(x=sf$time,y=sf$surv,yleft = 1,yright=NA)
  applow = approxfun(x=sf$time,y=sf$lower,yleft = 1,yright=NA)
  apphigh = approxfun(x=sf$time,y=sf$upper,yleft = 1,yright=NA)
  return(data.frame(pr=app(t),prlow=applow(t),prhigh=apphigh(t)))
}
```



```{r}
library(splines2)
include="logit"
testfi = seq(0,.75,by=.01)
ttest = 4 #followup time
fi_cuts = c(seq(0,.6,by=.1))

bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)

  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~fi,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~fi,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(fi),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testfi),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  #spline #I want to make sure I recover kaplain-meier if I crank up fit (since it's purportedly biased)
    #gotta use survpen since we don't know if Gompertz is right
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    #b = predict(bMat,stst[[ii]][[1]][,"fi"])
    #temp = data.frame(b)
    #colnames(temp) = colnames(bMat)
    
    #md = phreg(s2~.,data=temp,dist="gompertz",param="rate")
    #prS = numeric()
    #prSse = numeric()
    #for (kk in 1:nrow(testMat))
    #{
    #  pr = PHConfInt(ttest=ttest,t0=0,N = 100,fit=md,errorScale=1,x=testMat[kk,])
    #  prS[kk] = pr[["S"]]
    #  prSse[kk] = abs(pr[["Smax"]]/2-pr[["Smin"]]/2)
    #}
    #l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-prS))
    #lse[[ii]] = as.matrix(data.frame(fi=0,pr=prSse))
    temp = stst[[ii]][[1]]
    temp[,"status"] = stst[[ii]][[2]][,"status"] #stst[[ii]][1] is final status; [[2]] is current status
    temp[,"tstart"] =  stst[[ii]][[2]][,"start"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    temp[,"tstop"] =  stst[[ii]][[2]][,"stop"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    md = survPen(~smf(tstop)+smf(fi),data=temp,t0=tstart,t1=tstop,event=status)
    pr = predict(md,newdata=data.frame(tstop=ttest,fi=testfi,tstart=t0),conf.int=pnorm(1)-pnorm(-1))
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["surv"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["surv.inf"]]/2-pr[["surv.sup"]]/2)))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    fic = cut(stst[[ii]][[1]][,"fi"],fi_cuts,include.lowest=T)
    temp = data.frame(fi_cut=levels(fic))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = fic == temp[jj,"fi_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = abs(pr[["prhigh"]]/2-pr[["prlow"]]/2)
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"fi"] = mean(stst[[ii]][[1]][logi,"fi"],na.rm=T)
      temp[jj,"fise"] = SEM(stst[[ii]][[1]][logi,"fi"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("fi","pr")])
    lse[[ii]] = as.matrix(temp[,c("fise","prse")])
    
    logitmod = lm(log(pr/(1-pr))~sqrt(fi),subset(temp,pr != 0 & pr != 1))#,weights=1/(temp[,"prse"]^2+temp[,"fise"]^2)) #weights look worse (overfit)
    pr = predict(logitmod,data.frame(fi=testfi),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(fi=testfi,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit,pr_agg_sp)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  #frequencies
  g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(legend.position="none")
  
  g
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/death_prevalence_elsa_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/death_prevalence_elsa_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_sp,sprintf("%s/data/death_prevalence_elsa_logit_pragg_sp.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/death_prevalence_elsa_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/death_prevalence_elsa_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/death_prevalence_elsa.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/death_prevalence_elsa.png",outputDir),g,width=8,height=8,dpi=300)
  

}

gl = list(g)
```

Nfp prevalence

```{r}
library(splines2)
include="logit"
testNfp = seq(0,5,by=.01)
ttest = 4 #followup time
Nfp_cuts = 0:5

  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~Nfp,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testNfp,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~Nfp,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(Nfp),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testNfp),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  #spline #I want to make sure I recover kaplain-meier if I crank up fit (since it's purportedly biased)
    #gotta use survpen since we don't know if Gompertz is right
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    temp = stst[[ii]][[1]]
    temp[,"status"] = stst[[ii]][[2]][,"status"] #stst[[ii]][1] is final status; [[2]] is current status
    temp[,"tstart"] =  stst[[ii]][[2]][,"start"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    temp[,"tstop"] =  stst[[ii]][[2]][,"stop"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    md = survPen(~smf(tstop)+smf(Nfp),data=temp,t0=tstart,t1=tstop,event=status)
    pr = predict(md,newdata=data.frame(tstop=ttest,Nfp=testNfp,tstart=t0),conf.int=pnorm(1)-pnorm(-1))
    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["surv"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=abs(pr[["surv.inf"]]/2-pr[["surv.sup"]]/2)))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    Nfpc = cut(stst[[ii]][[1]][,"Nfp"],Nfp_cuts,include.lowest=T)
    temp = data.frame(Nfp_cut=levels(Nfpc))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = Nfpc == temp[jj,"Nfp_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = abs(pr[["prhigh"]]/2-pr[["prlow"]]/2)
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"Nfp"] = mean(stst[[ii]][[1]][logi,"Nfp"],na.rm=T)
      temp[jj,"Nfpse"] = SEM(stst[[ii]][[1]][logi,"Nfp"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("Nfp","pr")])
    lse[[ii]] = as.matrix(temp[,c("Nfpse","prse")])
    
    logitmod = lm(log(pr/(1-pr))~sqrt(Nfp),subset(temp,pr != 0 & pr != 1))#,weights=1/(temp[,"prse"]^2+temp[,"Nfpse"]^2)) #weights look worse (overfit)
    pr = predict(logitmod,data.frame(Nfp=testNfp),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(Nfp=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit,pr_agg_sp)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  #frequencies
  g = ggplot(plotdata,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=Nfp,xmin=Nfp-Nfpse,xmax=Nfp+Nfpse,y=pr),inherit.aes=F,height=0)+  
    labs(x=gFab5Name,y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(legend.position="none")
  
  g
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/Nfp_death_prevalence_elsa_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/Nfp_death_prevalence_elsa_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_sp,sprintf("%s/data/Nfp_death_prevalence_elsa_logit_pragg_sp.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/Nfp_death_prevalence_elsa_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/Nfp_death_prevalence_elsa_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/Nfp_death_prevalence_elsa.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/Nfp_death_prevalence_elsa.png",outputDir),g,width=8,height=8,dpi=300)
}
```

age - death prevalence

```{r}
library(splines2)
testage = seq(60,90,by=1)
ttest = 4 #followup time
age_cuts = c(seq(60,90,by=5)) #89 is max
include="logit"


  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~age,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~age,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(age),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testage),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    agec = cut(stst[[ii]][[1]][,"age"],age_cuts,include.lowest=T)
    temp = data.frame(age_cut=levels(agec))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = agec == temp[jj,"age_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = pr[["prhigh"]]/2-pr[["prlow"]]/2
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"age"] = mean(stst[[ii]][[1]][logi,"age"],na.rm=T)
      temp[jj,"agese"] = SEM(stst[[ii]][[1]][logi,"age"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("age","pr")])
    lse[[ii]] = as.matrix(temp[,c("agese","prse")])
    
    logitmod = lm(log(pr/(1-pr))~age,temp)#,weights=1/(temp[,"prse"]^2+temp[,"agese"]^2))
    pr = predict(logitmod,data.frame(age=testage),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(age=testage,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(age=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata = do.call(rbind,plotdata)
  
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  #frequencies
  g = ggplot(plotdata,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(legend.position="none")
  

  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/age_death_prevalence_elsa_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/age_death_prevalence_elsa_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/age_death_prevalence_elsa_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/age_death_prevalence_elsa_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/age_death_prevalence_elsa.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_death_prevalence_elsa.png",outputDir),g,width=8,height=8,dpi=300)
  

}
#plot(log(pr/(1-pr))~age,agg) #non-linear even here!
```

```{r}
plot(agg[,"age"],log(agg[,"pr"])-log(1-agg[,"pr"]))
abline(lm(log(pr/(1-pr))~age,agg))
```

################
# Predicting FUTURE fab-5 deficits (and frailty phenotype)
################


```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAcc = temp$acc
  agePredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAcc = RubinMat(metrics,lse=metricsSE)
  agePredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAcc,roc=agePredROC),file)
  }
}

```


```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_male_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccM = temp$acc
  agePredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccM = RubinMat(metrics,lse=metricsSE)
  agePredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccM,roc=agePredROCM),file)
  }
}

```


```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_female_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccF = temp$acc
  agePredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccF = RubinMat(metrics,lse=metricsSE)
  agePredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccF,roc=agePredROCF),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_fifpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAcc = temp$acc
  fiPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAcc = RubinMat(metrics,lse=metricsSE)
  fiPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAcc,roc=fiPredROC),file)
  }
}

```


```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_male_fifpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccM = temp$acc
  fiPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccM = RubinMat(metrics,lse=metricsSE)
  fiPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccM,roc=fiPredROCM),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_female_fifpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccF = temp$acc
  fiPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccF = RubinMat(metrics,lse=metricsSE)
  fiPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccF,roc=fiPredROCF),file)
  }
}

```

```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}
#plotdata[[length(vars)+1]] = as.data.frame(fiROC[[1]])
#colnames(plotdata[[length(vars)+1]])[1] = "specificities"
#specificity is user-specific so has no error
#plotdata[[length(vars)+1]][,"sensitivity_se"] = fiROC[[2]][,"sensitivity"]
#plotdata[[length(vars)+1]][,"variable"] = "FP"
#plotdata[[length(vars)+1]][,"max_youden"] = #max(plotdata[[length(vars)+1]][,"sensitivity"]+plotdata[[length(vars)+1]][,"specificities"],na.rm=T)
plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()
```
If we include fab-5 in the fi...

```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAcc = temp$acc
  fifpPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAcc = RubinMat(metrics,lse=metricsSE)
  fifpPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAcc,roc=fifpPredROC),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_male_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAccM = temp$acc
  fifpPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAccM = RubinMat(metrics,lse=metricsSE)
  fifpPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAccM,roc=fifpPredROCM),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_elsa_female_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAccF = temp$acc
  fifpPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAccF = RubinMat(metrics,lse=metricsSE)
  fifpPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAccF,roc=fifpPredROCF),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAcc = temp$acc
  fpPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAcc = RubinMat(metrics,lse=metricsSE)
  fpPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAcc,roc=fpPredROC),file)
  }
}
```


```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_male_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccM = temp$acc
  fpPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccM = RubinMat(metrics,lse=metricsSE)
  fpPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccM,roc=fpPredROCM),file)
  }
}
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_female_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccF = temp$acc
  fpPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccF = RubinMat(metrics,lse=metricsSE)
  fpPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccF,roc=fpPredROCF),file)
  }
}
```

```{r}
vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()
```
Leave-one-out...

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAcc = temp$acc
  fp4PredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      r = roc(data[[i]][,fpNames[j]]~Nfpexcl,ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAcc = RubinMat(metrics,lse=metricsSE)
  fp4PredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAcc,roc=fp4PredROC),file)
  }
}
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_male_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAccM = temp$acc
  fp4PredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl[logi],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAccM = RubinMat(metrics,lse=metricsSE)
  fp4PredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAccM,roc=fp4PredROCM),file)
  }
}
```


```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_elsa_female_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAccF = temp$acc
  fp4PredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl[logi],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAccF = RubinMat(metrics,lse=metricsSE)
  fp4PredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAccF,roc=fp4PredROCF),file)
  }
}
```

```{r}
g = list()
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g[[1]] = ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.7,.3))


vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g[[2]] = ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.7,.3))

marrangeGrob(g,nrow=1,ncol=2,top=NULL)
```

```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)


plotdata0 = plotdata
plotdata2 = list(plotdata)

vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata2[[2]] = plotdata
plotdata2[[1]][,"group"] = "FI"
plotdata2[[2]][,"group"] = "NFab5"

#avant guard idea: make symmetrical about x=y
#plotdata2[[2]][,"sensitivity"] = 1-plotdata2[[2]][,"sensitivity"]
#plotdata2[[2]][,"specificities"] = 1-plotdata2[[2]][,"specificities"]
plotdata2 = do.call(rbind,plotdata2)
fpNamesSorted = fpNames[c("FP","Slow gait","Low activity","Exhaustion","Weakness","Weight loss")]

cols = gg_color_hue(length(fpNamesSorted)-1)
ind = which(fpNamesSorted=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g = ggplot(plotdata2,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable,linetype=group))+
  geom_line()+
  geom_point(data=plotdata2[rep(c(T,rep(F,4)),length=nrow(plotdata2)),],aes(alpha=group))+
  geom_ribbon(alpha=.2,col=NA)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_shape_manual(breaks=fpNamesSorted,values = 1:length(fpNamesSorted),labels=names(fpNamesSorted))+
  scale_fill_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_colour_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_alpha_manual(breaks=c("FI","NFab5"),values=c(1,0))+
  scale_x_reverse()+
  labs(x="Specificity",y="Sensitivity")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.84,.38))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_roc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_roc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

### performance measures
```{r}
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAcc[[1]]),auc=fiPredAcc[[1]][,"auc"],auc_se=fiPredAcc[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAcc[[1]]),auc=fpPredAcc[[1]][,"auc"],auc_se=fpPredAcc[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAcc[[1]]),auc=fifpPredAcc[[1]][,"auc"],auc_se=fifpPredAcc[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAcc[[1]]),auc=fp4PredAcc[[1]][,"auc"],auc_se=fp4PredAcc[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"


plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5",gFab5Name,"Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+ 
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  #scale_alpha_manual(values=alphas)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position= c(.8,.88) #c(.8,.8)
        )
g

#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAcc[[1]][inds,"auc"][1:2]),
      mean(fp4PredAcc[[1]][inds,"auc"][1:2]),
      mean(fifpPredAcc[[1]][inds,"auc"][1:2]),
      mean(fpPredAcc[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=T
textSize=8
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.9,1) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(2.5,3.25)
  ybox = c(.85,.95) #c(.875,.925)
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) #c(3.5,4.25)
  ybox = c(.81,.91) #c(.82,.86)
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=bquote("Test 3.\nFI ~ "*.(gFab5Name)),size=textSize)
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 3.\nFI ~ %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}


#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
#g2 = g2 + scale_y_continuous(limits=c(0.45,1))
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))

#fix font
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position="none",legend.key.size = unit(3,"line"))

g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(b) ELSA")
  
g2

save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc.png",outputDir),g,width=10,height=8,dpi=300)
  
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc_wline.pdf",outputDir),g2,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc_wline.png",outputDir),g2,width=10,height=8,dpi=300)
}
```

```{r}
# MALES
# MALES
# MALES
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAccM[[1]]),auc=fiPredAccM[[1]][,"auc"],auc_se=fiPredAccM[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAccM[[1]]),auc=fpPredAccM[[1]][,"auc"],auc_se=fpPredAccM[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAccM[[1]]),auc=fifpPredAccM[[1]][,"auc"],auc_se=fifpPredAccM[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAccM[[1]]),auc=fp4PredAccM[[1]][,"auc"],auc_se=fp4PredAccM[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAccM[[1]]),auc=agePredAccM[[1]][,"auc"],auc_se=agePredAccM[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"

#plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))
plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(fiPredAcc[[1]][,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5","NFab5","Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_point(position=position_dodge(.1),size=1)+
  #geom_errorbar(position=position_dodge(.1),size=1,width=0)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g



#############
#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAccM[[1]][inds,"auc"][1:2]),
      mean(fp4PredAccM[[1]][inds,"auc"][1:2]),
      mean(fifpPredAccM[[1]][inds,"auc"][1:2]),
      mean(fpPredAccM[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=F
textSize=7
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.875,.975) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fifpPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(.75,1.5)
  ybox = c(.85,.95) #c(.725,.775)-0.05
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) # c(3.5,4.25)
  ybox = c(.75,.85) #c(.82,.86)-0.05
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=bquote("Test 3.\nFI ~"~.(gFab5Name)),size=textSize)
  a2 = fiPredAccM[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccM[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}

#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))


#add chronological age
#ageData = data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Age")
#g2 = g2 + geom_line(data=ageData,colour="black",fill=NA)
#g2 = g2 + geom_ribbon(data=ageData,colour=NA,fill="black",alpha=.15)

#fix font & legend
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position=c(.775,.8),legend.key.size = unit(2.5,"line"))
#g2 = g2 + guides(shape=guide_legend(ncol=2,byrow=FALSE))
g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(a) ELSA - Males")
  
g2


gl = list(g2)

# FEMALES
# FEMALES
# FEMALES
# FEMALES
# FEMALES
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAccF[[1]]),auc=fiPredAccF[[1]][,"auc"],auc_se=fiPredAccF[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAccF[[1]]),auc=fpPredAccF[[1]][,"auc"],auc_se=fpPredAccF[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAccF[[1]]),auc=fifpPredAccF[[1]][,"auc"],auc_se=fifpPredAccF[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAccF[[1]]),auc=fp4PredAccF[[1]][,"auc"],auc_se=fp4PredAccF[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAccF[[1]]),auc=agePredAccF[[1]][,"auc"],auc_se=agePredAccF[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"

#plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))
plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(fiPredAcc[[1]][,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5","NFab5","Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_point(position=position_dodge(.1),size=1)+
  #geom_errorbar(position=position_dodge(.1),size=1,width=0)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g



#############
#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAccF[[1]][inds,"auc"][1:2]),
      mean(fp4PredAccF[[1]][inds,"auc"][1:2]),
      mean(fifpPredAccF[[1]][inds,"auc"][1:2]),
      mean(fpPredAccF[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=T
textSize=7
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.9,1) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(.75,1.5)
  ybox = c(.85,.95) #c(.725,.775)-0.05
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) # c(3.5,4.25)
  ybox = c(.75,.85)+.05 #c(.82,.86)-0.05
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 3.\nFI ~ %s",gFab5Name),size=textSize)
  a2 = fiPredAccF[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccF[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}

#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))


#add chronological age
#ageData = data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Age")
#g2 = g2 + geom_line(data=ageData,colour="black",fill=NA)
#g2 = g2 + geom_ribbon(data=ageData,colour=NA,fill="black",alpha=.15)

#fix font & legend
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position=c(.775,.8),legend.key.size = unit(2.5,"line"))
#g2 = g2 + guides(shape=guide_legend(ncol=2,byrow=FALSE))
g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(b) ELSA - Female")
  
g2

save = T
if(save)
{

  
  gl[[2]] = g2+ggtitle("(b) ELSA - Females")
  gl[[1]] = gl[[1]]+ggtitle("(a) ELSA - Males")
  #for (i in 1:length(gl)) gl[[i]] = gl[[i]] + scale_y_continuous(limits=c(.39,1))
  gl[[2]] = gl[[2]]+theme(legend.position="none")

    #fix font
  for (i in 1:length(gl)) gl[[i]] = gl[[i]] + theme(axis.text.x=element_text(size=16,angle=0),axis.text.y=element_text(size=16,angle=0),axis.title.y=element_text(size=18,angle=90,hjust=.54))

  gl[[1]] = gl[[1]] + guides(shape=guide_legend(ncol=2,byrow=FALSE))+theme(legend.position=c(.575,.875))
  
    ggsave(sprintf("%s/results/fi_vs_fp_elsa_sex_auc_wline.pdf",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=6,dpi=300)
    ggsave(sprintf("%s/results/fi_vs_fp_elsa_sex_auc_wline.png",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=6,dpi=300)
}
```


```{r}
plotdata =  list()
plotdata[[1]] =  data.frame(variable=rownames(fifpPredAcc[[1]]),auc=fifpPredAcc[[1]][,"auc"],auc_se=fifpPredAcc[[2]][,"auc"],group="FI - including fab-5")
plotdata[[2]] = data.frame(variable=rownames(fpPredAcc[[1]]),auc=fpPredAcc[[1]][,"auc"],auc_se=fpPredAcc[[2]][,"auc"],group="NFab5")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc1.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc1.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAcc[[1]]),auc=fiPredAcc[[1]][,"auc"],auc_se=fiPredAcc[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fp4PredAcc[[1]]),auc=fp4PredAcc[[1]][,"auc"],auc_se=fp4PredAcc[[2]][,"auc"],group="NFab5 - leave-one-out")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))


g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc2.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_elsa_auc2.png",outputDir),g,width=10,height=8,dpi=300)
}
```

### Multi-roc
```{r}
file = sprintf("%s/data/fi_multiroc_elsa.rds",outputDir)

load=T
save=T
nboot=2000
if(file.exists(file) & load)
{
  print("file found, loading...")
  rocFit = readRDS(file)
  predROCFI = rocFit[["pr"]]
  cutsFI = rocFit[["cuts"]]
} else
{
  pred = list()
  predLow = list()
  predHigh = list()
  predSE = list()
  cuts = list()
  cutsSE = list()
  for (i in 1:length(data))
  {
    rocFit = OrdinalROC(y=data[[i]][,"Nfp_next_ord"],x=data[[i]][,"fi"],best.policy="random",nboot=nboot,direction="<")
    pr = predict.OrdinalROC(rocFit,x=seq(0,1,length=101),fast=F,CI=pnorm(c(-1,1)))
    pred[[i]] = as.matrix(pr[,c("x","ymed")])
    predLow[[i]] = as.matrix(pr[,c("x","ylow")])
    predHigh[[i]] = as.matrix(pr[,c("x","yhigh")])
    predSE[[i]] = matrix(0,nrow=nrow(pr),ncol=2)
    predSE[[i]][,2] = pr[,"yhigh"]/2-pr[,"ylow"]/2
    colnames(predSE[[i]]) = colnames(pred[[i]])
    cuts[[i]] = apply(rocFit$cuts,2,median,na.rm=T)
    cuts[[i]] = matrix(cuts[[i]],nrow=1,ncol=length(cuts[[i]]))
    colnames(cuts[[i]]) = sprintf("%d",1:5)
    cutsSE[[i]] = apply(rocFit$cuts,2,quantile,probs=pnorm(1),na.rm=T)/2 - apply(rocFit$cuts,2,quantile,probs=pnorm(-1),na.rm=T)/2    
    cutsSE[[i]] = matrix(cutsSE[[i]],nrow=1,ncol=length(cutsSE[[i]]))
    colnames(cutsSE[[i]]) = sprintf("%d",1:5)
  }
  predROCFI = RubinMat(pred,lse=predSE)
  predROCFILow = RubinMat(predLow)
  predROCFIHigh = RubinMat(predHigh)
  for (i in 1:2) predROCFI[[i]] = data.frame(predROCFI[[i]])
  for (i in 1:2) predROCFI[[i]][,"ylow"] = predROCFILow[[i]][,"ylow"]
  for (i in 1:2) predROCFI[[i]][,"yhigh"] = predROCFIHigh[[i]][,"yhigh"]
  cutsFI = RubinMat(cuts,lse=cutsSE)
  
  if(save) saveRDS(list(cuts=cutsFI,pr=predROCFI,prhigh=predROCFIHigh,prlow=predROCFILow),file)
}
```

```{r}
file = sprintf("%s/data/fp_multiroc_elsa.rds",outputDir)

load=T
save=T
nboot=2000
if(file.exists(file) & load)
{
  print("file found, loading...")
  rocFit = readRDS(file)
  predROCFP = rocFit[["pr"]]
  cutsFP = rocFit[["cuts"]]
} else
{
  pred = list()
  predLow = list()
  predHigh = list()
  predSE = list()
  cuts = list()
  cutsSE = list()
  for (i in 1:length(data))
  {
    rocFit = OrdinalROC(y=data[[i]][,"Nfp_next_ord"],x=data[[i]][,"Nfp"],best.policy="random",nboot=nboot,direction="<")
    pr = predict.OrdinalROC(rocFit,x=seq(0,5,length=101),fast=F,CI=pnorm(c(-1,1)))
    pred[[i]] = as.matrix(pr[,c("x","ymed")])
    predLow[[i]] = as.matrix(pr[,c("x","ylow")])
    predHigh[[i]] = as.matrix(pr[,c("x","yhigh")])
    predSE[[i]] = matrix(0,nrow=nrow(pr),ncol=2)
    predSE[[i]][,2] = pr[,"yhigh"]/2-pr[,"ylow"]/2
    colnames(predSE[[i]]) = colnames(pred[[i]])
    cuts[[i]] = apply(rocFit$cuts,2,median,na.rm=T)
    cuts[[i]] = matrix(cuts[[i]],nrow=1,ncol=length(cuts[[i]]))
    colnames(cuts[[i]]) = sprintf("%d",1:5)
    cutsSE[[i]] = apply(rocFit$cuts,2,quantile,probs=pnorm(1),na.rm=T)/2 - apply(rocFit$cuts,2,quantile,probs=pnorm(-1),na.rm=T)/2    
    cutsSE[[i]] = matrix(cutsSE[[i]],nrow=1,ncol=length(cutsSE[[i]]))
    colnames(cutsSE[[i]]) = sprintf("%d",1:5)
  }
  predROCFP = RubinMat(pred,lse=predSE)
  predROCFPLow = RubinMat(predLow)
  predROCFPHigh = RubinMat(predHigh)
  for (i in 1:2) predROCFP[[i]] = data.frame(predROCFP[[i]])
  for (i in 1:2) predROCFP[[i]][,"ylow"] = predROCFPLow[[i]][,"ylow"]
  for (i in 1:2) predROCFP[[i]][,"yhigh"] = predROCFPHigh[[i]][,"yhigh"]
  cutsFP = RubinMat(cuts,lse=cutsSE)
  
  if(save) saveRDS(list(cuts=cutsFP,pr=predROCFP,prhigh=predROCFPHigh,prlow=predROCFPLow),file)
}
```

```{r}
plotdata = list()
plotdata[[1]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[1]][,"y"] = fifpNextData[[1]][,"fi_mean"]
plotdata[[1]][,"se"] = fifpNextData[[2]][,"fi_mean"]
plotdata[[1]][,"weights"] = 1/plotdata[[1]][,"se"]^2
plotdata[[1]][,"model"] = "FI"
plotdata[[2]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[2]][,"y"] = fifpNextData[[1]][,"Nfp_mean"]/5
plotdata[[2]][,"se"] = fifpNextData[[2]][,"Nfp_mean"]/5
plotdata[[2]][,"weights"] = 1/plotdata[[2]][,"se"]^2
plotdata[[2]][,"model"] = "NFab5"
plotdata = do.call(rbind,plotdata)

rocPlotDataFI = data.frame(x=predROCFI[[1]][,"x"],y=predROCFI[[1]][,"ymed"],se=predROCFI[[2]][,"ymed"],
                      ymin=predROCFI[[1]][,"ylow"],ymax=predROCFI[[1]][,"yhigh"],model="FI"
                      )
rocPlotDataFP = data.frame(x=predROCFP[[1]][,"x"]/5,y=predROCFP[[1]][,"ymed"],se=predROCFP[[2]][,"ymed"],
                      ymin=predROCFP[[1]][,"ylow"],ymax=predROCFP[[1]][,"yhigh"],model="NFab5"
                      )
rocPlotData = rbind(rocPlotDataFI,rocPlotDataFP)
#fix boundaries
#Rubin's rules take symmetrical errors
  #could just pass upper/lower to Rubin...
#plotdata[,"ymin"] = plotdata[,"y"] - plotdata[,"se"]
#plotdata[plotdata[,"ymin"] < 0,"ymin"] = 0
#plotdata[,"ymin"] = plotdata[,"y"] + plotdata[,"se"]
#plotdata[plotdata[,"ymin"] >5,"ymin"] = 5
cols = gg_color_hue(2)
g = ggplot(plotdata,aes(x=y,y=Nfp_next,xmin=y-se,xmax=y+se,colour=model))+
  geom_pointrange()+
  geom_line(data=rocPlotData,inherit.aes=F,mapping=aes(x=x,y=y,ymin=ymin,ymax=ymax,colour=model))+
  geom_ribbon(data=rocPlotData,inherit.aes=F,mapping=aes(x=x,y=y,ymin=ymin,ymax=ymax,fill=model),alpha=.2)+
  scale_x_continuous(sec.axis=sec_axis(~ . * 5, name = "Number of fab-5 deficits (NFab5)",breaks=0:5))+
  labs(x="FI",y="Number of fab-5 deficits at followup")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.8,.2),
        axis.line.x = element_line(color = cols[1]), 
       axis.ticks.x = element_line(color = cols[1]),
        axis.line.x.top = element_line(color = cols[2]), 
       axis.ticks.x.top = element_line(color = cols[2]))

g
```

################
# Predicting FUTURE fab-5 deficits and FP using logistic regression
################
Note: calc requires repeats > 1 otherwise it'll crash with a "Error in dn[[2L]] : subscript out of bounds"
```{r}
Nreps = 10
Nfolds = 10
mc.cores = 1
print(fpNames)
outTypes = rep("binary",length(fpNames))
names(outTypes) = fpNames
gLoad=T
gSave=T
```
```{r}
fits = list()
```

```{r}
baseName = "elsa_age_sex_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$age_sex = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$age_sex = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```
```{r}
baseName = "elsa_barefi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$barefi = readRDS(file)
} else
{
  dataTypes = c(fi="continuous",fi="continuous") #trick to get it to run without error
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes),drop=F],outcomes=data[[i]][,names(outTypes),drop=F])
  fits$barefi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "elsa_fi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$fi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
library(splines2)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
for (i in 1:length(data)) 
{
  b = predict(bMat,data[[i]][,"fi"])
  for (j in 1:ncol(b)) data[[i]][,sprintf("fi_sp%02d",j)] = b[,j]
}
baseName = "elsa_fisp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fisp = readRDS(file)
} else
{
  dataTypes = numeric()
  for (j in 1:ncol(bMat)) dataTypes[j] = "continuous"
  names(dataTypes) = sprintf("fi_sp%02d",1:ncol(bMat))
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$fisp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
  fits$fisp$bMat = bMat
}

```

```{r}
baseName = "elsa_fifp_calc" #uses fifp i.e. fi including FP deficits
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fifp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fifp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$fifp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "elsa_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "elsa_onehot_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$onehotNfp = readRDS(file)
} else
{
  subdata = OneHotVecOrdinal(data[[1]][,"Nfp_ord"],rootname="Nfp")
  NfpTypes = rep("binary",ncol(subdata))
  names(NfpTypes) = colnames(subdata)
  dataTypes = c(age="continuous",sex="binary",NfpTypes)
  reshapedData = list()
  for (i in 1:length(data)) 
  {
    subdata = OneHotVecOrdinal(data[[i]][,"Nfp_ord"],rootname="Nfp")
    subdata = data.frame(data[[i]][,setdiff(names(dataTypes),colnames(subdata))],subdata)
    reshapedData[[i]] = list(data=subdata[,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  }
  fits$onehotNfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "elsa_fi_Nfp_calc"

file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi_Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])

  fits$fi_Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "elsa_fi_onehot_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi_onehotNfp = readRDS(file)
} else
{
  subdata = OneHotVecOrdinal(data[[1]][,"Nfp_ord"],rootname="Nfp")
  NfpTypes = rep("binary",ncol(subdata))
  names(NfpTypes) = colnames(subdata)
  dataTypes = c(age="continuous",sex="binary",fi="continuous",NfpTypes)
  reshapedData = list()
  for (i in 1:length(data)) 
  {
    subdata = OneHotVecOrdinal(data[[i]][,"Nfp_ord"],rootname="Nfp")
    subdata = data.frame(data[[i]][,setdiff(names(dataTypes),colnames(subdata))],subdata)
    reshapedData[[i]] = list(data=subdata[,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  }
  fits$fi_onehotNfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "elsa_fi_Nfp_fpvar_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$all = readRDS(file)
} else
{
  fpTypes = rep("binary",length(fpVar))
  names(fpTypes)=fpVar
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous")
  dataTypes = c(dataTypes,fpTypes)
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])

  fits$all = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
scores = list()
for (i in 1:length(fits))
{
  scores[[i]] = fits[[i]]$score
  scores[[i]][,sprintf("%s_se",colnames(fits[[i]]$scoreSE))] = fits[[i]]$scoreSE
  scores[[i]][,"outcome"] = rownames(fits[[i]]$score)
  scores[[i]][,"model"] = names(fits)[i]
}
scores = do.call(rbind,scores)

scores[,"clean_name"] = gsub("age_sex","Covariates only (age and sex)",scores[,"model"])
scores[,"clean_name"] = gsub("all","All predictors",scores[,"clean_name"])
scores[,"clean_name"] = gsub("fi_Nfp","FI and NFab5",scores[,"clean_name"])
scores[scores[,"model"]=="fi_onehotNfp","clean_name"] = "FI and NFab5 (onehot encoded)"
scores[scores[,"model"]=="fi","clean_name"] = "FI"
scores[scores[,"model"]=="Nfp","clean_name"] = "NFab5"
scores[scores[,"model"]=="fifp","clean_name"] = "FI - including fab-5 varibles"
```

```{r}
plotdata = subset(scores,model%in%c("fi","Nfp","all","fi_Nfp","fifp","age_sex"))
plotdata[,"outcome"] = factor(plotdata[,"outcome"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"outcome"]))
g = ggplot(plotdata,aes(x=outcome,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,colour=clean_name,shape=clean_name))+
  geom_pointrange(position=position_dodge(.2))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```
```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/elsa_glm_auc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/elsa_glm_auc.png",outputDir),g,width=10,height=8,dpi=300)
}
```



make a table
should add survival too; maybe make its own table
```{r}
bestFit = fits[["fi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/elsa_glm.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/elsa_glm_v2.csv",outputDir),row.names=FALSE)
```

```{r}
bestFit = fits[["barefi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/elsa_glm_bare.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/elsa_glm_bare_v2.csv",outputDir),row.names=FALSE)
```



what if we use everything we know about the current health state? kitchen skin model
```{r}
baseName = "elsa_fi_fab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$sink = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$sink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "elsa_fi_barefab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$baresink = readRDS(file)
} else
{
  dataTypes = c(fi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$baresink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

sqrt better fits the linearity assumption but... really not practical for clinical use etc
```{r}
for (i in 1:length(data)) data[[i]][,"sqrtfi"] = sqrt(data[[i]][,"fi"])
baseName = "elsa_fi_fab5_sqrt_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$sqrtsink = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",sqrtfi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$sqrtsink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

kitchen sink tileplot
qualitative structure seems more important than quantitative
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()
Clow = list()
Chigh =  list()
for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  Clow[[k]] = C[[k]]
  Chigh[[k]] = C[[k]]
  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"])
        Clow[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]-errorScale*subFitSE[jj,"Coef"])
        Chigh[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]+errorScale*subFitSE[jj,"Coef"])
      }
    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
  Clow[[k]][,setdiff(vars,colnames(Clow[[k]]))] = NA
  Chigh[[k]][,setdiff(vars,colnames(Chigh[[k]]))] = NA
}
C = do.call(rbind,C)
Clow = do.call(rbind,Clow)
Chigh = do.call(rbind,Chigh)
Clow = Clow[sort.list(C[,"sort_column"]),]
Chigh = Chigh[sort.list(C[,"sort_column"]),]
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]
Clow = C[,setdiff(colnames(Clow),"sort_column")]
Chigh = Chigh[,setdiff(colnames(Chigh),"sort_column")]
#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]
  Clow = C[,setdiff(colnames(Clow),"fi.1")]
  Chigh = Chigh[,setdiff(colnames(Chigh),"fi.1")]
}

#sort columns
ord = rev(c(2:4,5:ncol(C),1))
C = C[,ord]
Clow = Clow[,ord]
Chigh = Chigh[,ord]

#scale AUC to %
#C[,"auc"] = C["auc"]*100
#Clow[,"auc"] = Clow["auc"]*100
#Chigh[,"auc"] = Chigh["auc"]*100

#scale AUC to 0-10
#C[,"auc"] = C["auc"]*10
#Clow[,"auc"] = Clow["auc"]*10
#Chigh[,"auc"] = Chigh["auc"]*10

#cover ugly x:
#Clow[is.na(C)] = 1-1/10^6
#Chigh[is.na(C)] = 1+1/10^6
#C[is.na(C)] = 1

#scale
vars = setdiff(colnames(C),"auc")
C[,vars] = log(C[,vars],10)
Clow[,vars] = log(Clow[,vars],10)
Chigh[,vars] = log(Chigh[,vars],10)

g = TilePlot(C,mcilow=Clow,mcihigh=Chigh,na.value="white",pointSize=8,dropNonSig = F)
#fix labels
nms = colnames(C)
nms = gsub("auc","AUC",nms)
#nms = gsub("auc","AUC (%)",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
for (j in 1:length(fpVar)) nms = gsub(fpVar[j],names(fpVar)[j],nms,fixed=T)
g = g + scale_y_discrete(breaks=colnames(C),labels=nms)
nms = rownames(C)
for (j in 1:2) nms = gsub(sprintf("next%d",j),"next",nms)
for (j in 1:length(fpVar)) nms = gsub(sprintf("%s_next",fpVar[j]),names(fpVar)[j],nms,fixed=T)
nms = gsub(sprintf("fp_frail_next"),"FP frailty",nms,fixed=T)
nms = sprintf("%d. %s",rep(1:3,times=length(nms)/3),nms)
g = g + scale_x_discrete(breaks=rownames(C),labels=nms)
#fix scale
labs = c("0.5","1","2","5","10")
g = g + scale_colour_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0, limit = c(-.3,1.3),
                               name="Odds Ratio", na.value="white",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=labs)
g = g + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                              space = "Lab", midpoint = 0, limit =  c(-.3,1.3),
                               name="Odds Ratio", na.value="white",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=c("0.5","1","2","5","10"))
g = g + theme(legend.title=element_text())
g = g + theme(text=element_text(size=gTextSize))

#fix font
g = g + theme(axis.text.x=element_text(size=18,angle=90),axis.text.y=element_text(size=18,angle=0))

#add x/y labels
g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=20),axis.title.y=element_text(size=20,angle=90))
#g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=16))

#add title
g = g + ggtitle("(b) ELSA") + theme(title =element_text(size=gTextSize))

#scale up key
g = g + theme(legend.key.width = unit(4,"line"))

#clean up background
g = g + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
g = g + theme(panel.background = element_rect(fill = 'grey90',colour=NA))

#separate AUC
g = g + geom_rect(xmin=-2.1,xmax=18.5,ymin=.5,ymax=1.5,color="grey40",fill=NA,size=1)+ coord_cartesian(clip = 'off') 
#g = g + geom_segment(x=-2,xend=18.5,y=1.5,yend=1.5,color="grey",fill=NA,size=1)+ coord_cartesian(clip = 'off') 

#add second legend for AUC
#strategy: make a second plot and stick it below current plot
library(cowplot)
#g2 =  TilePlot(log(C[,"auc",drop=F],10),mcilow=log(Clow[,"auc",drop=F],10),mcihigh=log(Chigh[,"auc",drop=F],10),na.value="grey90",pointSize=8,dropNonSig = T)
g2 =  TilePlot(C[,"auc",drop=F],mcilow=Clow[,"auc",drop=F],mcihigh=Chigh[,"auc",drop=F],na.value="grey90",pointSize=8,dropNonSig = T)
g2 = g2 + scale_colour_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0.5, limit = c(0.5,1),
                               name="AUC", na.value="white")
g2 = g2 + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0.5, limit = c(0.5,1),
                               name="AUC", na.value="white")
g2 = g2 + theme(legend.title=element_text()) + theme(text=element_text(size=gTextSize))+ theme(legend.key.width = unit(4,"line"))

#3 plots now
layout = matrix(1,2,2)
layout[1,] = 1
layout[2,] = 2:3

g3 = ggdraw(cowplot::get_legend(g))
g = g +theme(legend.position="none")

gl = list(g,ggdraw(cowplot::get_legend(g2)),g3)



g
save=T
if(save)
{
  #ggsave(sprintf("%s/results/fp_next_tileplot_elsa.pdf",outputDir),g,width=12,height=8,dpi=300)
  #ggsave(sprintf("%s/results/fp_next_tileplot_elsa.png",outputDir),g,width=12,height=8,dpi=300)
  
  #temp: for combining with HRS
  layout[2,] = 2
  gl = gl[c(1,2)]

  
  ggsave(sprintf("%s/results/fp_next_tileplot_elsa.pdf",outputDir),marrangeGrob(gl,nrow=2,ncol=2,layout_matrix=layout,top=NULL,heights=c(.9,.1)),width=12,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_next_tileplot_elsa.png",outputDir),marrangeGrob(gl,nrow=2,ncol=2,layout_matrix=layout,top=NULL,heights=c(.9,.1)),width=12,height=8,dpi=300)
}
```


tabular form
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()

for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  for (j in 1:length(sc)) C[[k]][,sc[j]] = sprintf("$%.3f_{%.3f}^{%.3f}$",theseFits[[k]][["score"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]-qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]+qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]])

  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      
          #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]),exp(subFit[jj,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[jj,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      }

    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
}
C = do.call(rbind,C)
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]

#drop OR
colnames(C) = gsub(" OR","",colnames(C))
#clean up names
nms = colnames(C)
nms = gsub("auc","AUC",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
for (j in 1:length(fpVar)) nms = gsub(fpVar[j],names(fpVar)[j],nms,fixed=T)
colnames(C) = nms

#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]

}

#add outcome column
C[,"Outcome"] = rownames(C)
C[grep("frail",C[,"Outcome"] ),"Outcome"]      = "FP frailty"
C[grep("weight",C[,"Outcome"] ),"Outcome"]     = "Weight loss"
C[grep("grip",C[,"Outcome"] ),"Outcome"]       = "Weakness"
C[grep("gait",C[,"Outcome"] ),"Outcome"]       = "Slow gait"
C[grep("exhaustion",C[,"Outcome"] ),"Outcome"] = "Exhaustion"
C[grep("activity",C[,"Outcome"] ),"Outcome"]   = "Low activity"

#sort columns
ord = c("Outcome",setdiff(colnames(C),"Outcome"))
C = C[,ord]

#drop NAs
C[is.na(C)] = ""


write.csv(C,sprintf("%s/results/fp_next_elsa.csv",outputDir),row.names=FALSE)
```


kitchen sink model
```{r}
bestFit = fits[["sink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 10
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else if("age"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 0.1
      C[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/elsa_glm_sink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/elsa_glm_sink_v2.csv",outputDir),row.names=FALSE)
C0 = C
C20 = C2
```

```{r}
bestFit = fits[["baresink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 10
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else if("age"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 0.1
      C[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/elsa_glm_baresink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/elsa_glm_baresink_v2.csv",outputDir),row.names=FALSE)


C2[,setdiff(colnames(C20),colnames(C2))]=""
C2 = C2[,colnames(C20)]
C3 = rbind(C2,C20)[rep(1:nrow(C2),each=2)+rep(c(0,nrow(C2)),times=nrow(C2)),]
for (j in 1:length(fpVar)) colnames(C3) = gsub(fpVar[j],names(fpVar)[j],colnames(C3),fixed=T)
write.csv(C3,sprintf("%s/results/elsa_glm_sink_combined.csv",outputDir),row.names=FALSE)
```

################
# How realistic is the logit assumption?
################

```{r}
w = data[[1]]
fi_cuts = seq(0,.5,by=.05)
#w[,"fi_cut"] = cut(w[,"fi"],fi_cuts,labels=fi_cuts[-1]/2+fi_cuts[-length(fi_cuts)]/2,include.lowest=T)
w[,"fi_cut"] = cut(w[,"fi"],fi_cuts,include.lowest=T)

agg = aggregate(w[,c("fi",fpNames)],by=list(fi_cut=w[,"fi_cut"]),mean,na.rm=T)
agg[,sprintf("%s_se",c("fi",fpNames))] = aggregate(w[,c("fi",fpNames)],by=list(fi_cut=w[,"fi_cut"]),SEM,na.rm=T)[,c("fi",fpNames)]
```

fi is fairly close to logit-linear, but sqrt(fi) is much better
```{r}
g = list()
for (j in 1:length(fpNames))
{
  agg[,"y"] = agg[,fpNames[j]]
  agg[,"se"] = agg[,sprintf("%s_se",fpNames[j])]
  g[[j]] = ggplot(agg,aes(x=fi,y=logit(y),ymin=logit(y-se),ymax=logit(y+se)))+geom_pointrange()+geom_smooth(method="lm")+ggtitle(fpNames[j])
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)
```

```{r}
g = list()
for (j in 1:length(fpNames))
{
  agg[,"y"] = agg[,fpNames[j]]
  agg[,"se"] = agg[,sprintf("%s_se",fpNames[j])]
  g[[j]] = ggplot(agg,aes(x=sqrt(fi),y=logit(y),ymin=logit(y-se),ymax=logit(y+se)))+geom_pointrange()+geom_smooth(method="lm")+ggtitle(fpNames[j])
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)
```


################
# Predicting future Nfp
################

```{r}
gLoad=F
warning("temp")
```
#train a bunch of models

### FI as sole predictor

Models: 1: RF, 2: gam, 3: polr
```{r}
file = sprintf("%s/data/train_nfp_fi_elsa.rds",outputDir)
load=T
save=T
Nreps = 10
Nfolds = 10
rfGrid = expand.grid(mtry=1)
if(file.exists(file) & load)
{
  print("file found, loading...")
  accFI = readRDS(file)
} else
{
  print("file not found, computing...")
  mat = list()
  matSE = list()
  pred = list() #expected class
  predSE = list()
  predCl = list() #predicted class
  newdata = data.frame(fi=seq(0,1,length=101))
  for (i in 1:length(data))
  {
    pred[[i]] = newdata
    predCl[[i]] = newdata
    predSE[[i]] = newdata*0
    #thisData = data[[i]][sample(1:nrow(data[[i]]),100),] #for debugging, take small sample
    thisData = data[[i]]
    thisData[,"Nfp_next_ord"] = ordered(thisData[,"Nfp_next_ord"]) #drop any empty factors
    
    weights = rep(1,nrow(thisData))
    for (j in 0:5) weights[thisData[,"Nfp_next"]==j] = 1/mean(thisData[,"Nfp_next"]==j,na.rm=T)

    fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = Nfolds,
                           repeats = Nreps,
                           summaryFunction = SummaryNfp
                           )
    l = list()
    l$rf =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                 tuneGrid = rfGrid)
    l$rf$results[,"model"] = 1
    l$rf$results[,"weighted"] = F
    l$rf$pred = ExpectationPr(predict(l$rf,newdata=newdata,type="prob"))
  
    #l$mars =  train(Nfp_next ~ fi, data = thisData, 
    #             method = c("earth"), 
    #             trControl = fitControl
    #             )
    #l$mars$results[,"model"] = 2
    #l$mars$results[,"weighted"] = F
    #pr = predict(l$mars,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    #cl = pr
    #cl[cl < 0] = 0
    #cl[cl > 5] = 5
    #l$mars$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    #rm(pr)
  
    l$gam =  train(Nfp_next ~ fi, data = thisData, 
                 method = c("gam"), 
                 trControl = fitControl
                 )
    l$gam$results[,"model"] = 2
    l$gam$results[,"weighted"] = F
    pr = predict(l$gam,newdata=newdata)[,1] 
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$gam$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
      

    l$polr =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("polr"), 
                 trControl = fitControl)
    l$polr$results[,"model"] = 3
    l$polr$results[,"weighted"] = F
    l$polr$pred = ExpectationPr(predict(l$polr,newdata=newdata,type="prob"))
  
    l$rfW =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6),
                tuneGrid = rfGrid)
    l$rfW$results[,"model"] = 1
    l$rfW$results[,"weighted"] = T
    l$rfW$pred = ExpectationPr(predict(l$rfW,newdata=newdata,type="prob")) 
      
    l$marsW =  train(Nfp_next ~ fi, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
    l$marsW$results[,"model"] = 2
    l$marsW$results[,"weighted"] = T
    pr = predict(l$marsW,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$marsW$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
  
    l$polrW =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
    l$polrW$results[,"model"] = 3
    l$polrW$results[,"weighted"] = T
    l$polrW$pred = ExpectationPr(predict(l$polrW,newdata=newdata,type="prob"))
     
    #label best-performing hyperparameters
      #makes plotting easier
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
      results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
      results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
      l[[j]]$results = results
    }
  
    uncols = character()
    for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
    uncols = unique(uncols)
    #fill in empty columns (tune paramters)
    lres = list()
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,setdiff(uncols,colnames(results))] = NA
      rest = setdiff(colnames(results),c("model","weighted"))
      lres[[j]] = results[,c("model","weighted",rest)]
      lres[[j]][,"method"] = as.numeric(factor(lres[[j]][,"method"]))
      rm(rest)
      
      #add predictions
      pred[[i]][,names(l)[j]] = l[[j]]$pred[,c("Epr")]
      predCl[[i]][,names(l)[j]] = l[[j]]$pred[,c("class")]
      predSE[[i]][,names(l)[j]] = l[[j]]$pred[,c("sd")]
    }
  
    mat[[i]] = do.call(rbind,lres)
    seCols = colnames(mat[[i]])[grep("SD",colnames(mat[[i]]))]
    metCols = seCols
    for (jj in 1:length(metCols)) metCols[jj] = strsplit(metCols[jj],"SD",fixed=T)[[1]][1]
    sharedCols = setdiff(colnames(mat[[i]]),c(seCols,metCols))
    matSE[[i]] = mat[[i]][,c(sharedCols,seCols)]
    matSE[[i]] = as.matrix(matSE[[i]])
    mat[[i]] = mat[[i]][,c(sharedCols,metCols)] 
    mat[[i]] = as.matrix(mat[[i]])
    colnames(matSE[[i]]) = colnames(mat[[i]])

    pred[[i]] = as.matrix(pred[[i]])
    predCl[[i]] = as.matrix(predCl[[i]])
    predSE[[i]] = as.matrix(predSE[[i]])
    colnames(predSE[[i]]) = colnames(pred[[i]])
    rm(l)
  }
  
  acc = RubinMat(mat,lse=matSE)
  for (i in 1:length(acc))
  {
    acc[[i]] = data.frame(acc[[i]])
    acc[[i]][,"metrics"] = "fi"
    acc[[i]][,"outcome"] = "Nfp"
  }
  pred = RubinMat(pred,lse=predSE)
  for (i in 1:length(pred)) pred[[i]] = data.frame(pred[[i]])
  predCl = RubinMat(predCl)  
  for (i in 1:length(predCl)) predCl[[i]] = data.frame(predCl[[i]])
  
  if(save)
  {
    saveRDS(list(acc=acc,pred=pred,predCl=predCl,results=results),file)
  }
  
  
}
```

```{r}
plotdata = subset(accFI,best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
file = sprintf("%s/data/train_nfp_nfp_elsa.rds",outputDir)
load=T
save=T
Nreps = 10
Nfolds = 10
rfGrid = expand.grid(mtry=1)
if(file.exists(file) & load)
{
  print("file found, loading...")
  accFI = readRDS(file)
} else
{
  print("file not found, computing...")
  mat = list()
  matSE = list()
  pred = list() #expected class
  predSE = list()
  predCl = list() #predicted class
  newdata = data.frame(Nfp=seq(0,5,length=101))
  for (i in 1) #:length(data))
  {
    pred[[i]] = newdata
    predCl[[i]] = newdata
    predSE[[i]] = newdata*0
    #thisData = data[[i]][sample(1:nrow(data[[i]]),100),] #for debugging, take small sample
    thisData = data[[i]]
    thisData[,"Nfp_next_ord"] = ordered(thisData[,"Nfp_next_ord"]) #drop any empty factors
    thisData[,"Nfp_ord"] = ordered(thisData[,"Nfp_ord"]) #drop any empty factors
    
    #encode with onehot for polr
    ordData = as.data.frame(OneHotVecOrdinal(thisData[,"Nfp_ord"]))
    ordData[,"Nfp_next_ord"] = data[,"Nfp_next_ord"]
    
    weights = rep(1,nrow(thisData))
    for (j in 0:5) weights[thisData[,"Nfp_next"]==j] = 1/mean(thisData[,"Nfp_next"]==j,na.rm=T)

    fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = Nfolds,
                           repeats = Nreps,
                           summaryFunction = SummaryNfp
                           )
    l = list()
    l$rf =  train(Nfp_next_ord ~ Nfp_ord, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                 tuneGrid = rfGrid)
    l$rf$results[,"model"] = 1
    l$rf$results[,"weighted"] = F
    l$rf$pred = ExpectationPr(predict(l$rf,newdata=newdata,type="prob"))
  
    l$mars =  train(Nfp_next ~ Nfp, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl
                 )
    l$mars$results[,"model"] = 2
    l$mars$results[,"weighted"] = F
    pr = predict(l$mars,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$mars$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
    l$polr =  train(Nfp_next_ord ~ ., data = ordData,
                 method = c("polr"), 
                 trControl = fitControl)
    l$polr$results[,"model"] = 3
    l$polr$results[,"weighted"] = F
    l$polr$pred = ExpectationPr(predict(l$polr,newdata=newdata,type="prob"))
  
    l$rfW =  train(Nfp_next_ord ~ Nfp_ord, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6),
                tuneGrid = rfGrid)
    l$rfW$results[,"model"] = 1
    l$rfW$results[,"weighted"] = T
    l$rfW$pred = ExpectationPr(predict(l$rfW,newdata=newdata,type="prob")) 
      
    l$marsW =  train(Nfp_next ~ Nfp, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
    l$marsW$results[,"model"] = 2
    l$marsW$results[,"weighted"] = T
    pr = predict(l$marsW,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$marsW$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
  
    l$polrW =  train(Nfp_next_ord ~ ., data = ordData,
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
    l$polrW$results[,"model"] = 3
    l$polrW$results[,"weighted"] = T
    l$polrW$pred = ExpectationPr(predict(l$polrW,newdata=newdata,type="prob"))
     
    #label best-performing hyperparameters
      #makes plotting easier
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
      results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
      results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
      l[[j]]$results = results
    }
  
    uncols = character()
    for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
    uncols = unique(uncols)
    #fill in empty columns (tune paramters)
    lres = list()
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,setdiff(uncols,colnames(results))] = NA
      rest = setdiff(colnames(results),c("model","weighted"))
      lres[[j]] = results[,c("model","weighted",rest)]
      lres[[j]][,"method"] = as.numeric(factor(lres[[j]][,"method"]))
      rm(rest)
      
      #add predictions
      pred[[i]][,names(l)[j]] = l[[j]]$pred[,c("Epr")]
      predCl[[i]][,names(l)[j]] = l[[j]]$pred[,c("class")]
      predSE[[i]][,names(l)[j]] = l[[j]]$pred[,c("sd")]
    }
  
    mat[[i]] = do.call(rbind,lres)
    seCols = colnames(mat[[i]])[grep("SD",colnames(mat[[i]]))]
    metCols = seCols
    for (jj in 1:length(metCols)) metCols[jj] = strsplit(metCols[jj],"SD",fixed=T)[[1]][1]
    sharedCols = setdiff(colnames(mat[[i]]),c(seCols,metCols))
    matSE[[i]] = mat[[i]][,c(sharedCols,seCols)]
    matSE[[i]] = as.matrix(matSE[[i]])
    mat[[i]] = mat[[i]][,c(sharedCols,metCols)] 
    mat[[i]] = as.matrix(mat[[i]])
    colnames(matSE[[i]]) = colnames(mat[[i]])

    pred[[i]] = as.matrix(pred[[i]])
    predCl[[i]] = as.matrix(predCl[[i]])
    predSE[[i]] = as.matrix(predSE[[i]])
    colnames(predSE[[i]]) = colnames(pred[[i]])
    rm(l)
  }
  
  acc = RubinMat(mat,lse=matSE)
  for (i in 1:length(acc))
  {
    acc[[i]] = data.frame(acc[[i]])
    acc[[i]][,"metrics"] = "fi"
    acc[[i]][,"outcome"] = "Nfp"
  }
  pred = RubinMat(pred,lse=predSE)
  for (i in 1:length(pred)) pred[[i]] = data.frame(pred[[i]])
  predCl = RubinMat(predCl)  
  for (i in 1:length(predCl)) predCl[[i]] = data.frame(predCl[[i]])
  
  if(save)
  {
    saveRDS(list(acc=acc,pred=pred,predCl=predCl,results=results),file)
  }
  
  
}
```

### Nfp as sole predictor

```{r}
file = sprintf("%s/data/train_nfp_nfp.rds",outputDir)
load=T
save=T
if(file.exists(file) & load)
{
  print("file found, loading...")
  lFP = readRDS(file)
  accFP = lFP$acc
} else
{
  print("file not found, computing...")
  
  weights = rep(1,nrow(data))
  for (j in 0:5) weights[data[,"Nfp_next"]==j] = 1/mean(data[,"Nfp_next"]==j,na.rm=T)

  #encode with onehot for polr
  ordData = as.data.frame(OneHotVecOrdinal(data[,"Nfp_ord"]))
  ordData[,"Nfp_next_ord"] = data[,"Nfp_next_ord"]
  
  fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           summaryFunction = SummaryNfp
                           )
  l = list()
  l$rf =  train(Nfp_next_ord ~ Nfp_ord, data = data, 
                 method = c("rf"), 
                 trControl = fitControl)
  l$rf$results[,"model"] = "rf"
  l$rf$results[,"weighted"] = F
  
  l$mars =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("earth"), 
                 trControl = fitControl
                 )
  l$mars$results[,"model"] = "mars"
  l$mars$results[,"weighted"] = F
  
  l$lo =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("gamLoess"), 
                 trControl = fitControl)
  l$lo$results[,"model"] = "loess"
  l$lo$results[,"weighted"] = F
  
  l$polr =  train(Nfp_next_ord ~ ., data = ordData, 
                 method = c("polr"), 
                 trControl = fitControl)
  l$polr$results[,"model"] = "polr"
  l$polr$results[,"weighted"] = F
  
  l$rfW =  train(Nfp_next_ord ~ Nfp_ord, data = data, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6))
  l$rfW$results[,"model"] = "rf"
  l$rfW$results[,"weighted"] = T

  l$marsW =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
  l$marsW$results[,"model"] = "mars"
  l$marsW$results[,"weighted"] = T
  
  l$loW =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("gamLoess"), 
                 trControl = fitControl,
                 weights=weights)
  l$loW$results[,"model"] = "loess"
  l$loW$results[,"weighted"] = T
  
  l$polrW =  train(Nfp_next_ord ~ ., data = ordData, 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
  l$polrW$results[,"model"] = "polr"
  l$polrW$results[,"weighted"] = T

  
  #label best-performing hyperparameters
    #makes plotting easier
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
    results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
    results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
    l[[j]]$results = results
  }
  
  uncols = character()
  for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
  uncols = unique(uncols)
  #fill in empty columns (tune paramters)
  lres = list()
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,setdiff(uncols,colnames(results))] = NA
    rest = setdiff(colnames(results),c("model","metrics","weighted"))
    lres[[j]] = results
    rm(rest)
  }
  
  accFP = do.call(rbind,lres)
  
  accFP[,"metrics"] = "Nfp"
  accFP[,"outcome"] = "Nfp"
  
  #rearrange
  rest = setdiff(colnames(accFP),c("outcome","model","metrics","weighted"))
  accFP = accFP[,c("outcome","model","metrics","weighted",rest)]
  
  if(save)
  {
    saveRDS(list(acc=accFP,l=l),file)
  }
}
```

```{r}
plotdata = subset(accFP,best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
plotdata = subset(rbind(accFI[,cols],accFP[,cols]),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```


### Using all of the binary FP vars aspredictors

```{r}
file = sprintf("%s/data/train_nfp_fpvar.rds",outputDir)
load=T
save=T
if(file.exists(file) & load)
{
  print("file found, loading...")
  lFPVar = readRDS(file)
  accFPVar = lFPVar$acc
} else
{
  print("file not found, computing...")
  
  weights = rep(1,nrow(data))
  for (j in 0:5) weights[data[,"Nfp_next"]==j] = 1/mean(data[,"Nfp_next"]==j,na.rm=T)

  fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           summaryFunction = SummaryNfp
                           )
  l = list()
  l$rf =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("rf"), 
                 trControl = fitControl)
  l$rf$results[,"model"] = "rf"
  l$rf$results[,"weighted"] = F
  
  l$mars =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("earth"), 
                 trControl = fitControl
                 )
  l$mars$results[,"model"] = "mars"
  l$mars$results[,"weighted"] = F
  
  l$lo =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("gamLoess"), 
                 trControl = fitControl)
  l$lo$results[,"model"] = "loess"
  l$lo$results[,"weighted"] = F
  
  l$polr =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("polr"), 
                 trControl = fitControl)
  l$polr$results[,"model"] = "polr"
  l$polr$results[,"weighted"] = F
  
  l$rfW =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6))
  l$rfW$results[,"model"] = "rf"
  l$rfW$results[,"weighted"] = T

  l$marsW =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
  l$marsW$results[,"model"] = "mars"
  l$marsW$results[,"weighted"] = T
  
  l$loW =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("gamLoess"), 
                 trControl = fitControl,
                 weights=weights)
  l$loW$results[,"model"] = "loess"
  l$loW$results[,"weighted"] = T
  
  l$polrW =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
  l$polrW$results[,"model"] = "polr"
  l$polrW$results[,"weighted"] = T

  
  #label best-performing hyperparameters
    #makes plotting easier
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
    results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
    results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
    l[[j]]$results = results
  }
  
  uncols = character()
  for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
  uncols = unique(uncols)
  #fill in empty columns (tune paramters)
  lres = list()
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,setdiff(uncols,colnames(results))] = NA
    lres[[j]] = results
    rm(rest)
  }
  
  acc = do.call(rbind,lres)
  
  acc[,"metrics"] = "fpVar"
  acc[,"outcome"] = "Nfp"
  
  #rearrange
  rest = setdiff(colnames(acc),c("outcome","model","metrics","weighted"))
  accFPVar = acc[,c("outcome","model","metrics","weighted",rest)]
  
  if(save)
  {
    saveRDS(list(acc=accFPVar,l=l),file)
  }
}
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=F),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(accFPVar[sort.list(accFPVar[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(subset(plotdata,weighted),aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=metrics))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_rmse)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"RMSE"],decreasing=F),"model"]))
g = ggplot(plotdata,aes(x=model,y=RMSE,ymin=RMSE-RMSESD,ymax=RMSE+RMSESD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

# AUC - prediction - frailty

How well does FI predict frailty in the CURRENT wave? - AUC

```{r}
library(pROC)
fp = c(data[,"fp_frail"],data[,"fp_frail_next"])
fi = c(data[,"fi"],data[,"fi_next"])
r = roc(fp~fi,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the CURRENT wave? Should be perfect

```{r}
fp = c(data[,"fp_frail"],data[,"fp_frail_next"])
Nfp = c(data[,"Nfp"],data[,"Nfp_next"])
r = roc(fp~Nfp,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

# AUC - prognostication - frailty

How well does FI predict frailty in the next wave? - AUC

```{r}
library(pROC)
r = roc(data[,"fp_frail_next"]~data[,"fi"],ci.method="boot")
rfi = r
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the next wave?

```{r}
r = roc(data[,"fp_frail_next"]~data[,"Nfp"],ci.method="boot")
rfp = r
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```
```{r}
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
legend("topleft",c("FI","NFP"),col=1:2,lty=1:2)
```

# AUC - prediction - pre-frail or worse

How well does FI predict frailty in the CURRENT wave? - AUC

```{r}
library(pROC)
Nfp = c(data[,"Nfp"],data[,"Nfp"])
fi = c(data[,"fi"],data[,"fi_next"])
r = roc(I(Nfp>0)~fi,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

# AUC - prognostication - pre-frail or worse

How well does FI predict frailty in the next wave? - AUC

```{r}
library(pROC)
r = roc(I(Nfp_next > 0)~fi,data,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the next wave?

```{r}
r = roc(I(Nfp_next > 0)~Nfp,data,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```
# POLR
```{r}
library(MASS)
data[,"Nfp_next_ord"] = ordered(data[,"Nfp_next"],0:5)
m = polr(Nfp_next_ord~fi,data)
pr = predict(m,data)
C = xtabs(~data[,'Nfp_next']+pr)
print(sprintf("Accuracy: %.2f",sum(diag(C))/sum(C)))

pr = as.numeric(as.character(pr))
cor(data[,'Nfp_next'],pr,use='pairwise.complete')
ggplot(data.frame(Nfp=data[,'Nfp_next'],pr=pr),aes(x=Nfp,y=pr))+geom_jitter(width=.1,height=.1)
```

```{r}
data[,"Nfp_next_ord"] = ordered(data[,"Nfp_next"],0:5)
m = polr(Nfp_next_ord~.,data[,c("Nfp_next_ord",fpVar)])
pr = predict(m,data)
C = xtabs(~data[,'Nfp_next']+pr)
print(sprintf("Accuracy: %.2f",sum(diag(C))/sum(C)))

pr = as.numeric(as.character(pr))
cor(data[,'Nfp_next'],pr,use='pairwise.complete')
ggplot(data.frame(Nfp=data[,'Nfp_next'],pr=pr),aes(x=Nfp,y=pr))+geom_jitter(width=.1,height=.1)
```

# GLM
```{r}
prevalenceRatio = mean(1-data[,"fp_frail_next"],na.rm=T)/mean(data[,"fp_frail_next"]) #odds ratio?
weights = rep(1,nrow(data))
weights[data[,"fp_frail_next"] > 0.01] = ratio
m = glm(fp_frail_next~fi,data,family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

```{r}
m = glm(fp_frail_next~.,data[,c("fp_frail_next",fpVar)],family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

```{r}
m = glm(fp_frail_next~Nfp,data,family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

# Damage and repair
```{r}
data[,"dfp"] = data[,"Nfp_next"] - data[,"Nfp"]
print(table(data[,"dfp"]))
data[,"damage"] = 1*(data[,"dfp"] > 0)
data[,"repair"] = 1*(data[,"dfp"] < 0)
data[,"dfp_trinary"] = data[,"dfp"]
data[data[,"dfp"] < 0,"dfp_trinary"] = -1
data[data[,"dfp"] > 0,"dfp_trinary"] = 1
```

Damage seems to be the most important thing to predict.

Nfp clearly better than FI. Although both are quite poor.
Probably need to do this conditionally 1 by 1
```{r}
rfi = roc(damage~fi,data)
rfi_next = roc(damage~fi_next,data)
#rfi_next = roc(damage~I(fi*length(fiVar)+Nfp),data) #~FI with FP variables included #doesn't help
rfp = roc(damage~Nfp,data)
print(auc(rfi))
print(auc(rfp))
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
lines(rfi_next,col=3,lty=3)
legend("topleft",c("FI","NFP","FI next"),col=1:3,lty=1:3)
```

```{r}
rfi = roc(repair~fi,data)
rfp = roc(repair~Nfp,data)
print(auc(rfi))
print(auc(rfp))
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
legend("topleft",c("FI","NFP"),col=1:2,lty=1:2)
```

#GLM - Damage

```{r}
prevalenceRatio = mean(1-data[,"damage"],na.rm=T)/mean(data[,"damage"]) #odds ratio?
weights = rep(1,nrow(data))
weights[data[,"damage"] > 0.01] = ratio
m = glm(damage~fi,data,family="binomial",weights=weights)
C = xtabs(~data[,'damage']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

# Random Forest - should use cross-validation for more precise estimate

How well does FI predict frailty in the next wave? - Random Forest

Problem seems to be that RF doesn't like continuous variables, wants to make too many cuts.

```{r}
library(randomForest)
classwt = c(1,1)
#classwt = 1/c(mean(data[,"fp_frail_next"],na.rm=T),mean(1-data[,"fp_frail_next"],na.rm=T)) #not right
rf = randomForest(factor(fp_frail_next,c(0,1))~fi,data,classwt=classwt)
#rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt) #does way better
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
classwt = c(1,1)
rf = randomForest(factor(fp_frail_next,c(0,1))~.,data[,c("fp_frail_next",fpVar)],classwt=classwt)
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
classwt = c(1,1)
rf = randomForest(factor(fp_frail_next,c(0,1))~Nfp,data,classwt=classwt)
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```

FI + FP
```{r}
classwt = c(1,1)
#classwt = 1/c(mean(data[,"fp_frail_next"],na.rm=T),mean(1-data[,"fp_frail_next"],na.rm=T)) #not right
rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt)
#rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt) #does way better
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```

# Random Forest - multiple classes

How well does FI predict frailty in the next wave? - Random Forest
Looks like it has too much flexibility, wants to put multiple cuts instead of just one

```{r}
library(randomForest)
classwt = c(1,1,1)
print(table(data[,"fpclass_next"]))
rf = randomForest(fpclass_next~fi,data,classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2])) #assess is for only 2x2
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
rf = randomForest(fpclass_next~.,data[,c(fpVar,"fpclass_next")],classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2]))
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
rf = randomForest(fpclass_next~Nfp,data,classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2]))
```
# Random Forest - regression for Nfp

How well does FI predict frailty in the next wave? - Random Forest
Looks like it has too much flexibility, wants to put multiple cuts instead of just one

```{r}
library(randomForest)
rf = randomForest(Nfp_next~fi,data)
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.01)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
rf = randomForest(Nfp_next~.,data[,c(fpVar,"Nfp_next")])
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.01)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
rf = randomForest(Nfp_next~Nfp,data)
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.05)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```

##########################
# Old code from fi_vs_fp.Rmd
#######################

```{r}
logi = apply(!is.na(fp),1,all)
fp = fp[logi,]
predictors = predictors[logi,]
covariates = covariates[logi,]
outcomes = outcomes[logi,]
nhanes = nhanes[logi,]
s = s[logi,]
print(sprintf("Cutting %d individuals due to missingness (/%d)",sum(!logi),length(logi)))
```

```{r}
fpVar = c("BMXBMI","MSXW20TM","PFQ060E","PFQ060H","PAQ520")
names(fpVar) = c("Low BMI","Slow gait","Weakness","Exhaustion","Low activity")

varTypes=readRDS(sprintf("%s/data/varTypes.rds",outputDir))

fiVar=subset(varTypes,fiVar)[,"var"]
fiVar = setdiff(fiVar,fpVar) #remove all fp variables from FI

labVar=subset(varTypes,labVar)[,"var"]
labVar = setdiff(labVar,fpVar) #remove all fp variables from FI

clinicVar=subset(varTypes,clinicVar)[,"var"]
clinicVar = setdiff(clinicVar,fpVar) #remove all fp variables from FI

```


```{r}
fi = apply(predictors[,fiVar],1,mean,na.rm=T)
data = data.frame(fi=fi)
data[,"filab"] = apply(predictors[,labVar],1,mean,na.rm=T)
data[,"ficlinic"] = apply(predictors[,clinicVar],1,mean,na.rm=T)
```

Demographic stuff
```{r}
demo = data.frame(variable=names(fpVar))
for (i in 1:length(fpVar)) demo[i,"frequency/mean"] = mean(fp[,fpVar[i]])
demo[nrow(demo)+1,"variable"] = "sex"
demo[nrow(demo),"frequency/mean"] = mean(covariates[,"RIAGENDR"])
demo[nrow(demo)+1,"variable"] = "age"
demo[nrow(demo),"frequency/mean"] = mean(covariates[,"RIDAGEYR"])
demo[nrow(demo)+1,"variable"] = "FI"
demo[nrow(demo),"frequency/mean"] = mean(fi)
demo[nrow(demo)+1,"variable"] = "FP"
demo[nrow(demo),"frequency/mean"] = mean(apply(fp,1,sum,na.rm=T) >= 3)

demo = demo[c(6:9,1:5),]
demo

save=T
if(save)
{
  write.csv(demo,sprintf("%s/data/demographics_elsa.csv",outputDir),row.names = F)
}
```

```{r}
plotdata = data.frame(Age=nhanes[,"RIDAGEYR"],Gen=nhanes[,"RIAGENDR"],FI=fi)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
ggplot(plotdata,aes(x=Age,y=FI,colour=Sex,shape=Sex))+
  geom_point(position=position_jitter(.05))+
  #scale_y_continuous(trans="log10")+
  geom_smooth()+
  theme_minimal()
```

```{r}
plotdata = data.frame(Age=nhanes[,"RIDAGEYR"],Gen=nhanes[,"RIAGENDR"],FP=apply(fp,1,mean,na.rm=T)*5)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
ggplot(plotdata,aes(x=Age,y=FP,colour=Sex,shape=Sex))+
  geom_point(position=position_jitter(.05))+
  #scale_y_continuous(trans="log10")+
  geom_smooth()+
  theme_minimal()
```

```{r}
plotdata = rbind(data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=fi,method="FI",age=outcomes[,"RIDAGEYR"]),
          data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=apply(fp,1,mean,na.rm=T),method="FP",age=outcomes[,"RIDAGEYR"])
          )

g = ggplot(plotdata,aes(x=age,y=y,colour=method,fill=method,shape=method))+
  geom_point(position=position_jitter(0),alpha=.1)+
  labs(x="Age",y="Frailty Score")+
  #scale_y_continuous(trans="log10")+
  #scale_y_continuous(limits=c(0,.5))+
  #geom_smooth(method="gam",formula=y~s(x,k=10))+
  #geom_smooth(method="gam")+
  geom_smooth()+ #loess
  #geom_smooth(method="lm",formula=y~x+I(x^2)+I(x^3))+
  theme_minimal()+
  theme(legend.position=c(.2,.8),legend.title=element_blank())
g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/age.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/age.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],fi=fi,fp=apply(fp,1,mean,na.rm=T))
g =ggplot(plotdata,aes(x=fi,y=fp))+
  geom_point(position=position_jitter(.1))+
  geom_smooth(method="gam")+
  labs(x="FI",y="FP score (/5)")+
  theme_minimal()
g
print(cor(fi,apply(fp,1,mean,na.rm=T),use='pairwise.complete',method="spearman"))
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/fp_vs_fi.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_vs_fi.png",outputDir),g,width=10,height=8,dpi=300)
}
```


```{r}
plotdata = rbind(data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=fi,method="FI"),
          data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=apply(fp,1,mean,na.rm=T),method="FP")
          )
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
plotdata = subset(plotdata,Outcome=="Died") #everybody was followed for at least 10 years
g = ggplot(plotdata,aes(x=ttd,y=y,colour=method,fill=method,shape=method))+
  geom_point(position=position_jitter(0),alpha=.1)+
  labs(x="Time-to-death",y="Frailty Score")+
  #scale_y_continuous(trans="log10")+
  #scale_y_continuous(limits=c(0,.5))+
  scale_x_reverse()+
  #geom_smooth(method="gam",formula=y~s(x,k=10))+
  #geom_smooth(method="gam")+
  geom_smooth()+ #loess
  #geom_smooth(method="lm",formula=y~x+I(x^2)+I(x^3))+
  theme_minimal()+
  theme(legend.position=c(.2,.8),legend.title=element_blank())
g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/ttd.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/ttd.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
library(mgcv)
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],fi=fi,fp=apply(fp,1,mean,na.rm=T),age=outcomes[,"RIDAGEYR"])
#m = gam(ttd~te(fi,age),data=plotdata)
#m = gam(ttd~s(fi),data=plotdata)
m = gam(ttd~s(fi,k=5),data=plotdata)
#m = gam(ttd~s(fi,k=10),data=plotdata)
#m = gam(ttd~s(fi,knots=seq(0,1,length=10)),data=plotdata)

testdata = data.frame(ttd=NA,age=rep(70,times=100),fi=seq(0,1,length=100))
pr = predict(m,newdata=testdata,se.fit=T)
testdata[,"pr"] = pr$fit
testdata[,"prse"] = pr$se.fit
testdata[,"method"] = "FI"


m = gam(ttd~s(fp,k=5),data=plotdata)
#m = gam(ttd~s(fp,k=10),data=plotdata)
testdata2 = data.frame(ttd=NA,age=rep(70,times=100),fp=seq(0,1,length=100))
pr = predict(m,newdata=testdata2,se.fit=T)
testdata2[,"pr"] = pr$fit
testdata2[,"prse"] = pr$se.fit
testdata2[,"method"] = "FP"

colnames(testdata)[3] = "y"
colnames(testdata2)[3] = "y"
testdata = rbind(testdata,testdata2)

g = ggplot(testdata,aes(x=y,y=pr,ymin=pr-prse,ymax=pr+prse,colour=method,shape=method,fill=method))+
  geom_line()+
  geom_ribbon(alpha=.2)+
  scale_y_reverse()+
  geom_hline(yintercept=0,lty=3)+
  labs(y="Time-to-death (prediction)",x="FI")+
  theme_minimal()+
  theme(legend.position=c(.2,.8),legend.title=element_blank())
g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/ttd_models.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/ttd_models.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
plotdata = rbind(data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=fi,method="FI"),
          data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],y=apply(fp,1,mean,na.rm=T),method="FP")
          )
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
plotdata = subset(plotdata,Outcome=="Died") #everybody was followed for at least 10 years

agg = aggregate(plotdata[,c("y","ttd")],by=list(method=plotdata[,"method"]),mean,na.rm=T)
aggsd = aggregate(plotdata[,c("y","ttd")],by=list(method=plotdata[,"method"]),sd,na.rm=T)
agg[,"ysd"] = aggsd[,"y"]
agg[,"ttdsd"] = aggsd[,"ttd"]

ggplot(agg,aes(x=ttd,y=y,colour=method))+
  geom_line()+
  labs(x="Time-to-death")+
  #scale_y_continuous(trans="log10")+
  scale_x_reverse()+
  theme_minimal()
```

```{r}
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],FI=fi)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
ggplot(plotdata,aes(x=ttd,y=FI,colour=Outcome,shape=Outcome))+
  geom_point(position=position_jitter(.05))+
  labs(x="Time-to-death")+
  #scale_y_continuous(trans="log10")+
  scale_x_reverse()+
  geom_smooth()+
  theme_minimal()
```

```{r}
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],FI=fi,age=outcomes[,"RIDAGEYR"])
plotdata[,"ageq"] = cut(outcomes[,"RIDAGEYR"],c(0,60,70,80,Inf),include.lowest=T)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
ggplot(plotdata,aes(x=ttd,y=FI,colour=ageq,shape=Outcome))+
  geom_point(position=position_jitter(.05))+
  labs(x="Time-to-death")+
  #scale_y_continuous(trans="log10")+
  scale_x_reverse()+
  geom_smooth()+
  theme_minimal()
```

```{r}
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],FP=apply(fp,1,mean,na.rm=T)*5)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
ggplot(plotdata,aes(x=ttd,y=FP,colour=Outcome,shape=Outcome))+
  geom_point(position=position_jitter(.05))+
  labs(x="Time-to-death")+
  #scale_y_continuous(trans="log10")+
  scale_x_reverse()+
  geom_smooth()+
  theme_minimal()
```

```{r}
plotdata = data.frame(ttd=s[,"stop"]-outcomes[,"RIDAGEYR"],status=s[,"status"],Gen=nhanes[,"RIAGENDR"],FP=apply(fp,1,mean,na.rm=T)*5)
plotdata[,"Sex"] = "U"
plotdata[plotdata[,"Gen"]==0,"Sex"] = "M"
plotdata[plotdata[,"Gen"]==1,"Sex"] = "F"
plotdata[,"Outcome"] = "Unknown"
plotdata[plotdata[,"status"]==0,"Outcome"] = "Censored"
plotdata[plotdata[,"status"]==1,"Outcome"] = "Died"
plotdata[,"FP"] = ordered(plotdata[,"FP"])
ggplot(plotdata,aes(y=ttd,x=FP,colour=Outcome,shape=Outcome))+
  geom_boxplot()+
  labs(y="Time-to-death")+
  #scale_y_continuous(trans="log10")+
  theme_minimal()
```


Predict FP variables using FP variables vs FI(s)

```{r}
file = sprintf("%s/data/accuracy.rds",outputDir)
load=T
save=T
if(file.exists(file))
{
  print("file found, loading...")
  acc = readRDS(file)
} else
{
  print("file not found, computing...")
types = rep("binary",ncol(fp))
names(types)=colnames(fp)
fit = Calc(data,fp,covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
accfi = cbind(fit$score,fit$scoreSE)
accfi[,"outcome"] = rownames(fit$score)
accfi[,"feature"] = "fis"
accfi[,"covariates"] = "none"
accfi[,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
accfi[,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
accfi[,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")
#accfi[,sprintf("selection_rate_%s",colnames(fit$featuresUsed))] = c(fit$featuresUsed[1,])
#accfi[,sprintf("selection_rate_%s_se",colnames(fit$featuresUsed))] = c(fit$featuresUsedSE[1,])

acc = list()
for (j in 1:ncol(fp))
{
  types = "binary"
  names(types) = colnames(fp)[j]
  fit = Calc(fp[,-j],fp[,j,drop=F],covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
  colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
  acc[[j]] = cbind(fit$score,fit$scoreSE)
  acc[[j]][,"outcome"] = rownames(fit$score)
  acc[[j]][,"feature"] = "fpvars"
  acc[[j]][,"covariates"] = "none"
  acc[[j]][,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
  acc[[j]][,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
  acc[[j]][,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")
  #acc[[j]][,sprintf("selection_rate_%s",colnames(fit$featuresUsed))] = c(fit$featuresUsed[1,])
  #acc[[j]][,sprintf("selection_rate_%s_se",colnames(fit$featuresUsed))] = c(fit$featuresUsedSE[1,])
}
acc = do.call(rbind,acc)
accfp = acc

acc = list()
for (j in 1:ncol(fp))
{
    types = "binary"
  names(types) = colnames(fp)[j]
  fpmu = data.frame(fpmu=apply(fp[,-j],1,mean,na.rm=T))
  fit = Calc(fpmu,fp[,j,drop=F],covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
  colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
  acc[[j]] = cbind(fit$score,fit$scoreSE)
  acc[[j]][,"outcome"] = rownames(fit$score)
  acc[[j]][,"feature"] = "fpmu"
  acc[[j]][,"covariates"] = "none"
  acc[[j]][,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
  acc[[j]][,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
  acc[[j]][,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")
}
acc = do.call(rbind,acc)
accfpmu = acc

types = rep("binary",ncol(fp))
names(types)=colnames(fp)
fit = Calc(data[,"fi",drop=F],fp,covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
accfi1 = cbind(fit$score,fit$scoreSE)
accfi1[,"outcome"] = rownames(fit$score)
accfi1[,"feature"] = "fi"
accfi1[,"covariates"] = "none"
accfi1[,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
accfi1[,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
accfi1[,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")

types = rep("binary",ncol(fp))
names(types)=colnames(fp)
fit = Calc(data[,"ficlinic",drop=F],fp,covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
accficlinic = cbind(fit$score,fit$scoreSE)
accficlinic[,"outcome"] = rownames(fit$score)
accficlinic[,"feature"] = "ficlinic"
accficlinic[,"covariates"] = "none"
accficlinic[,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
accficlinic[,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
accficlinic[,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")

types = rep("binary",ncol(fp))
names(types)=colnames(fp)
fit = Calc(data[,"filab",drop=F],fp,covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
accfilab = cbind(fit$score,fit$scoreSE)
accfilab[,"outcome"] = rownames(fit$score)
accfilab[,"feature"] = "filab"
accfilab[,"covariates"] = "none"
accfilab[,"feature_list"] = paste(colnames(fit$featuresUsed),collapse="_")
accfilab[,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
accfilab[,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")

  acc = rbind(accfi,accfp,accfpmu,accfi1,accficlinic,accfilab)
  if(save)
  {
    saveRDS(acc,file)
  }
}

```
```{r}

```


```{r}
library(ggplot2)
plotdata = subset(acc,feature%in%c("fi","ficlinic","filab","fpmu","fpvars"))
plotdata[,"feature"] = gsub("filab","FI LAB",plotdata[,"feature"])
plotdata[,"feature"] = gsub("ficlinic","FI CLINIC",plotdata[,"feature"])
plotdata[,"feature"] = gsub("fi","FI",plotdata[,"feature"])
plotdata[,"feature"] = gsub("fpmu","NFab5",plotdata[,"feature"])
plotdata[,"feature"] = gsub("fpvars","Fab-5 variables",plotdata[,"feature"])
plotdata[,"outcome"] = gsub("BMXBMI","Low BMI",plotdata[,"outcome"])
plotdata[,"outcome"] = gsub("MSXW20TM","Slow gait",plotdata[,"outcome"])
plotdata[,"outcome"] = gsub("PFQ060E","Weakness",plotdata[,"outcome"])
plotdata[,"outcome"] = gsub("PFQ060H","Exhaustion",plotdata[,"outcome"])
plotdata[,"outcome"] = gsub("PAQ520","Low activity",plotdata[,"outcome"])
levs = plotdata[sort.list(subset(acc,feature=="fi")[,"auc"]),"outcome"]
plotdata[,"outcome"] = factor(plotdata[,"outcome"],levs)
g = ggplot(plotdata,aes(x=outcome,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,colour=feature,shape=feature))+
    geom_pointrange(width=0,position=position_dodge(.1))+
    geom_hline(yintercept=0.5,lty=3)+
    scale_y_continuous(limits=c(0.5,1))+
    labs(x="Predicted Outcome",y="AUC")+
    theme_minimal()+
    theme(legend.title=element_blank(),legend.position=c(.2,.8))

g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/auc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/auc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
ggplot(acc,aes(x=outcome,y=youden,ymin=youden-youden_se,ymax=youden+youden_se,colour=feature,shape=feature))+
    geom_pointrange(width=0,position=position_dodge(.1))+
    geom_hline(yintercept=0,lty=3)+
    scale_y_continuous(limits=c(NA,1))+
    labs(x="Predicted Outcome",y="Youden")+
    theme_minimal()
```
How well do we predict FP using FI?

ROC curve
```{r}
library(pROC)
r = roc(I(apply(fp,1,sum,na.rm=T) >= 3)~data[,"fi"],ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

```{r}
ficut = fi >= cut$threshold[2] #>= or > don't matter
xtabs(~I(apply(fp,1,sum,na.rm=T) >= 3)+ficut)
#Assess(xtabs(~outcomes[,"frail"]+ficut))
#xtabs(~apply(fp,1,sum,na.rm=T)+ficut)
```
```{r}
summary(coxph(s~I(apply(fp,1,sum,na.rm=T) >= 3)))
#coxph(s~I(ficut*outcomes[,"frail"]))
summary(coxph(s~ficut))
```

```{r}
library(GGally)
groups = rep("robust",length(fi))
groups[apply(fp,1,sum,na.rm=T) >= 3 & ficut] = "FP and FI > 0.21"
groups[apply(fp,1,sum,na.rm=T) >= 3 & !ficut] = "FP"
groups[apply(fp,1,sum,na.rm=T) < 3 & ficut] = "FI > 0.21"
groupsf = factor(groups,c("robust","FP","FI > 0.21","FP and FI > 0.21"))
g = ggsurv(survfit(s~groupsf),CI=T,order.legend = F)
#g = g + scale_x_continuous(limits=c(50,NA))
g = g + labs(x="Age")
g = g + theme_minimal()
g = g + theme(legend.title=element_blank(),legend.position=c(.3,.3))
g
#print(summary(coxph(formula = s ~ factor(groups,c("robust","fp","fi","fp_and_fi")))))
print(summary(coxph(formula = s ~ groups)))
```
```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/group_surv.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/group_surv.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
g = ggroc(r,linewidth=1)
g = g + geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="darkgrey", linetype="dashed")
g = g + labs(x="Specificity",y="Sensitivity")
#g = g + geom_segment(aes(x=cut$specificity[2],xend=cut$specificity[2],y=0,yend=cut$sensitivity[2]),colour="red")
#g = g + geom_rect(inherit.aes=F,mapping=aes(xmin=cut$specificity[1],xmax=cut$specificity[3],ymin=0,ymax=1),fill="red",alpha=.2)
g = g + theme_minimal()

g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/roc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/roc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

Logistic regression

```{r}
types = c(fp="binary")
dat = data.frame(fp=1*(apply(fp,1,sum,na.rm=T) >= 3))
fit = Calc(data[,"fi",drop=F],dat, covariates=NULL,modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10,featureSelection=F)
colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
#acc = cbind(fit$score,fit$scoreSE)
#acc[,"feature"] = "FI"
#acc[,"selection_rates"] = paste(fit$featuresUsed[1,],collapse="_")
#acc[,"selection_rates_se"] = paste(fit$featuresUsedSE[1,],collapse="_")
```

```{r}
metrics = data.frame(metric=colnames(fit$score),value=as.numeric(fit$score[1,]),se=as.numeric(fit$scoreSE[1,]))
metrics = subset(metrics,metric%in%c("acc","auc","sensitivity","specificity","youden"))
ggplot(metrics,aes(x=metric,y=value,ymin=value-se,ymax=value+se))+geom_pointrange(width=0)+
  scale_y_continuous(limits=c(0,1))+
  theme_minimal()+
  labs(y="Score",x="Metric")
```

Xue approach: crude mortality
Xue, Q. L., BandeenRoche, K. & Tian, J. Progression of Physical Frailty and the Risk of AllCause Mortality: Is There a Point of No Return? Journal of the (2021)
```{r}
data = data.frame(fpmu = apply(fp,1,mean,na.rm=T))
data[,'fpmu'] = factor(data[,'fpmu'])
m = coxph(s~fpmu,data)
print(summary(m))
pred = rownames(summary(m)$coefficients)
for (j in 1:length(pred)) pred[j] = strsplit(pred[j],"fpmu")[[1]][2]
pred = as.numeric(pred)
haz = data.frame(HR=summary(m)$coefficients[,"coef"],se=summary(m)$coefficients[,"se(coef)"],predictor="fpordinal",predFactor=rownames(summary(m)$coefficients),pred=pred,refValue=0)
```
```{r}
ggplot(haz,aes(x=pred*5,y=HR,ymin=HR-se,ymax=HR+se))+geom_pointrange(width=0)+labs(x="FP")+geom_smooth()
```
Partial values are due to missingness.

```{r}
data = data.frame(fi=fi)
#cuts = c(0,.05,.1,.3,1) #what are appropriate cuts?
cuts = quantile(fi,na.rm=T,probs=seq(0,1,length=10))
data[,"fiq"] = cut(data[,"fi"],cuts,include.lowest=T)
values = numeric()
levs = levels(data[,"fiq"])
for (j in 1:length(levs)) values[j] = mean(data[data[,"fiq"]==levs[j],"fi"],na.rm=T)
names(values) = levs
m = coxph(s~fiq,data)
print(summary(m))
hazfi = data.frame(HR=summary(m)$coefficients[,"coef"],se=summary(m)$coefficients[,"se(coef)"],predictor="fiordinal",predFactor=rownames(summary(m)$coefficients),pred=values[-1],refValue=values[1],sanity_check=names(values[-1]))
```
```{r}
print("sanity check, these should match ranges")
print(hazfi[,c("predFactor","sanity_check")])
```

```{r}
data = data.frame(fpmu = apply(fp,1,mean,na.rm=T))
m = coxph(s~fpmu,data)
print(summary(m))
hazfpmu = data.frame(HR=summary(m)$coefficients[,"coef"],se=summary(m)$coefficients[,"se(coef)"],predictor="fpmu")
```

```{r}
data = data.frame(fi=fi)
m = coxph(s~fi,data)
print(summary(m))
hazfimu = data.frame(HR=summary(m)$coefficients[,"coef"],se=summary(m)$coefficients[,"se(coef)"],predictor="fi")
```

```{r}
haz2 = haz
haz2[,"pred"] = haz[,"pred"]*5
haz2[,"group"] = "FP"
hazfi2 = hazfi[,setdiff(colnames(hazfi),"sanity_check")]
hazfi2[,"group"] = "FI"
hazfi2[,"pred"] = (hazfi2[,"pred"]-min(hazfi2[,"pred"]))/diff(range(hazfi[,"pred"]))*diff(range(haz2[,"pred"]))+min(haz2[,"pred"])
plotdata = rbind(haz2,hazfi2)
hazfimu2 = hazfimu
hazfimu2[,"group"] = "FI"

hazfpmu2 = hazfpmu
hazfpmu2[,"group"] = "FP"


ggplot(plotdata,aes(x=pred,y=HR,ymin=HR-se,ymax=HR+se,colour=group,fill=group,shape=group))+
  geom_pointrange(width=0)+
  labs(x="")+
  geom_smooth()+
  #geom_rect(data=hazfimu2,mapping=aes(x=1,xmin=1,xmax=5,ymin=hazfimu2[1,"HR"]-hazfimu2[1,"se"],ymax=hazfimu2[1,"HR"]+hazfimu2[1,"se"]),alpha=.3,colour="black",linewidth=1)+ #should be a line
  #geom_rect(data=hazfpmu2,mapping=aes(x=1,xmin=1,xmax=5,ymin=hazfpmu2[1,"HR"]-hazfpmu2[1,"se"],ymax=hazfpmu2[1,"HR"]+hazfpmu2[1,"se"]),alpha=.3,colour="black",linewidth=1)+
  theme_minimal()
```

```{r}
print("to do: do we need to account for reference value?")
haz2 = haz
haz2[,"group"] = "FP"
hazfi2 = hazfi[,setdiff(colnames(hazfi),"sanity_check")]
hazfi2[,"group"] = "FI"
#hazfi2[,"pred"] = (hazfi2[,"pred"]-min(hazfi2[,"pred"]))/diff(range(hazfi[,"pred"]))*diff(range(haz2[,"pred"]))+min(haz2[,"pred"])
plotdata = rbind(haz2,hazfi2)


hazfimu2 = data.frame(pred=c(0,hazfi[,"pred"],1))
hazfimu2[,"HR"] = hazfimu[,"HR"]*(hazfimu2[,"pred"] )
hazfimu2[,"se"] = hazfimu[,"se"]*(hazfimu2[,"pred"] )
#hazfimu2[,"HR"] = hazfimu[,"HR"]*(hazfimu2[,"pred"] - hazfi[,"refValue"]) #doesn't look right
#hazfimu2[,"se"] = hazfimu[,"se"]*(hazfimu2[,"pred"] - hazfi[,"refValue"]) #doesn't look right
hazfimu2[,"group"] = "FI"
hazfimu2[,"pred"] = c(0,hazfi2[,"pred"],1)

hazfpmu2 = data.frame(pred=c(0,haz[,"pred"],1))
hazfpmu2[,"HR"] = hazfpmu[,"HR"]*(hazfpmu2[,"pred"] )
hazfpmu2[,"se"] = hazfpmu[,"se"]*(hazfpmu2[,"pred"] )
#hazfpmu2[,"HR"] = hazfpmu[,"HR"]*(hazfpmu2[,"pred"] - haz[,"refValue"]) #doesn't look right
#hazfpmu2[,"se"] = hazfpmu[,"se"]*(hazfpmu2[,"pred"] - haz[,"refValue"])#doesn't look right
hazfpmu2[,"group"] = "FP"
hazfpmu2[,"pred"] = c(0,haz2[,"pred"],1)

plotdata2 = rbind(hazfpmu2,hazfimu2)


g = ggplot(plotdata,aes(x=pred,y=HR,ymin=HR-se,ymax=HR+se,colour=group,fill=group,shape=group))+
  geom_pointrange(width=0)+
  labs(x="",y="ln(HR)")+
  geom_line(data=plotdata2)+
  geom_ribbon(data=plotdata2,alpha=.3)+
  theme_minimal()+
  theme(legend.title=element_blank(), legend.position=c(.2,.8))

g
```

```{r}
print("to do: do we need to account for reference value?")
haz2 = haz
haz2[,"pred"] = haz[,"pred"]*5
haz2[,"group"] = "FP"
hazfi2 = hazfi[,setdiff(colnames(hazfi),"sanity_check")]
hazfi2[,"group"] = "FI"
hazfi2[,"pred"] = (hazfi2[,"pred"]-min(hazfi2[,"pred"]))/diff(range(hazfi[,"pred"]))*diff(range(haz2[,"pred"]))+min(haz2[,"pred"])
plotdata = rbind(haz2,hazfi2)


hazfimu2 = data.frame(pred=c(0,hazfi[,"pred"]))
hazfimu2[,"HR"] = hazfimu[,"HR"]*(hazfimu2[,"pred"] )
hazfimu2[,"se"] = hazfimu[,"se"]*(hazfimu2[,"pred"] )
#hazfimu2[,"HR"] = hazfimu[,"HR"]*(hazfimu2[,"pred"] - hazfi[,"refValue"]) #doesn't look right
#hazfimu2[,"se"] = hazfimu[,"se"]*(hazfimu2[,"pred"] - hazfi[,"refValue"]) #doesn't look right
hazfimu2[,"group"] = "FI"
hazfimu2[,"pred"] = c(0,hazfi2[,"pred"])

hazfpmu2 = data.frame(pred=c(0,haz[,"pred"]))
hazfpmu2[,"HR"] = hazfpmu[,"HR"]*(hazfpmu2[,"pred"] )
hazfpmu2[,"se"] = hazfpmu[,"se"]*(hazfpmu2[,"pred"] )
#hazfpmu2[,"HR"] = hazfpmu[,"HR"]*(hazfpmu2[,"pred"] - haz[,"refValue"]) #doesn't look right
#hazfpmu2[,"se"] = hazfpmu[,"se"]*(hazfpmu2[,"pred"] - haz[,"refValue"])#doesn't look right
hazfpmu2[,"group"] = "FP"
hazfpmu2[,"pred"] = c(0,haz2[,"pred"])

plotdata2 = rbind(hazfpmu2,hazfimu2)


g = ggplot(plotdata,aes(x=pred,y=HR,ymin=HR-se,ymax=HR+se,colour=group,fill=group,shape=group))+
  geom_pointrange(width=0)+
  geom_line(data=plotdata2)+
  geom_ribbon(data=plotdata2,alpha=.3)+
  labs(x="Score",y="ln(HR)")+
  theme_minimal()+
  theme(legend.title=element_blank(), legend.position=c(.2,.8))

g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/hr.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/hr.png",outputDir),g,width=10,height=8,dpi=300)
}
```


Rough idea of how well FI works

```{r}
types = c(fp="binary")
dat = data.frame(fp=1*(apply(fp,1,sum,na.rm=T) >= 3))
acc = list()
for (i in 1:ncol(data))
{
  fit = Calc(data[,i,drop=F],dat,covariates[,c("RIDAGEYR","RIAGENDR")],modelName="glm",outcomeTypes=types,save=F,folds=10,repeats=10)
  colnames(fit$scoreSE) = sprintf("%s_se",colnames(fit$scoreSE))
  acc[[i]] = cbind(fit$score,fit$scoreSE)
  acc[[i]][,"feature"] = colnames(data)[i]
  acc[[i]][,"selection_rate"] = fit$featuresUsed[,1]
  acc[[i]][,"selection_rate_se"] = fit$featuresUsedSE[,1]
}
acc = do.call(rbind,acc)
```

```{r}
rf = Calc(data,1*(apply(fp,1,sum,na.rm=T) >= 3),covariates[,c("RIDAGEYR","RIAGENDR")],modelName="rf",outcomeTypes=types,save=F,folds=10,repeats=10)
```


Spare Code
```{r}
stop("spare code")
```

```{r}
library(survPen)
sp = survPen(~1+death+fi,data=stst[[1]][[1]],t0=start,t1=death,event=status)
```

```{r}
library(colorspace)
library(scico)
conf.int = pnorm(1)-pnorm(-1)

st = stst[[1]][[1]]
sst = stst[[1]][[2]]

probs = seq(0,1,length=3)
cuts = quantile(st[,"fi"],probs=probs)

zq = cut(st[,"fi"],cuts,labels = sprintf("%.0f%%",round(probs[-1]*100)),include.lowest=T)
cols = scico(length(levels(zq)), palette = 'roma')
t = seq(60,100,by=1)
fitdata = list()
for (j in 1:length(levels(zq)))
{
  muzq = mean(st[zq==levels(zq)[j],"fi"],na.rm=T)
  test = data.frame(start=60,death=t,fi=muzq) 
  pr = predict(sp,newdata=test)
  

  fitdata[[j]] = data.frame(strata=levels(zq)[j],t=t,
                  S = pr[["surv"]],
                  Smin= pr[["surv.inf"]],
                  Smax = pr[["surv.sup"]]
                  )
}
fitdata=do.call(rbind,fitdata)

fitdata[,"strata"]= factor(fitdata[,"strata"],levels(zq))


sf = survfit(sst ~ z,data=data.frame(z=zq),conf.int=conf.int)
group = rep("unknown",length(sf$cumhaz))
ind = 0
for (j in 1:length(sf$strata))
{
  group[1:sf$strata[j]+ind] = gsub("z=","",names(sf$strata)[j])
  ind = ind + sf$strata[j]
}
group = factor(group,levels(zq))
  
#survival
logi = !is.na(sf$upper) & !is.na(sf$lower)
g = ggplot(data.frame(t=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,strata=group)[logi,],
       aes(x=t,y=S,ymin=Smin,ymax=Smax,colour=strata,fill=strata))+
  geom_line(lty=2)+
  geom_ribbon(alpha=.5,colour=NA)+
  #scale_colour_manual(breaks=levels(group),values=cols)+
  #scale_fill_manual(breaks=levels(group),values=cols)+
  scale_colour_discrete_diverging("Blue-Red")+
  scale_fill_discrete_diverging("Blue-Red")+
  labs(y="Survival",x="Years on dialysis",colour="Percentile",fill="Percentile",linetype="")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
          legend.position= "right", #c(.6,.3), #
          legend.key.size = unit(4,"line"),
          legend.text=element_text(size=gTextSize*.9)#,
          #legend.title=element_blank()
        )


g = g + geom_line(data=fitdata,lwd=2,inherit.aes=F,mapping=aes(x=t,y=S,colour=strata,linetype="Fit"))
g = g + geom_ribbon(data=fitdata,alpha=.15,colour=NA)


#g = g + scale_x_continuous(limits=c(60,100))

g



```


#### spare code
```{r}
stop("spare code")
```

coefficients

calibration curves
how do we get errorbars? not sure... I doubt the errors are independent
assume they're independent for now

prevalence
```{r}
fi_cuts = c(seq(0,.6,by=.05),1)
outcomes = unique(sp[["importance"]][,"Outcome"])
g = list()
for (i in 1:length(outcomes))
{

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  

  #frequencies
  g[[i]] = ggplot(data.frame(x=agg[[1]][,"fi"],xse=agg[[2]][,"fi"],y=agg[[1]][,2],yse=agg[[2]][,2]),aes(x=x,xmin=x-xse,xmax=x+xse,y=y,ymin=y-yse,ymax=y+yse))+
    geom_pointrange()+
    #geom_line()+
    #geom_ribbon(alpha=.1)+
    geom_smooth(colour="black")+
    labs(x="FI",y=bquote("Prevalence"),title=outcomes[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)

```

OR = P/1-P
dOR = dP/(1-P)^2
```{r}
library(MASS)
samples = 1000 #for errorbars
sp = fits[["fisp"]]
bMat = sp[["bMat"]]
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testfi = seq(0,.75,by=.01)
fi_cuts = c(seq(0,.6,by=.05),1)
outcomes = unique(sp[["importance"]][,"Outcome"])
g = list()
for (i in 1:length(outcomes))
{
  logi = sp[["importance"]][,"Outcome"] == outcomes[i]
  subFit = sp[["importance"]][logi,]
  subFitSE = sp[["importanceSE"]][logi,]
 
  tr = matrix(NA,nrow=samples,ncol=length(testfi)) #coefficient
  for (ii in 1:samples)
  {
    beta = mvrnorm(n=1,mu=subFit[colnames(bMat),"Coef"],Sigma=diag(subFitSE[colnames(bMat),"Coef"]))
    tr[ii,] = predict(bMat,testfi)%*%beta
  }
  #tr is normally distributed, pr is not
  #pr = 1/(1+exp(-tr)) #probability, neglecting offset
  
  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  
  #regression coefficient
  #g[[i]] = ggplot(data.frame(x=testfi,y=apply(tr,2,mean,na.rm=T),yse=apply(tr,2,sd,na.rm=T)),aes(x=x,y=y,ymin=y-yse,ymax=y+yse))+
  #  geom_line()+
  #  geom_ribbon(alpha=.15)+
  #  labs(x="FI",y=bquote(beta),title=outcomes[i])
  
  OR = agg[[1]][,2]/(1-agg[[1]][,2])
  dOR = agg[[2]][,2]/(1-agg[[1]][,2])^2
  
  #Odds ratio
#  g[[i]] = ggplot(data.frame(x=testfi,y=apply(tr,2,mean,na.rm=T),yse=apply(tr,2,sd,na.rm=T)),aes(x=x,y=exp(y),ymin=exp(y-qnorm(.975)*yse),ymax=exp(y+qnorm(.975)*yse)))+
#    geom_line()+
#    geom_ribbon(alpha=.15)+
#    geom_pointrange(data=data.frame(x=agg[[1]][,"fi"],xse=agg[[2]][,"fi"],y=OR,yse=dOR))+ #error in FI is small so can ignore
#    #geom_pointrange(data=data.frame(x=agg[[1]][,"fi"],xse=agg[[2]][,"fi"],y=agg[[1]][,2],yse=agg[[2]][,2]))+ #error in FI is small so can ignore #probability
#    labs(x="FI",y=bquote("Odds ratio"),title=outcomes[i])+
#    scale_y_log10()+
#    annotation_logticks(sides="l")+
#    theme_minimal()
  
  
    #prevalence / probability
    offset = coef(glm(y~1,family="binomial",data=data.frame(y=data[[1]][,outcomes[i]])))
  g[[i]] = ggplot(data.frame(x=testfi,y=apply(tr,2,mean,na.rm=T),yse=apply(tr,2,sd,na.rm=T)),aes(x=x,y=1/(1+exp(-offset-y)),ymin=1/(1+exp(-offset-y+qnorm(.975)*yse)),ymax=1/(1+exp(-offset-y-qnorm(.975)*yse))))+
    geom_line()+
    geom_ribbon(alpha=.15)+
    geom_pointrange(data=data.frame(x=agg[[1]][,"fi"],xse=agg[[2]][,"fi"],y=OR,yse=dOR))+ #error in FI is small so can ignore
    #geom_pointrange(data=data.frame(x=agg[[1]][,"fi"],xse=agg[[2]][,"fi"],y=agg[[1]][,2],yse=agg[[2]][,2]))+ #error in FI is small so can ignore #probability
    labs(x="FI",y=bquote("Probability"),title=outcomes[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()

}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)
```


