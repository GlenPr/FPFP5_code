---
title: "FI vs FP"
output: html_notebook
---

Glen Pridham, June 2024 with major changes CART imputed data.

FI vs FP. Which one predicts FP better?

FI lab data needs to be binarized. Just do clinic for now.

Notes:
-BMI deficit is extremely rare ~2% of people. The cut (18.5) seems unreasonable, but it's what others use (Wilhelm-Leen, Blodgett).
-Lee used a much more complicated BMI criteria which is closer to ELSA but requires variables I don't have
-Beniak used a similar definition to Lee, but moved BMI cut up to 22.5
-Kurnat-Thoma dropped BMI entirely and used self-reported weight loss instead
-Chen used 18.5 cut

Baniak, L. M., Yang, K., Choi, J. & Chasens, E. R. Long Sleep Duration Is Associated With Increased Frailty Risk in Older Community-Dwelling Adults. J. Aging Health 32, 42–51 (2020)
Chen, L.-H. & Wu, L.-W. Association between serum lactate dehydrogenase and frailty among individuals with metabolic syndrome. PLoS One 16, e0256315 (2021)
Lee, M. J., Varadaraj, V., Tian, J., Bandeen-Roche, K. & Swenor, B. K. The Association between Frailty and Uncorrected Refractive Error in Older Adults. Ophthalmic Epidemiol. 27, 219–225 (2020)
Kurnat-Thoma, E. L., Murray, M. T. & Juneau, P. Frailty and Determinants of Health Among Older Adults in the United States 2011–2016. J. Aging Health 34, 233–244 (2022)
Wilhelm-Leen, E. R., Hall, Y. N., K Tamura, M. & Chertow, G. M. Frailty and chronic kidney disease: the Third National Health and Nutrition Evaluation Survey. Am. J. Med. 122, 664–71.e2 (2009)
Blodgett, J., Theou, O., Kirkland, S., Andreou, P. & Rockwood, K. Frailty in NHANES: Comparing the frailty index and phenotype. Arch. Gerontol. Geriatr. 60, 464–470 (2015)



```{r}
gRootName = "fi_vs_fp_nhanes"
gRootDir = "/home/glen/Documents/r"  #where scripts are
outputDir = "/home/glen/analysis/fi_vs_fp" #analysis directory
#gFab5Name = "NPheno5"
gFab5Name = "NFPFP5"

source(sprintf("%s/stpm.R",gRootDir),verbose=0) 
source(sprintf("%s/logreg.R",gRootDir),verbose=0) 
source(sprintf("%s/pca.R",gRootDir),verbose=0)  #cov2
source(sprintf("%s/main.R",gRootDir),verbose=0)
source(sprintf("%s/plots.R",gRootDir),verbose=0) #TilePlot
source(sprintf("%s/terminal_decline.R",gRootDir),verbose=0) 
source(sprintf("%s/roc.R",gRootDir),verbose=0) 

library(tidyr) #for spread (long to wide) and gather (wide to long) #http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/
library(GGally)
library(gridExtra)
library(ggrepel)
library(survival)
library(mice)

gTextSize = 20
gAxisTextSize = 12
gPointSize = 4
gLineWidth = 1.5
#gColours = function(n,space="ag_GrnYl") return(colorspace::sequential_hcl(n,space))
gColours = function(n) 
{
    hues = seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 90)[1:n]
}
```

```{r}
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

medianBS = function(x,nboot=100)
{
  m = numeric(nboot)
  for (i in 1:nboot)
  {
    m[i] = median(sample(x,length(x),replace=T),na.rm=T)
  }
  return(list(est=mean(m),se=sd(m)))
}

SummaryNfp = function(data,lev=NULL,model=NULL)
{
  #based on defaultSummary()
  #no assumptions on data
  
  #continuous metrics:
  prnum = as.numeric(as.character(data[,"pred"]))
  gtnum = as.numeric(as.character(data[,"obs"]))
  rmse = sqrt(mean((gtnum-prnum)^2,na.rm=T))
  mae = mean(abs(gtnum-prnum),na.rm=T)
  
  contMetrics = c(rmse,mae)
  names(contMetrics) =   c("RMSE","MAE")
  
  #discrete metrics:
  prin = round(as.numeric(as.character(data[,"pred"])))
  prin[prin < 0] = 0
  prin[prin > 5] = 5
  prin = ordered(prin,0:5)
  gtin = round(as.numeric(as.character(data[,"obs"])))
  gtin = ordered(gtin,0:5)
  
  #C = xtabs(~gtin+prin)
  discMetrics = multiClassSummary(data=data.frame(obs=gtin,pred=prin),lev=lev,model=model)
  
  youden = discMetrics["Mean_Sensitivity"] + discMetrics["Mean_Specificity"] - 1
  names(youden) = "Mean_Youden"
  
  metrics = c(contMetrics,discMetrics,youden)
  
  return(metrics)
}

ExpectationPr = function(pr,newdata=NULL) 
{
  #pr: data.frame from predict e.g. pr = predict(rf,newdata=data[[1]],type="prob")
  cl = as.numeric(colnames(pr))
  
  #most likely class
  maxPr = cl[apply(pr,1,which.max)]
  
  #expectation value of classes
  E = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl),1,sum,na.rm=T)
  #second moment
  E2 = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl)^2,1,sum,na.rm=T)  
  #sd
  s = sqrt(E2-E^2)

  if(!is.null(newdata))
  {
  df = matrix(NA,nrow=nrow(pr),ncol=3+ncol(newdata))
  colnames(df) = c(colnames(newdata),"class","Epr","sd")
  df[,1:ncol(newdata)] = as.matrix(newdata)
  df[,1+ncol(newdata)] = maxPr
  df[,2+ncol(newdata)] = E
  df[,3+ncol(newdata)] = s
  }
  else
  {
      df = matrix(NA,nrow=nrow(pr),ncol=3)
    colnames(df) = c("class","Epr","sd")
    df[,1] = maxPr
    df[,2] = E
    df[,3] = s
  }
  return(df)
}
```


```{r}
#sanity check:
  #encoding is the same between nhanes_cc and imputed
#but now data may be TYPED!
BinarizeFP = function(x,
                            bmi="BMXBMI",
                            bmiCut = 18.5,
                            useQuantileBMI=F, #bottom 20% are frail, sex-specific
                            walk="MSXW20TM", #time to walk 20 feet (higher = worse)
                            walkCut = "calc", #typically same length as nrow(x) because gender-specific
                            weak="PFQ060E", #Lifting or carrying difficulty
                            #weakVals = (1:3)/3, #1: no difficulty, 2: some, 3:much, 4: unable
                            weakCut = .01, #deficit > 0
                            weakNA = c(7,9),  #7: refused #9: don't know 
                            exhaust = "PFQ060H", #Walking between rooms on same floor
                            #exhaustVals = (1:3)/3, #1: no difficulty, 2: some, 3:much, 4: unable
                            exhaustCut = .01, #deficit > 0
                            exhaustNA = c(7,9),  #7: refused #9: don't know 
                            activity="PAQ520", #relative activity to others of same age
                            activityVals = 2, #1: more, 2: less, 3: about the same
                            activityNA = c(7,9), #7: refused #9: don't know 
                            na.rm=T,
                            binarize=T
                            )
{
  #Wilhelm-Leen2009-xe
    #3+:
    #BMI <= 18.5
    #8 foot time in bottom 20% for your gender
    #
  count = as.data.frame(matrix(NA,nrow=nrow(x),ncol=5))
  colnames(count)=c("bmi","gait","weak","exhausted","activity")
  
  #check for types and strip
  vars = c(bmi,walk,weak,exhaust,activity)
  for (j in 1:length(vars))
  {
    #cl = class(x[,vars[j]])
    if(is.factor(x[,vars[j]]))
    {
      print(sprintf("factor found, %s (%s), stripping type...",vars[j],colnames(count)[j]))
      warning(sprintf("factor found, %s (%s), stripping type...",vars[j],colnames(count)[j]))
      x[,vars[j]] = as.numeric(as.character(x[,vars[j]]))
    }
  }
  
  #BMI
  if(useQuantileBMI) 
  {
    #sex = 0
    logi = x[,"RIAGENDR"] == 0
    bmiCut = quantile(x[logi,bmi],probs=.2,na.rm=T)
    count[logi,"bmi"] = as.integer(x[logi,bmi] <= bmiCut) 
    print(sprintf("sex 0 BMI cut: %.1f",bmiCut))
    rm(logi)
    rm(bmiCut)
    #sex = 1
    logi = x[,"RIAGENDR"] == 1
    bmiCut = quantile(x[logi,bmi],probs=.2,na.rm=T)
    count[logi,"bmi"] = as.integer(x[logi,bmi] <= bmiCut) 
    print(sprintf("sex 1 BMI cut: %.1f",bmiCut))
    rm(logi)
    rm(bmiCut)
  }
  else  count[,"bmi"] = as.integer(x[,bmi] <= bmiCut) 
  
  #walk/gait
  if(is.na(walkCut))
  {
    warning("FrailtyPhenotype: skipping gait, no cut provided.")
  }
  else if (walkCut[1]=="calc")
  {
    sex = x[,"RIAGENDR"]
    unsex = sort(unique(sex))
    unsex = unsex[!is.na(unsex)]
    if(length(unsex)>2) stop("Non-binary sexes")
    
    for (i in 1:2)
    {
      logi = sex==unsex[i]
      logi[is.na(logi)] = F
      count[logi,"gait"] = as.integer(x[logi,walk] >= quantile(x[logi,walk],probs=.8,na.rm=na.rm)) #update: June 2023, cut was backwards
    }
  }
  else
  {
    count[,"gait"] = as.integer(x[,walk] >= walkCut)  #update: June 2023, cut was backwards
  }
  
  #weakness
  #count[,"weak"] = as.integer(round(x[,weak],3) %in% round(weakVals,3))
  count[,"weak"] = as.integer(x[,weak] >= weakCut)
  
  #exhaustion
  #count[,"exhausted] = as.integer(round(x[,exhaust],3) %in% round(exhaustVals,3))
  count[,"exhausted"] = as.integer(x[,exhaust] >= exhaustCut)
  
  #physical activity
  NAs = is.na(x[,activity])
  count[,"activity"] = as.integer(x[,activity] %in% activityVals) 
  count[NAs,"activity"] = NA

  
  return(count)
}

```

```{r}
m  = readRDS(sprintf("%s/data/nhanes01_60plus_mice_m15.rds",outputDir))
s = readRDS(sprintf("%s/data/nhanes01_60plus_survival.rds",outputDir))
s[s[,1] >= 85,1] = NA #drop top-coded ages
varTypes = readRDS(sprintf("%s/data/varTypes.rds",outputDir)) 
codex = read.csv(sprintf("%s/nhanes_fivar.csv",outputDir),row.names=1)
```

```{r}
fpVar = c("BMXBMI","MSXW20TM","PFQ060E","PFQ060H","PAQ520")
fpNames = c("bmi","gait","weak","exhausted","activity")
names(fpNames) = c("Low BMI","Slow gait","Weakness","Exhaustion","Low activity")
fiLabVar = subset(varTypes,labVar)[,"var"]
fiLabVar = setdiff(fiLabVar,fpVar)
print(sprintf("total LAB FI variables: %d",length(fiLabVar)))
print(fiLabVar)
fiClinicVar = subset(varTypes,clinicVar)[,"var"]
fiClinicVar = setdiff(fiClinicVar,fpVar)
names(fiClinicVar) = varTypes[fiClinicVar,"name"]
print(sprintf("total CLINIC FI variables: %d",length(fiClinicVar)))
print(fiClinicVar)
fiVar = c(fiLabVar,fiClinicVar)

demoVar = c("RIDAGEYR","RIAGENDR")
names(demoVar) = c("age","sex")
```

```{r}
  #cuts
  #include only if you have low activity, exhaustion, BMI and either grip or weakness
    #probably fine if we demand all 5, most of the missingness is BMI + gait
logiCut = apply(!m$where[,c("BMXBMI","PFQ060H", "PAQ520")],1,all) & (!m$where[,"MSXW20TM"] | !m$where[,"PFQ060E"])
print(sprintf("dropping %d due to missing FP vars",sum(!logiCut)))


#top-coded age cut
  #age cut #85 is top-coded
ageLogi = mice::complete(m,1)[,"RIDAGEYR"] < 85
print(sprintf("Dropping %d individuals with top-coded age",sum(!ageLogi)))



logiCut= logiCut & ageLogi

print(sprintf("Combined cuts: dropping %d individuals with top-coded age or missing FP vars (/ %d)",sum(!logiCut),nrow(s)))

scut = s[logiCut,]

#reshape data for analysis
data = list() #will be cut 
stst = list() #won't be cut
for (i in 1:m$m)
{
  imp = mice::complete(m,i)
  #fp = BinarizeFP(imp,useQuantileBMI=F,bmiCut=18.5) #Wilhelm-Lee and Blodgett cut #fp prevalence: 5.3% #low BMI prevalence: 1.5% #calibration curves look like shit
  fp = BinarizeFP(imp,useQuantileBMI=F,bmiCut=22.5) #Baniak cut #fp prevalence: 6.5% #low BMI basically impossible to predict; #low BMI prevalence: 12.6%
  fp_qcut = BinarizeFP(imp,useQuantileBMI=T)
  data[[i]] = imp[,demoVar,drop=F]
  colnames(data[[i]]) = names(demoVar)
  for (j in 1:ncol(fp)) data[[i]][,colnames(fp)[j]] = fp[,j]
  data[[i]][,"Nfp"] = apply(fp,1,sum)
  data[[i]][,"Nfp_qcut"] = apply(fp_qcut,1,sum)
  data[[i]][,"fp"] = as.integer(data[[i]][,"Nfp"] >= 3)
  data[[i]][,"fp_class"] = NA
  data[[i]][data[[i]][,"Nfp"] >= 2.99,"fp_class"] = "frail"
  data[[i]][data[[i]][,"Nfp"] > 0.01 & data[[i]][,"Nfp"] < 2.99 ,"fp_class"] = "prefrail"
  data[[i]][data[[i]][,"Nfp"] < 0.01,"fp_class"] = "robust"
  data[[i]][,"fp_class"] = ordered(data[[i]][,"fp_class"],c("robust","prefrail","frail"))
  data[[i]][,"Nfp_ord"] = ordered(data[[i]][,"Nfp"],0:5)
  
  #compute FI - drop type first
  fiData = imp[,fiVar]
  for (j in 1:ncol(fiData)) fiData[,j] = as.numeric(as.character(fiData[,j]))
  #data[[i]][,"fi"] = apply(fiData[,fiVar],1,mean,na.rm=T)
  #data[[i]][,"fiLab"] = apply(fiData[,fiLabVar],1,mean,na.rm=T)
  #data[[i]][,"fiClinic"] = apply(fiData[,fiClinicVar],1,mean,na.rm=T)
  data[[i]][,"fi"] = apply(fiData[,fiClinicVar],1,mean,na.rm=T) # just using clinical data for now

  #update: keep fivar
  data[[i]][,fiClinicVar] = fiData[,fiClinicVar]

    
  #FI using fp variables
  data[[i]][,"fifp"] = apply(data.frame(fiData[,fiClinicVar],fp),1,mean,na.rm=T)
  
  stst[[i]] = data[[i]] #[,c("fi","fifp","Nfp")]

  #apply cuts
  data[[i]] = data[[i]][logiCut,]
}
```

```{r}
save = T
if(save)
{
  saveRDS(data,sprintf("%s/data/nhanes_mi_preprocessed.rds",outputDir))
  saveRDS(m$where,sprintf("%s/data/nhanes_where.rds",outputDir))
  saveRDS(m$where[logiCut,],sprintf("%s/data/nhanes_where_cut.rds",outputDir))
}
```

could try embed
```{r}
df = data[[1]][,c(fiClinicVar,"bmi","gait","weak","exhausted","activity")]
for (j in 1:ncol(df)) df[,j] = as.numeric(as.character(df[,j]))
C = cov2(df,use='pairwise.complete',center=F)
C = C/sqrt(outer(diag(C),diag(C)))
TilePlot(C)
ord=seriate(C,method="PCA")
TilePlot(C[ord[[1]],ord[[1]]])
ord=seriate(C,method="PCA_angle")
TilePlot(C[ord[[1]],ord[[1]]])

C = cor(df,use='pairwise.complete')
ord=seriate(C,method="PCA")
TilePlot(C[ord[[1]],ord[[1]]])
ord=seriate(C,method="PCA_angle")
TilePlot(C[ord[[1]],ord[[1]]])

pc = prcomp2(df,center=F,scale=F)
#outer(P[,1],Pinv[1,])
#z= y%*%t(Pinv)
#p = x%*%rotation = x%*%t(rotation_inv)
#rotation_inv = t(rotation)
#rotation = P
#should be outer(basis,basis)
g = list()
for (i in 1:6){
  g[[i]] = TilePlot(outer(pc$rotation[,i],pc$rotation[,i]))+ggtitle(sprintf("PC%02d",i))
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)

C = outer(pc$rotation[,5],pc$rotation[,5])
ord=seriate(abs(C),method="PCA")
inds = ord[[1]]
#inds = c(ord[[1]][-1],ord[[1]][1])
TilePlot(C[inds,inds])
```
#hclust

```{r}
d = list()
fpnms =  c("Low BMI","Slow gait","Feel weak","Exhaustion","Low activity")
for (i in 1:m$m)
{

  temp = data[[i]][,c(fpNames,fiClinicVar)]
  colnames(temp)[1:length(fpNames)] = fpnms
  #colnames(temp)[1:length(fiClinicVar)+length(fpNames)] = codex[fiClinicVar,"name"]
  #colnames(temp)[1:length(fiClinicVar)+length(fpNames)] = names(fiClinicVar)
  #colnames(temp) = gsub("_"," ",colnames(temp))
  #colnames(temp) = gsub("lem","LEM",colnames(temp))
  #colnames(temp) = gsub("lsa","LSA",colnames(temp))
  #colnames(temp) = gsub("iadl","IADL",colnames(temp))
  #colnames(temp) = gsub("adl","ADL",colnames(temp))
  #colnames(temp) = gsub("gpa","GPA",colnames(temp))
  #colnames(temp) = gsub("srh","SRH",colnames(temp))
  for (j in 1:ncol(temp)) temp[,j] = as.integer(as.numeric(as.character(temp[,j])) > .49) #binarize and drop type

  #binary: #https://en.wikipedia.org/wiki/Jaccard_index
    #binary is >= 0 and <= 1
    #sum( (x[x | y] | y[x | y]) & !(x[x | y] & y[x | y]) )/sum(x | y)
    #considers only when at least x or y == 1
      #proportion of the time you have x or y but not x and y
      #This is same is |intersection|/|union|
  d[[i]] = dist(t(temp),"binary") #canberra is for counts, binary is for binary
  d[[i]] = as.matrix(d[[i]])
  
  #could put cluster membership stuff in here to get errorbar
    #both for bootstrap and imputation error
}

d = RubinMat(d)
#d = ListMeanSD(d)
#d = Reduce("+",d)/length(d)
```

```{r}
h = hclust(as.dist(d[[1]]),method="average")
plot(h)
```


```{r}
ColourLabels = function(labs)
{
  types = codex[labs,"Type"]
  for (j in 1:length(fpnms)) types[labs==fpnms[j]] = "Pheno5"
  types = factor(types,c("ADL","Diag","GPA","LSA","IADL","LEM","Pheno5","SRH"))
  #make LEM separate colour
  #i = as.numeric(types)
  #print(i)
  #i[i==7] = 1
  #i[i>7] = i[i>7]-1
  #print(cbind(i,as.character(types)))
  #print(length(unique(i)))
  #cols = gg_color_hue(length(unique(i)))[i]
  #cols[types=="LSA"] = "grey"
  #types = factor(types)
  cols = gg_color_hue(length(levels(types)))[as.numeric(types)]
  return(data.frame(label=types,colour=cols))
}
```
```{r}
library(ggplot2)
library(ggdendro)
```

```{r}
inds = h$labels[h$order]
#ddf = segment(dendro_data(h,type="rectangle"))
ddf = segment(dendro_data(h)) #looks same to me
#ddf[,"colour"] = ordered(cl)
dsort = d[[1]][inds,inds]

nms = rownames(dsort)
nms = codex[rownames(dsort),"Terse"]
for (j in 1:length(fpVar)) nms[rownames(dsort)==fpnms[j]] = tolower(fpnms[j])
rownames(dsort) = nms
colnames(dsort) = nms
diag(dsort) = NA
g = TilePlot(1-dsort,na.value="grey89",zname="Similarity") +  geom_segment(data=ddf, aes(x=y*8+length(h$labels)+.5, y=x, xend=yend*8+length(h$labels)+.5, yend=xend),inherit.aes=F) + #theme(panel.background = element_rect(fill='white', colour="white"))
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(),
        legend.background=element_rect(fill="white",colour="grey60"),
        #axis.text.x=element_blank(),
        axis.text.x=element_text(angle=90,vjust=.5,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"]),
        axis.text.y=element_text(angle=0,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"])
        )

#fix legend
#g = g + labs(fill="Proximity",colour="Proximity")
g = g + theme(legend.title=element_text())

#donor plot for labels
df = ColourLabels(rownames(d[[1]][inds,inds]))
df[,"x"] = 1
df[,"y"] = 1
gd = ggplot(df,aes(x=x,y=y,colour=label))+
  geom_point()+
  #scale_colour_manual(breaks=df[,"label"],values=df[,"colour"])+
  theme(legend.title=element_blank())

library(cowplot)
g = list(ggdraw(cowplot::get_legend(gd)),g)


#add box?
#g[[2]] = g[[2]]+annotate("rect",xmin=1.5,ymin=1.5,xmax=28.5,ymax=28.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=28.5,ymin=28.5,xmax=46.5,ymax=46.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=1.5,ymin=1.5,xmax=18.5,ymax=18.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=18.5,ymin=18.5,xmax=46.5,ymax=46.5,fill=NA,colour="grey50")


marrangeGrob(g,nrow=1,ncol=2,widths=c(.1,.9),top=NULL)

save=T
if(save)
{
  ggsave(sprintf("%s/results/nhanes_clustering.pdf",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/nhanes_clustering.png",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300)
}
```

#ggdendro - for ggplot dendrograms
```{r}
library(ggplot2)
library(ggdendro)
```

```{r}
ggdendrogram(h, rotate = FALSE, size = 2)
```
what is the smallest cluster that contains all 5 FP?
```{r}
library(dendextend)
i = 1
for (i in 1:length(h$labels))
{
  k = length(h$labels)-i+1
  cl = cutree(h, k=k)
  #are all the FP vars in the same cluster?
  if(length(unique(cl[fpnms]))==1)
  {
    print(sprintf("cut at %d",k))
    print("cluster members:")
    clNum = cl[fpnms][1]
    print(cl[cl==clNum]) #who all is in your group
    print("non-cluster members:")
    print(cl[cl!=clNum])
    break
  }
}

plot(color_branches(h, k=k))#leaflab="none")
```

```{r}
#inds = sort.list(cl)
inds = h$labels[h$order]
TilePlot(1-d[[1]][inds,inds])
```

```{r}
inds = h$labels[h$order]
#ddf = segment(dendro_data(h,type="rectangle"))
ddf = segment(dendro_data(h)) #looks same to me
#ddf[,"colour"] = ordered(cl)
TilePlot(1-d[[1]][inds,inds]) +  geom_segment(data=ddf, aes(x=y*8+length(h$labels)+.5, y=x, xend=yend*8+length(h$labels)+.5, yend=xend),inherit.aes=F) + #theme(panel.background = element_rect(fill='white', colour="white"))
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())
```

has promise but not great
```{r}
g = list()
inds = h$labels[h$order]
g[[1]] =TilePlot(1-d[[1]][inds,inds])
g[[2]] = ggdendrogram(h, rotate = TRUE, size = 2,labels = FALSE)+theme(axis.text.y=element_blank(),axis.text.x=element_blank())
#g[[2]] = g[[2]] + theme(plot.margin = margin(t = 10, r = 0, b = 10, l = 0, unit = "pt")) # not working (???)
layout = matrix(NA,nrow=4,ncol=4)
layout[1:3,1:3] = 1
layout[1:3,4] = 2
marrangeGrob(g,nrow=nrow(layout),ncol=ncol(layout),layout_matrix=layout,top=NULL)#,widths=c(1,.5))
```

#https://stackoverflow.com/questions/50992112/decrease-size-of-dendogram-or-y-axis-ggplot
ok but this just gets the segments
```{r}
hc       = h 
dendr    <- dendro_data(hc, type="rectangle") # convert for ggplot
clust    <- cutree(hc,k=k)                    # find k  clusters
clust.df <- data.frame(label=names(clust), cluster=factor(clust))
# dendr[["labels"]] has the labels, merge with clust.df based on label column
dendr[["labels"]] <- merge(dendr[["labels"]],clust.df, by="label")
# plot the dendrogram; note use of color=cluster in geom_text(...)
ggplot() + 
  geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + 
  geom_text(data=label(dendr), 
            aes(x, y, label=label, hjust=0, color=cluster), 
            size=3) +
  coord_flip() + 
  scale_y_reverse(expand=c(0.2, 0)) + 
  theme(axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank())
```



visualize in 2D
not sure what MDS is...
```{r}
fit = isoMDS(as.dist(d[[1]]), k=2) # k is the number of dim
fit # view results

# plot solution
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Nonmetric MDS", type="n")
text(x, y, labels = row.names(d[[1]]),col=1+row.names(d[[1]])%in%fpnms, cex=.7)
```

### age / sex dependence
```{r}
LogLinEps = function(fi,
                     age,
                     a0=0.065,
                     newdata=data.frame(age=age)
                     )
{
  #fit linear model with skew thing
    #i.e. log(fi+a0) = age
  
  #step 1. find optimal a0 by minimizing residual skew
  obj = function(par)
  {
    mod  = lm(log(fi+par)~age)
    return(abs(skew(mod$residuals)))
  }
  
  op = optim(a0,obj,method="Brent",lower=0.001,upper=.2)
  
  a = op[["par"]]
  
  #step 2. fit model
  mod = lm(log(fi+a)~age)
  
  pr = predict(mod,newdata,se.fit=T)
  pr[[1]] = exp(pr[[1]])-a
  pr[[2]] = (exp(pr[[1]]))*pr[[2]]
  
  return(list(pr=pr,mod=mod,op=op,a=a))
}
```

```{r}
agg = list()
aggse = list()
age_cuts = seq(60,85,by=5)
fimodelM = list()
fimodelseM = list()
fimodelF = list()
fimodelseF = list()
fimodel2M = list()
fimodel2seM = list()
fimodel2F = list()
fimodel2seF = list()
testage = seq(60,85,by=1)
for (i in 1:length(data))
{
  agg[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),mean,na.rm=T)
  aggse[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),SEM,na.rm=T)
   #drop age_cut and clean up type
  agg[[i]]=agg[[i]][,-1]
  aggse[[i]]=aggse[[i]][,-1]
  for (j in 1:ncol(agg[[i]]))
  {
    agg[[i]][,j] = as.numeric(as.character(agg[[i]][,j]))
    aggse[[i]][,j] = as.numeric(as.character(aggse[[i]][,j]))
  }
   
  
  agg[[i]] = as.matrix(agg[[i]])
  aggse[[i]] = as.matrix(aggse[[i]])
  
  fimodelM[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelM[[i]]) = c("age","fi")
  fimodelseM[[i]] = fimodelM[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==0))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelM[[i]][,1] = testage
  fimodelM[[i]][,2] = exp(pr[[1]])
  fimodelseM[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  fimodelF[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelF[[i]]) = c("age","fi")
  fimodelseF[[i]] = fimodelF[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==1))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelF[[i]][,1] = testage
  fimodelF[[i]][,2] = exp(pr[[1]])
  fimodelseF[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  
  fimodel2M[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2M[[i]]) = c("age","fi")
  fimodel2seM[[i]] = fimodel2M[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==0)[,"fi"],age=subset(data[[i]],sex==0)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2M[[i]][,1] = testage
  fimodel2M[[i]][,2] = pr[[1]]
  fimodel2seM[[i]][,2] = pr[[2]]
  
  fimodel2F[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2F[[i]]) = c("age","fi")
  fimodel2seF[[i]] = fimodel2F[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==1)[,"fi"],age=subset(data[[i]],sex==1)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2F[[i]][,1] = testage
  fimodel2F[[i]][,2] = pr[[1]]
  fimodel2seF[[i]][,2] = pr[[2]]
}

ageData = RubinMat(agg,aggse)
ageData[[1]] = data.frame(ageData[[1]])
ageData[[1]][,sprintf("%sse",colnames(ageData[[1]]))] = ageData[[2]]
ageData = ageData[[1]]

fiDataM = RubinMat(fimodelM,fimodelseM)
fiDataM[[1]] = data.frame(fiDataM[[1]])
fiDataM[[1]][,sprintf("%sse",colnames(fiDataM[[1]]))] = fiDataM[[2]]
fiDataM = fiDataM[[1]]
fiDataM[,"sex"] = "Male"
fiDataF = RubinMat(fimodelF,fimodelseF)
fiDataF[[1]] = data.frame(fiDataF[[1]])
fiDataF[[1]][,sprintf("%sse",colnames(fiDataF[[1]]))] = fiDataF[[2]]
fiDataF = fiDataF[[1]]
fiDataF[,"sex"] = "Female"
fiData = rbind(fiDataM,fiDataF)

fiData2M = RubinMat(fimodel2M,fimodel2seM)
fiData2M[[1]] = data.frame(fiData2M[[1]])
fiData2M[[1]][,sprintf("%sse",colnames(fiData2M[[1]]))] = fiData2M[[2]]
fiData2M = fiData2M[[1]]
fiData2M[,"sex"] = "Male"
fiData2F = RubinMat(fimodel2F,fimodel2seF)
fiData2F[[1]] = data.frame(fiData2F[[1]])
fiData2F[[1]][,sprintf("%sse",colnames(fiData2F[[1]]))] = fiData2F[[2]]
fiData2F = fiData2F[[1]]
fiData2F[,"sex"] = "Female"
fiData2 = rbind(fiData2M,fiData2F)

sex = rep("Female",nrow(ageData))
sex[ageData[,"sex"]==0] = "Male"
ageData[,"sex"] = sex

ggplot(ageData,aes(x=age,xmin=age-agese,xmax=age+agese,y=fi,ymin=fi-fise,ymax=fi+fise,colour=sex,fill=sex))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  geom_line(data=fiData)+
  geom_ribbon(data=fiData,alpha=.15,colour=NA)+
  geom_line(data=fiData2)+ #log-linear with intercept #looks same
  geom_ribbon(data=fiData2,alpha=.15,colour=NA)

save=T
if(save)
{
  write.csv(ageData,sprintf("%s/results/age_dependence_nhanes.csv",outputDir),row.names=T)
  write.csv(fiData,sprintf("%s/results/age_dependence_nhanes_logfi.csv",outputDir),row.names=T)
  write.csv(fiData2,sprintf("%s/results/age_dependence_nhanes_logepsfi.csv",outputDir),row.names=T)
}
```

# Q0. What does survival / health look like for individuals missing the fab-5?
```{r}
where = m$where
complete = apply(m$where[,fpVar],1,sum) == 0
complete = factor(complete,c(F,T),labels=c("Incomplete","Complete (fab-5)"))
thalf = summary(survfit(s~complete))$table[,"median"]
dt = round(diff(thalf),1)
pval = summary(coxph(s~complete))$sctest[3]
print(sprintf("p-value (score/logrank test): %s",pval))
g = ggsurv(survfit(s~complete),CI=T,plot.cens=F)+
    scale_x_continuous(limits=c(60,NA))+
    labs(x="Age",y="Survival")+
    annotate("segment",x=thalf[1],xend=thalf[2],y=.5,yend=.5,arrow = arrow(ends = "both", angle = 30, length = unit(.2,"cm")))+
    annotate("text",x=mean(thalf),y=.55,label=bquote(Delta*t[1/2]*"="*.(dt)))+
    annotate("text",x=mean(thalf),y=.475,label="***")+
    theme_minimal()+
    theme(title=element_text(),
          legend.title=element_blank(),
          legend.position=c(.8,.8))
g

print(summary(coxph(s~complete)))
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/missingness_bad_survival_nhanes.pdf",outputDir),
         g,width=8,height=6,dpi=300)
  
  ggsave(sprintf("%s/results/missingness_bad_survival_nhanes.png",outputDir),
         g,width=8,height=6,dpi=300)
}
```

Demographic stuff
post imputation, from functional deficit preprocessed data
```{r}
 
vars = c("bmi","weak","gait","exhausted","activity")
names(vars) = c("Weight loss","Weakness","Slow gait","Exhaustion", "Low activity")
vars = c(Age="age",Females="sex",FI="fi",NFab5="Nfp",FP="fp",vars)
prevalence = rep(T,length(vars)) #scale to % 
prevalence[vars %in% c("age","fi","Nfp")] = F
Ndigits = rep(0,length(vars))
Ndigits[vars %in% c("fi","Nfp")] = 2

#prevalence
pr = list()
prse = list()
prsd = list()
for (i in 1:length(data))
{
  #fix sex
  data[[i]][,"sex"] = as.numeric(as.character(data[[i]][,"sex"]))
  #add id column
  data[[i]][,"id"]=1:nrow(data[[i]])
  pr[[i]] = matrix(NA,nrow=length(vars),ncol=1)
  rownames(pr[[i]]) = names(vars)
  colnames(pr[[i]]) = "Frequency"
  prse[[i]] = pr[[i]]
  prsd[[i]] = pr[[i]]
  for (j in 1:length(vars)) 
  {
    pr[[i]][j,1] = mean(data[[i]][,vars[j]],na.rm=T)
    if(prevalence[j]) #binary variables
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    else  #non-binary
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    
  }
}

pr = RubinMat(pr,prse)
prsd = RubinMat(prsd)

demo = matrix(NA,nrow=nrow(pr[[1]])+2,ncol=2)

colnames(demo) = c("","Frequency/Mean")
demo[1,1] = "Individuals"
demo[1,2] = unlen(data[[1]][,"id"])
demo[2,1] = "Entries"
demo[2,2] = nrow(data[[1]])
skip = 1:2
demo[-skip,1] = rownames(pr[[1]])
demo[-skip,2][prevalence] = sprintf("%.1f%%",100*pr[[1]][prevalence,1]) #,100*prsd[[1]][prevalence,1])  #errors from imputation are small relative to sd so just ignore
demo[-skip,2][!prevalence] = sprintf("%.0f (%.0f)",pr[[1]][!prevalence,1],prsd[[1]][!prevalence,1]) 

demo[-skip,2][Ndigits == 2] = sprintf("%.2f (%.2f)",pr[[1]][Ndigits == 2,1],prsd[[1]][Ndigits == 2,1]) 

save=T
if(save)
{
  write.csv(demo,sprintf("%s/data/demographics_nhanes.csv",outputDir),row.names = F)
}
```

#correlation matrix

```{r}
BootCor = function(x,nboot=100,...)
{
  C = list()
  for (i in 1:nboot)
  {
    inds = sample(1:nrow(x),replace=T)
    C[[i]] = cor(x[inds,],...)
  }
  C = ListMeanSD(C)
  return(list(C=C[[1]],se=C[[2]]))
}
```

```{r}
C = list()
Cse = list()
vars = c("Nfp","fi","fifp","age")
method = "pearson"
#method = "spearman"
for (i in 1:length(data))
{
  C[[i]] = BootCor(data[[i]][,vars],use='pairwise.complete',method=method) 
  Cse[[i]] = C[[i]][[2]]
  C[[i]] = C[[i]][[1]]
}
C = RubinMat(C,Cse)

save=T
if(save)
{
  write.csv(C[[1]],sprintf("%s/results/%s_nhanes.csv",outputDir,method),row.names=T)
  write.csv(C[[2]],sprintf("%s/results/%s_nhanes_se.csv",outputDir,method),row.names=T)
}
```

################
# prevalence curves
################
```{r}
fpNames = c("fp",c("bmi","gait","weak","exhausted", "activity"))
names(fpNames) = fpNames
```


```{r}
library(splines2)
include="sqrt"
#include = c("linear","sqrt")
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
#nms = c("FP","Low BMI","Slow gait","Weakness","Exhaustion","Low activity")
nms = c("FP frailty","Low BMI","Slow gait","Feel weak","Exhaustion","Low activity")
#re-order to match others
nms = nms[c(1:2,4,3,5:6)]
outcomes = outcomes[c(1:2,4,3,5:6)]
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - spline
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    b = predict(bMat,data[[ii]][,"fi"])
    temp = data.frame(b)
    colnames(temp) = colnames(bMat)
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~.,data=temp,family=binomial)
    pr = predict(md,testMat,se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]

  plotdata = list(pr_agg,pr_agg_sq)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%include)
  
  #frequencies
  if(length(include)>1) g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))
  else g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse))
  g[[i]] = g[[i]] + geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=sprintf("(%s) %s",letters[i], nms[i]))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
  
}

#clean up legends
  #drop them all - use labels instead
cols = gg_color_hue(2)[1:2]
g[[1]] = g[[1]] + theme(legend.position=c(.2,.8),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")
g[[1]] = g[[1]] + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
g[[1]] = g[[1]] + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
g[[1]] = g[[1]] + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
for (i in 2:length(g)) g[[i]] = g[[i]]+theme(legend.position="none")

#labels
#library(ggrepel)
if(length(include)>1) for (i in 1:length(g)) g[[i]] = g[[i]] + labs(x=bquote("FI,"~f),y=bquote("Prevalence,"~p))


layout = matrix(1:6,nrow=2,ncol=3)
for (i in 1:nrow(layout)) layout[i,] = 1:ncol(layout)+(i-1)*ncol(layout)
marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout)

save=T
if(save)
{
  nm = "prevalence"
  #if(scale) nm = "prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  
  ggsave(sprintf("%s/results/%s_nhanes.pdf",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s_nhanes.png",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
}
```

By sex
```{r}
library(splines2)
include="sqrt"
#include = c("linear","sqrt")
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
fi_labs = levels(cut(seq(-1,1,by=.01),fi_cuts))
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
#nms = c("FP","Low BMI","Slow gait","Weakness","Exhaustion","Low activity")
nms = c("FP frailty","Low BMI","Slow gait","Feel weak","Exhaustion","Low activity")
#re-order to match others
nms = nms[c(1:2,4,3,5:6)]
outcomes = outcomes[c(1:2,4,3,5:6)]
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  pr_agg[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_aggF = RubinMat(l,lse)
  pr_aggF[[1]] = data.frame(pr_aggF[[1]])
  pr_aggF[[1]][,sprintf("%sse",colnames(pr_aggF[[2]]))] = pr_aggF[[2]]
  pr_aggF = pr_aggF[[1]]
  pr_aggF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  pr_agg_sq[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sqF = RubinMat(l,lse)
  pr_agg_sqF[[1]] = data.frame(pr_agg_sqF[[1]])
  pr_agg_sqF[[1]][,sprintf("%sse",colnames(pr_agg_sqF[[2]]))] = pr_agg_sqF[[2]]
  pr_agg_sqF = pr_agg_sqF[[1]]
  pr_agg_sqF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    agg = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(agg[,"fi_cut"]),] = agg[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(agg)
    rm(aggse)
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]
  agg[,"sex"] = "Male"

  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    aggtemp = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(aggtemp[,"fi_cut"]),] = aggtemp[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(aggtemp)
    rm(aggse)
  }
  aggF = RubinMat(l,lse)
  for (j in 1:length(aggF)) colnames(aggF[[j]])[2] = "pr"
  aggF[[1]] = data.frame(aggF[[1]])
  aggF[[1]][,sprintf("%sse",colnames(aggF[[2]]))] = aggF[[2]]
  aggF = aggF[[1]]
  aggF[,"sex"] = "Female"
  
  plotdata = list(pr_agg,pr_aggF,pr_agg_sq,pr_agg_sqF)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]][,"model"] = "sqrt"
  plotdata[[4]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%include)
  plotdata[,"sex"] = factor(plotdata[,"sex"],c("Female","Male"))
  
  agg = rbind(agg,aggF)
  
  #frequencies
  if(length(include)>1) 
  {
    g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))
  }   else g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,fill=sex,colour=sex,linetype=sex,shape=sex))
  g[[i]] = g[[i]] + geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=sex,shape=sex),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,colour=sex,shape=sex),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=sprintf("(%s) %s",letters[i], nms[i]))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
  
}

#clean up legends
g[[1]] = g[[1]] + theme(legend.position=c(.25,.8),legend.title=element_blank())
for (i in 2:length(g)) g[[i]] = g[[i]] + theme(legend.position="none")

layout = matrix(1:6,nrow=2,ncol=3)
for (i in 1:nrow(layout)) layout[i,] = 1:ncol(layout)+(i-1)*ncol(layout)
marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout)

save=T
if(save)
{
  nm = "prevalence"
  #if(scale) nm = "prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  
  ggsave(sprintf("%s/results/%s_nhanes_sex.pdf",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s_nhanes_sex.png",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
}
```

#######
#survival
#######

```{r}
library(eha)
mg = phreg(s~1,dist = "gompertz",param="rate")

```

```{r}
plot(s,xlim=c(60,100),ylim=c(0,1))
s0 = exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*60))/coef(mg)["rate"]) #looks a little better #we know they survived to 60
#s0 = 1 # looks very similar
curve(exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*x))/coef(mg)["rate"])/s0,add=T,col=2) #using eha fit
curve(exp(-Hgompertz(x,rate=coef(mg)["rate"],shape=exp(coef(mg)["log(level)"]),param="rate"))/s0,col=3,lty=3,add=T) #should be same
```

```{r}
library(MASS)
PHConfInt = function(ttest = seq(60,100,by=.1),
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    x=NULL, #named vector
                    t0=ttest[1]
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(ttest))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[names(x)]
      fits[i,] = exp(sum(beta*x))*(Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0)
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,t=ttest,x=x,t0=t0))
}

PHConfInt2VecX = function(x, #vector of values
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    t0=60
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[1]
      fits[i,] = exp(beta*x)*Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,x=x,ttest=ttest,t0=t0))
}

PHConfInt.hazard = function(x, #matrix or data.frame of covariates
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    param="rate" #phreg lets you fit differently
                    )
{
  x = as.matrix(x)
  param  = tolower(param)

  fits = matrix(NA,nrow=N,ncol=nrow(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(x)) 
    {
      if(param=="rate") fits[i,] = hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
    else 
    {
      #print(par)
      #print(colnames(x))
      beta = par[colnames(x)]
      #print(beta)
      #print(head(x%*%beta))
      #fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      if(param=="rate") fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
  }
  h = apply(fits,2,mean,na.rm=T)
  hsd = apply(fits,2,sd,na.rm=T)
  hmin = h-errorScale*hsd
  hmax = h+errorScale*hsd

    
  return(list(h=h,hsd=hsd,hmin=hmin,hmax=hmax,fit=fit,N=N,x=x,ttest=ttest,t0=t0,param=param))
}

GompertzHazard = function(t,fit)
{
  #survival:
  #plot(s)
  #curve(exp(baselineHazard*exp(beta*x)*(1-exp(alpha*t))/alpha)/s0,add=T,col=2)
  h = exp(coef(fit)["log(level)"])*exp(coef(fit)["rate"]*t)*exp(coef(fit)["rate"])
  return(h)
    
}

t = PHConfInt(fit=mg)

plot(s,xlim=c(60,100),ylim=c(0,1))
lines(t[["t"]],t[["S"]],col=2)
lines(t[["t"]],t[["Smin"]],col=2,lty=2)
lines(t[["t"]],t[["Smax"]],col=2,lty=2)
```

fits near the end and that's what we really care about

```{r}
library(eha)
fit = phreg(s~(fi),data=stst[[1]],dist = "gompertz",param="rate")

```

```{r}
library(scico)
st = stst[[1]]
#st[,"fi"] = sqrt(st[,"fi"])
sst = s
conf.int = pnorm(1)-pnorm(-1)
#conf.int = .95
#cuts = c(-Inf,-2:1+.5,Inf)
#zq = cut(st[,"z01"],cuts)
probs = seq(0,1,length=3)
cuts = quantile(st[,"fi"],probs=probs)

zq = cut(st[,"fi"],cuts,labels = sprintf("%.0f%%",round(probs[-1]*100)))
cols = scico(length(levels(zq)), palette = 'roma')
t = seq(60,100,by=1)
fitdata = list()
for (j in 1:length(levels(zq)))
{
  muzq = mean(st[zq==levels(zq)[j],"fi"],na.rm=T)
  x = c(fi=muzq)
  #names(x)="sqrt(fi)"
  H = PHConfInt(ttest=t,N=1000,fit=fit,errorScale=qnorm(.975),x=x,t0=60)
  
  fitdata[[j]] = data.frame(strata=levels(zq)[j],
                            #t=t,
                            t=H[["t"]],
                            #H=exp(coef(fit)[1]*muzq)*Hgompertz(t,rate=coef(fit)["rate"],shape=exp(coef(fit)["log(level)"]),param="rate")
                            H=H[["H"]],
                            Hmin=H[["Hmin"]],
                            Hmax=H[["Hmax"]],
                            dH=H[["Hsd"]]
                  )
}
fitdata=do.call(rbind,fitdata)
#fitdata[,"dH"] = 0
fitdata[,"S"] = exp(-fitdata[,"H"])
#fitdata[,"dS"] = 0
fitdata[,"Smin"] = exp(-fitdata[,"Hmin"])
fitdata[,"Smax"] = exp(-fitdata[,"Hmax"])
fitdata[,"strata"]= factor(fitdata[,"strata"],levels(zq))

sf = survfit(sst ~ z,data=data.frame(z=zq),conf.int=conf.int)
group = rep("unknown",length(sf$cumhaz))
ind = 0
for (j in 1:length(sf$strata))
{
  group[1:sf$strata[j]+ind] = gsub("z=","",names(sf$strata)[j])
  ind = ind + sf$strata[j]
}
group = factor(group,levels(zq))
  
#survival
logi = !is.na(sf$upper) & !is.na(sf$lower)
g = ggplot(data.frame(t=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,strata=group)[logi,],
       aes(x=t,y=S,ymin=Smin,ymax=Smax,colour=strata,fill=strata))+
  geom_line(lty=2)+
  geom_ribbon(alpha=.5,colour=NA)+
  #scale_colour_manual(breaks=levels(group),values=cols)+
  #scale_fill_manual(breaks=levels(group),values=cols)+
  #scale_colour_discrete_diverging("Blue-Red")+
  #scale_fill_discrete_diverging("Blue-Red")+
  scico::scale_color_scico_d(palette="roma")+
  scico::scale_fill_scico_d(palette="roma")+
  labs(y="Survival",x="Years on dialysis",colour="Percentile",fill="Percentile",linetype="")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
          legend.position= "right", #c(.6,.3), #
          legend.key.size = unit(4,"line"),
          legend.text=element_text(size=gTextSize*.9)#,
          #legend.title=element_blank()
        )


g = g + geom_line(data=fitdata,lwd=1,inherit.aes=F,mapping=aes(x=t,y=S,colour=strata,linetype="Fit"))
g = g + geom_ribbon(data=fitdata,colour=NA,alpha=.15)

g = g + scale_x_continuous(limits=c(60,100))
g = g + scale_y_continuous(limits=c(0,1))

g


save = T
if(save)
{
  ggsave(sprintf("%s/results/survival_diagnostic_fi_nhanes.pdf",outputDir),
           g,width=8,height=6,dpi=300)
  ggsave(sprintf("%s/results/survival_diagnostic_fi_nhanes.png",outputDir),
           g,width=8,height=6,dpi=300)
}

```

```{r}
library(splines2)
ttest = 60
t0 = 60
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.1),1)
#fi_cuts = c(seq(0,.6,by=.05),1)
#fi_cuts = c(0,seq(0.01,.6,by=.1),1) #bad idea... very low FI have basically 0 risk


#linear
l = list()
lse = list()
param = list()
paramse = list()
paramsemat = list()
blin = numeric()
for(ii in 1:length(stst))
{
  md = phreg(s~fi,data=stst[[ii]],dist = "gompertz",param="rate")
  #md = phreg(s~fi,data=stst[[ii]],dist = "gompertz",param="canonical") #very similar

  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=data.frame(fi=testfi),param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  
  param[[ii]] = matrix(coef(md),nrow=1,ncol=length(coef(md)))
  colnames(param[[ii]]) = names(coef(md))
  paramse[[ii]] = matrix(diag(md[["var"]]),nrow=1,ncol=length(coef(md)))
  colnames(paramse[[ii]]) = names(coef(md))
  paramsemat[[ii]] = as.matrix(md[["var"]])
  blin[ii] = BIC(md)
}
pr_agg = RubinMat(l,lse)
pr_agg[[1]] = data.frame(pr_agg[[1]])
pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
pr_agg = pr_agg[[1]]
blin=mean(blin)
rm(l)
rm(lse)
  
param = RubinMat(param,paramse,checkAlignment = F)
paramsemat = RubinMat(paramsemat)
  
#gompertz - sqrt
l = list()
lse = list()
bsq = numeric()
for(ii in 1:length(stst))
{
  md = phreg(s~sqrt(fi),data=stst[[ii]],dist = "gompertz",param="rate") #fails
  #md = phreg(s~sqrt(fi),data=stst[[ii]],dist = "gompertz",param="canonical") ##probably wrong

  test = data.frame(sqrt(testfi))
  colnames(test) = "sqrt(fi)"
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=test,param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  bsq[ii] = BIC(md)
}
pr_agg_sq = RubinMat(l,lse)
pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
pr_agg_sq = pr_agg_sq[[1]]
bsq=mean(bsq)
rm(l)
rm(lse)


#gompertz - spline
l = list()
lse = list()
bsp = numeric()
for(ii in 1:length(stst))
{
  b = predict(bMat,stst[[ii]][,"fi"])
  temp = data.frame(b)
  colnames(temp) = colnames(bMat)
  
  md = phreg(s~.,data=temp,dist = "gompertz",param="rate")
  #md = phreg(s~.,data=temp,dist = "gompertz",param="canonical") #waaaaaaay off
  
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=testMat,param=md[["param"]])

  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  bsp[ii] = BIC(md)
}
pr_agg_sp = RubinMat(l,lse)
pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
pr_agg_sp = pr_agg_sp[[1]]
bsp = mean(bsp)
rm(l)
rm(lse)

#population stats
#still has to use coxph because of censorship
l = list()
lse = list()
boh = numeric()
for(ii in 1:length(stst))
{
  temp = stst[[ii]]
  temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
  
  md = phreg(s~fi_cut,data=temp,dist = "gompertz",param="rate")
  #md = phreg(s~fi_cut,data=temp,dist = "gompertz",param="canonical") #very similar
    
  test = data.frame(y=NA,fi=testfi)
  test[,"fi_cut"] = cut(test[,"fi"],fi_cuts,include.lowest=T)
  test = aggregate(test[,c("y","fi")],by=list(fi_cut=test[,"fi_cut"]),mean,na.rm=T) #compress down into 1 / unique value
  test[,"fise"] = aggregate(test[,c("fi"),drop=F],by=list(fi_cut=test[,"fi_cut"]),SEM,na.rm=T)[,"fi"]
  #one-hot:
  beta = coef(md)[!(names(coef(md))%in%c("rate","log(level)","log(scale)","log(shape)"))]
  onehot = matrix(0,nrow=nrow(test),ncol=length(beta))
  nms = character()
  for (jj in 1:length(beta)) nms[jj] = strsplit(names(beta)[jj],"fi_cut")[[1]][2]
  for (jj in 1:nrow(test)) 
  {
      onehot[jj,] = as.integer(nms == test[jj,"fi_cut"])
  }
    
  colnames(onehot) = names(beta)

  
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=onehot,param=md[["param"]])

  l[[ii]] = as.matrix(data.frame(fi=test[,"fi"],pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  boh[ii] = BIC(md)
}
agg = RubinMat(l,lse)
for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
agg[[1]] = data.frame(agg[[1]])
agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
agg = agg[[1]]
boh = mean(boh)

plotdata = list(pr_agg,pr_agg_sq,pr_agg_sp) #spline is just overfitting #
plotdata[[1]][,"model"] = "linear"
plotdata[[2]][,"model"] = "sqrt"
plotdata[[3]][,"model"] = "spline"
plotdata = do.call(rbind,plotdata)

#errorbars are errors not CIs
g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="NHANES")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()

#errorbars are errors not CIs
g = ggplot(pr_agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="NHANES")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()

g

#errorbars are errors not CIs
save=T
if(save)
{
  ggsave(sprintf("%s/results/hazard_nhanes_gompertz.pdf",outputDir),g,width=9,height=8,dpi=300)
  ggsave(sprintf("%s/results/hazard_nhanes_gompertz.png",outputDir),g,width=9,height=8,dpi=300)
  
  #table of coefficients
  tb = data.frame(beta=sprintf("%.3f pm %.3f",param[[1]][1,"fi"],param[[2]][1,"fi"]),
                  alpha=sprintf("%.3f pm %.3f",param[[1]][1,"rate"],param[[2]][1,"rate"]),
                  lnh0=sprintf("%.3f pm %.3f",param[[1]][1,"log(level)"],param[[2]][1,"log(level)"]),
                  h0=sprintf("%.3f pm %.3f",exp(param[[1]][1,"log(level)"]),exp(param[[1]][1,"log(level)"])*param[[2]][1,"log(level)"])
                  )
  write.csv(tb,sprintf("%s/results/hazard_nhanes_gompertz.csv",outputDir))
  write.csv(paramsemat,sprintf("%s/results/hazard_nhanes_gompertz_errors.csv",outputDir))
  print("fit parameters:")
  print(tb)
  
  #will load these in elsewhere to compare to HRS 
  write.csv(pr_agg,sprintf("%s/results/hazard_nhanes_gompertz_pragg.csv",outputDir),row.names=F)
  write.csv(agg,sprintf("%s/results/hazard_nhanes_gompertz_agg.csv",outputDir),row.names=F)
}

qplot(c("linear","sqrt","spline","one-hot"),c(blin,bsq,bsp,boh),ylab="BIC",xlab="",main="Model selection")
```


```{r}
where = m$where
g = list()
for (j in 1:length(fpVar))
{
  x = rep("Reported",nrow(m$where))
  x[m$where[,fpVar[j]]] = "Missing"
  g[[j]] = ggsurv(survfit(s~x),CI=T,plot.cens=F)+
    scale_x_continuous(limits=c(50,NA))+
    labs(x="Age",y="Survival")+
    ggtitle(names(fpNames)[j])+
    theme_minimal()+
    theme(title=element_text(),
          legend.title=element_blank(),
          legend.position=c(.25,.25))
}
marrangeGrob(g,nrow=2,ncol=3,top=NULL)
```
Is value of Nfp likely to be higher if we're missing variables?

```{r}
mat = list()
matSE = list()
for (i in 1:length(stst))
{
  #JUST the imputed values
  imp = as.matrix(stst[[i]][,fpNames])
  imp[!m$where[,fpVar]] = NA
  
  #EXCLUDE the imputed values
  obs = as.matrix(stst[[i]][,fpNames])
  obs[m$where[,fpVar]] = NA
  
  #group by number missing
  Nmiss = apply(m$where[,fpVar],1,sum)
  groups = sort(unique(Nmiss))
  Nfp_imp = numeric()
  Nfp_imp_se = numeric()
  fi_imp = numeric()
  fi_imp_se = numeric()
  mu_imp = numeric()
  se_imp = numeric()
  mu_obs = numeric()
  se_obs = numeric()
  fp_prev_imp = numeric()
  fp_prev_imp_se = numeric()
  fp_prev_obs = numeric()
  fp_prev_obs_se = numeric()
  for (j in 1:length(groups))
  {
    logi = Nmiss==groups[j]
    Nfp_imp[j] = mean(stst[[i]][logi,"Nfp"])
    Nfp_imp_se[j] = SEM(stst[[i]][logi,"Nfp"])
    fi_imp[j] = mean(stst[[i]][logi,"fi"])
    fi_imp_se[j] = SEM(stst[[i]][logi,"fi"])
    mu_imp[j] = mean(imp[logi,],na.rm=T)
    se_imp[j] = SEM(c(imp[logi,]),na.rm=T)
    mu_obs[j] = mean(obs[logi,],na.rm=T)
    se_obs[j] = SEM(c(obs[logi,]),na.rm=T)
    fp_prev_imp[j] = mean(stst[[i]][logi,"Nfp"]>2.99)
    fp_prev_imp_se[j] = SEM(stst[[i]][logi,"Nfp"]>2.99)
    fp_prev_obs[j] = mean(apply(obs[logi,,drop=F],1,sum,na.rm=T)>2.99)
    fp_prev_obs_se[j] = SEM(apply(obs[logi,,drop=F],1,sum,na.rm=T)>2.99)
  }
  
  #(relative) hazard for each group
  cph = coxph(s~factor(Nmiss,groups))
  beta = c(0,summary(cph)$coefficients[,"coef"])
  beta_se = c(NA,summary(cph)$coefficients[,"se(coef)"])  
  
  mat[[i]] = as.matrix(data.frame(Nfp_imp=Nfp_imp,fi_imp=fi_imp,Nmiss=groups,mu_imp=mu_imp,mu_obs=mu_obs,beta=beta,
                                  fp_imp=fp_prev_imp,fp_obs=fp_prev_obs))
  matSE[[i]] = as.matrix(data.frame(Nfp_imp=Nfp_imp_se,fi_imp=fi_imp_se,Nmiss=0,mu_imp=se_imp,mu_obs=se_obs,beta=beta_se,
                                    fp_imp=fp_prev_imp_se,fp_obs=fp_prev_obs_se))
}
nfpImp = RubinMat(mat,lse=matSE)

#looks bad
#plotdata = data.frame(nfpImp[[1]])
#ggplot(plotdata,aes(x=ordered(Nmiss,0:5),y=mu_obs))+geom_boxplot()
```

```{r}
plotdata = list()
plotdata[[1]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"mu_obs"],se=nfpImp[[2]][,"mu_obs"],group="Deficit (fab-5)")
plotdata[[2]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"fp_imp"],se=nfpImp[[2]][,"fp_imp"],group="FP (imputed)")
plotdata[[3]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"fp_obs"],se=nfpImp[[2]][,"fp_obs"],group="FP (observed)")
#plotdata[[4]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"beta"],se=nfpImp[[2]][,"beta"],group="Hazard ratio (log scale)")
#plotdata[[4]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"mu_imp"],se=nfpImp[[2]][,"mu_imp"],group="Imputed Deficit Prevalence")
#plotdata[[4]] = data.frame(Nmiss=nfpImp[[1]][,"Nmiss"],y=nfpImp[[1]][,"fi_imp"],se=nfpImp[[2]][,"fi_imp"],group="FI (imputed)")
plotdata = do.call(rbind,plotdata)

mubeta = mean(nfpImp[[1]][2:4,"beta"])

g= ggplot(subset(plotdata, Nmiss < 5),aes(x=Nmiss,y=y,ymin=y-se,ymax=y+se,colour=group,shape=group))+
  geom_pointrange(position=position_dodge(.1))+
  labs(x="Number of missing variables (fab-5)",y="Prevalence")+
  #geom_smooth(mapping=aes(weight=1/se^2),method="lm",formula=y~x,se=F)+
  geom_smooth(data=subset(plotdata,group=="Deficit (fab-5)" & Nmiss < 5), mapping=aes(weight=1/se^2),method="lm",formula=y~x,se=F, lty=2)+
  geom_smooth(data=subset(plotdata,group=="FP (imputed)" & Nmiss < 5), mapping=aes(weight=1/se^2),method="lm",formula=y~x,se=F, lty=2)+
  #geom_smooth(data=subset(plotdata,group=="Hazard ratio (log scale)" & Nmiss < 5 & Nmiss > 0),method="lm",formula=y~1,se=F, lty=2)+
  #geom_segment(x=1,xend=3,y=mubeta,yend=mubeta,colour=gg_color_hue(2)[2],lty=2,size=1)+   
  #geom_segment(x=0,xend=1,y=0,yend=0,colour=gg_color_hue(2)[2],lty=2,size=1)+
  #geom_segment(x=1,xend=1,y=0,yend=mubeta,colour=gg_color_hue(2)[2],lty=2,size=1)+
  theme_minimal()+
  theme(legend.title=element_blank(),legend.position=c(.2,.8))
g
```
```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/missingness_bad_nhanes.pdf",outputDir),
         g,width=8,height=6,dpi=300)
  
  ggsave(sprintf("%s/results/missingness_bad_nhanes.png",outputDir),
         g,width=8,height=6,dpi=300)
}
```


################
# death prevalence curves
################
probability of dying within the followup time (4 years)

use kaplan-meier non-parametric estimator for points
linear interpolator
problem: apparently the estimator is biased. but forcing gompertz is also biased. only solution is to use survpen and make sure I recover kaplan meier result

```{r}
library(eha)
library(survPen)
```

```{r}
#note: survfit(s~x) is same as just splitting up by x strata
NonParSurv = function(s,t,conf.int=pnorm(1)-pnorm(-1))
{
  sf = survfit(s~1,conf.int=conf.int)
  app = approxfun(x=sf$time,y=sf$surv,yleft = 1,yright=NA)
  applow = approxfun(x=sf$time,y=sf$lower,yleft = 1,yright=NA)
  apphigh = approxfun(x=sf$time,y=sf$upper,yleft = 1,yright=NA)
  return(data.frame(pr=app(t),prlow=applow(t),prhigh=apphigh(t)))
}


NonParSurv.cox = function(s,
                        pr, #coxph model predicted risk #pr = predict(fit,data.frame(my$x),type="risk")
                        t=4,
                        t0=0,
                        conf.int=pnorm(1)-pnorm(-1))
{
  #returns probablity of surviving form t0 to t
  #assumes proportional hazard -> S = (S0)^(exp(beta*x)) = (S0)^pr
  #Q. do I need to center the predictors? Answer: no.
  #returns data.frame with nrow = length(pr)  
    #i.e. individual baseline survival probabilities
  sf = survfit(s~1,conf.int=conf.int)
  app = approxfun(x=sf$time,y=sf$surv,yleft = 1,yright=NA)
  applow = approxfun(x=sf$time,y=sf$lower,yleft = 1,yright=NA)
  apphigh = approxfun(x=sf$time,y=sf$upper,yleft = 1,yright=NA)

  if(t0 != 0)
  {
    pr = 1-(app(t)/app(t0))^pr
    prlow = 1-(applow(t)/applow(t0))^pr
    prhigh = 1-(apphigh(t)/apphigh(t0))^pr
  }
  else
  {
    pr = 1-(app(t))^pr
    prlow = 1-(applow(t))^pr
    prhigh = 1-(apphigh(t))^pr
  }
  
    return(data.frame(pr=pr,prlow=prlow,prhigh=prhigh))
}

```


```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
ttest = 4 #followup time
t0=0
fi_cuts = c(seq(0,.6,by=.1),1)

bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)

  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    md = phreg(s2~fi,data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~fi,data=stst[[ii]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age


    md = phreg(s2~sqrt(fi),data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testfi),N = 1000,fit=md,errorScale=1,ttest=ttest,t0=t0)

    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  #spline #I want to make sure I recover kaplain-meier if I crank up fit (since it's purportedly biased)
    #gotta use survpen since we don't know if Gompertz is right
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    temp = stst[[ii]]
    temp[,"status"] = s[,3]
    temp[,"tstart"] =  s[,1]-s[,1]
    temp[,"tstop"] =  s[,2]-s[,1]
    md = survPen(~smf(tstop)+smf(fi),data=subset(temp,!is.na(tstart)),t0=tstart,t1=tstop,event=status) #drop NAs (topcoded ages)
    pr = predict(md,newdata=data.frame(tstop=ttest,fi=testfi,tstart=t0),conf.int=pnorm(1)-pnorm(-1))
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["surv"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["surv.inf"]]/2-pr[["surv.sup"]]/2)))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    fic = cut(stst[[ii]][,"fi"],fi_cuts,include.lowest=T)
    temp = data.frame(fi_cut=levels(fic))
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    
    for (jj in 1:nrow(temp))
    {
      logi = fic == temp[jj,"fi_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1)) #,t0=t0 #can;t take t0 (yet)
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = abs(pr[["prhigh"]]/2-pr[["prlow"]]/2)
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"fi"] = mean(stst[[ii]][logi,"fi"],na.rm=T)
      temp[jj,"fise"] = SEM(stst[[ii]][logi,"fi"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("fi","pr")])
    lse[[ii]] = as.matrix(temp[,c("fise","prse")])
    
    logitmod = lm(log(pr/(1-pr))~sqrt(fi),temp,weights=1/(temp[,"prse"]^2+temp[,"fise"]^2)) #weights look worse (overfit) #sqrt > linear (closer to spline)
    pr = predict(logitmod,data.frame(fi=testfi),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(fi=testfi,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit,pr_agg_sp)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%c("logit","spline"))
  
  #frequencies
  g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  
  g
  
  
  pr_agg[,"dt"] = ttest-t0
  pr_agg[,"dtse"] = 0
  pr_agg_sq[,"dt"] = ttest-t0
  pr_agg_sq[,"dtse"] = 0
  pr_agg_sp[,"dt"] = ttest-t0
  pr_agg_sp[,"dtse"] = 0
  pr_agg_logit[,"dt"] = ttest-t0
  pr_agg_logit[,"dtse"] = 0
  agg[,"dt"] = ttest-t0
  agg[,"dtse"] = 0

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/death_prevalence_nhanes_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/death_prevalence_nhanes_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_sp,sprintf("%s/data/death_prevalence_nhanes_logit_pragg_sp.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/death_prevalence_nhanes_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/death_prevalence_nhanes_logit_agg.csv",outputDir),row.names=F)
  }

save=T
if(save)
{
  ggsave(sprintf("%s/results/death_prevalence_nhanes.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/death_prevalence_nhanes.png",outputDir),g,width=8,height=8,dpi=300)
  

}
```

age - death prevalence

```{r}
library(splines2)
testage = seq(60,85,by=1)
ttest = 4 #followup time
t0 = 0
age_cuts = c(seq(60,85,by=5))



  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    md = phreg(s2~age,data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest,t0=t0)
    #md = phreg(s2~age,data=stst[[ii]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    md = phreg(s2~sqrt(age),data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testage),N = 1000,fit=md,errorScale=1,ttest=ttest,t0=t0)

    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    agec = cut(stst[[ii]][,"age"],age_cuts,include.lowest=T)
    temp = data.frame(age_cut=levels(agec))
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = agec == temp[jj,"age_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = pr[["prhigh"]]/2-pr[["prlow"]]/2
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"age"] = mean(stst[[ii]][logi,"age"],na.rm=T)
      temp[jj,"agese"] = SEM(stst[[ii]][logi,"age"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("age","pr")])
    lse[[ii]] = as.matrix(temp[,c("agese","prse")])
    
    logitmod = lm(log(pr/(1-pr))~age,temp)#,weights=1/(temp[,"prse"]^2+temp[,"agese"]^2))
    pr = predict(logitmod,data.frame(age=testage),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(age=testage,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(age=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g = ggplot(plotdata,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  

  
  
  pr_agg[,"dt"] = ttest-t0
  pr_agg[,"dtse"] = 0
  pr_agg_sq[,"dt"] = ttest-t0
  pr_agg_sq[,"dtse"] = 0
  pr_agg_logit[,"dt"] = ttest-t0
  pr_agg_logit[,"dtse"] = 0
  agg[,"dt"] = ttest-t0
  agg[,"dtse"] = 0

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/age_death_prevalence_nhanes_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/age_death_prevalence_nhanes_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/age_death_prevalence_nhanes_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/age_death_prevalence_nhanes_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/age_death_prevalence_nhanes.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_death_prevalence_nhanes.png",outputDir),g,width=8,height=8,dpi=300)
  

}
#plot(log(pr/(1-pr))~age,agg) #non-linear even here!
```

```{r}
plot(agg[,"age"],log(agg[,"pr"])-log(1-agg[,"pr"]))
abline(lm(log(pr/(1-pr))~age,agg))

plot(sqrt(agg[,"age"]),log(agg[,"pr"])-log(1-agg[,"pr"]))
abline(lm(log(pr/(1-pr))~sqrt(age),agg))
```

Nfp - death prevalence

```{r}
library(splines2)
testNfp = seq(0,5,by=.1)
ttest = 4 #followup time
t0 = 0
Nfp_cuts = 0:5



  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    md = phreg(s2~Nfp,data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testNfp,N = 1000,fit=md,errorScale=1,ttest=ttest,t0=t0)
    #md = phreg(s2~Nfp,data=stst[[ii]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testNfp,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age

    md = phreg(s2~sqrt(Nfp),data=stst[[ii]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testNfp),N = 1000,fit=md,errorScale=1,ttest=ttest,t0=t0)

    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    Nfpc = cut(stst[[ii]][,"Nfp"],Nfp_cuts,include.lowest=T)
    temp = data.frame(Nfp_cut=levels(Nfpc))
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = Nfpc == temp[jj,"Nfp_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = pr[["prhigh"]]/2-pr[["prlow"]]/2
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"Nfp"] = mean(stst[[ii]][logi,"Nfp"],na.rm=T)
      temp[jj,"Nfpse"] = SEM(stst[[ii]][logi,"Nfp"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("Nfp","pr")])
    lse[[ii]] = as.matrix(temp[,c("Nfpse","prse")])
    
    logitmod = lm(log(pr/(1-pr))~Nfp,temp)#,weights=1/(temp[,"prse"]^2+temp[,"agese"]^2))
    pr = predict(logitmod,data.frame(Nfp=testNfp),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(Nfp=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g = ggplot(plotdata,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=Nfp,xmin=Nfp-Nfpse,xmax=Nfp+Nfpse,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x=gFab5Name,y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  

  
  
  pr_agg[,"dt"] = ttest-t0
  pr_agg[,"dtse"] = 0
  pr_agg_sq[,"dt"] = ttest-t0
  pr_agg_sq[,"dtse"] = 0
  pr_agg_logit[,"dt"] = ttest-t0
  pr_agg_logit[,"dtse"] = 0
  agg[,"dt"] = ttest-t0
  agg[,"dtse"] = 0

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/Nfp_death_prevalence_nhanes_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/Nfp_death_prevalence_nhanes_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/Nfp_death_prevalence_nhanes_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/Nfp_death_prevalence_nhanes_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/Nfp_death_prevalence_nhanes.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/Nfp_death_prevalence_nhanes.png",outputDir),g,width=8,height=8,dpi=300)
  

}
#plot(log(pr/(1-pr))~Nfp,agg) #non-linear even here!
```

stratify by age - can't get a decent fit :(

################
# Cox models for death
################
Could also do Gompertz or spline...
```{r}
preds = c("sex","age","fi","bmi","gait","weak","exhausted","activity")

names(preds)=c("Female","Age per 10","FI per 0.1","Low BMI","Slow","Weakness","Exhaustion","Low activity")
use = list()
use[[1]] = preds %in% c("fi")
use[[2]] = preds %in% c("age","sex")
use[[3]] = preds %in% c("age","sex","fi")
use[[4]] = preds == preds


C = list()
Cse = list()
for (ii in 1:length(stst))
{
    s2 = s
    s2 = Surv(s[,1]-s[,1],s[,2]-s[,1],s[,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]]))
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2 = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2) = dimnames(C[[1]])
for (j in 1:length(preds)) C2[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2[is.na(C[[1]])] = ""
C2[,"BIC"] = sprintf("%.0f",C[[1]][,"BIC"])
C2[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2)[colnames(C2)==preds[j]] = names(preds)[j]

write.csv(C2,sprintf("%s/results/nhanes_cox.csv",outputDir),row.names=FALSE)
```
# Cox by sex
```{r}
#MALES
#MALES
#MALES
preds = c("age","fi","bmi","gait","weak","exhausted","activity")

names(preds)=c("Age per 10","FI per 0.1","Low BMI","Slow","Weakness","Exhaustion","Low activity")
use = list()
use[[1]] = preds %in% c("age")
use[[2]] = preds %in% c("fi")
use[[3]] = preds %in% c("age","fi")
use[[4]] = preds == preds


C = list()
Cse = list()
for (ii in 1:length(stst))
{
  logi = stst[[ii]][,"sex"] == 0
    s2 = s[logi,]
    s2 = Surv(s[logi,1]-s[logi,1],s[logi,2]-s[logi,1],s[logi,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]])-1)
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][logi,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2M = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2M) = dimnames(C[[1]])
for (j in 1:length(preds)) C2M[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2M[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2M[is.na(C[[1]])] = ""
colnames(C2M)[colnames(C2M)=="BIC"] = "deltaBIC"
C2M[,"deltaBIC"] = sprintf("%.0f",C[[1]][,"BIC"]-C[[1]][1,"BIC"])
C2M[1,"deltaBIC"] = "Ref."
C2M[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2M)[colnames(C2M)==preds[j]] = names(preds)[j]

write.csv(C2M,sprintf("%s/results/nhanes_male_cox.csv",outputDir),row.names=FALSE)

#FEMALE
#FEMALE
#FEMALE
#FEMALE
C = list()
Cse = list()
for (ii in 1:length(stst))
{
  logi = stst[[ii]][,"sex"] == 1
    s2 = s[logi,]
    s2 = Surv(s[logi,1]-s[logi,1],s[logi,2]-s[logi,1],s[logi,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]])-1)
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][logi,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2F = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2F) = dimnames(C[[1]])
for (j in 1:length(preds)) C2F[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2F[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2F[is.na(C[[1]])] = ""
colnames(C2F)[colnames(C2F)=="BIC"] = "deltaBIC"
C2F[,"deltaBIC"] = sprintf("%.0f",C[[1]][,"BIC"]-C[[1]][1,"BIC"])
C2F[1,"deltaBIC"] = "Ref."
C2F[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2F)[colnames(C2F)==preds[j]] = names(preds)[j]

write.csv(C2F,sprintf("%s/results/nhanes_female_cox.csv",outputDir),row.names=FALSE)
C2 = cbind(t(C2M),t(C2F))
C2 = rbind("",C2)
rownames(C2)[1] = "Predictor or measure"
C2[1,1] = "NHANES - Males"
C2[1,5] = "NHANES - Females"
write.csv(C2,sprintf("%s/results/nhanes_sex_cox.csv",outputDir),row.names=TRUE)
```

# Cox assumption
```{r}
prname="fi"
#cuts = c(0,.05,seq(.15,.65,by=.1),1)
cuts = c(seq(0,.65,by=.1),1)
ytest = seq(0,.8,by=.01)
labs = unique(cut(seq(0,1,by=.1),cuts,include.lowest=T))
fitdata = list()
prdata = list()
fitdatase = list()
prdatase = list()
for (i in 1:length(stst))
{
  pr = stst[[i]][,prname]
  pr = cut(pr,cuts,labels=labs,include.lowest=T)
  #pr = factor(pr,sortedlabs) #refactor so that middle quantile is first
  vals = aggregate(stst[[i]][,prname],by=list(q=pr),mean,na.rm=T)
  vals_se = aggregate(stst[[i]][,prname],by=list(q=pr),SEM,na.rm=T)
  
  mod = coxph(s~pr)
  C = summary(mod)$coefficients
  
  fitdata[[i]] = data.frame(beta=c(0,C[,"coef"]),y=vals[,"x"])
  colnames(fitdata[[i]]) = gsub("y",prname,colnames(fitdata[[i]]))
  #colnames(fitdata[[i]]) = gsub("beta","pr",colnames(fitdata[[i]]))
  fitdata[[i]] = as.matrix(fitdata[[i]])
  
  fitdatase[[i]] = data.frame(beta=c(0,C[,"se(coef)"]),y=vals_se[,"x"])
  colnames(fitdatase[[i]]) = gsub("y",prname,colnames(fitdatase[[i]]))
  #colnames(fitdatase[[i]]) = gsub("beta","pr,colnames(fitdatase[[i]]))
  fitdatase[[i]] = as.matrix(fitdatase[[i]])
  
  temp = data.frame(y=stst[[i]][,prname])
  m = coxph(s~y,temp)
  prdata[[i]] = data.frame(y=ytest)
  prdatase[[i]] = data.frame(y=rep(0,length(ytest)))
  pr = predict(m,prdata[[i]],se.fit=T,type="lp")
  prdata[[i]][,"pr"] = pr[[1]]
  prdatase[[i]][,"pr_se"] = pr[[2]]
  
  colnames(prdata[[i]]) = gsub("y",prname,colnames(prdata[[i]]))
  colnames(prdata[[i]]) = gsub("pr","beta",colnames(prdata[[i]]))
  prdata[[i]] = as.matrix(prdata[[i]])
  colnames(prdatase[[i]]) = gsub("y",prname,colnames(prdatase[[i]]))
  colnames(prdatase[[i]]) = gsub("pr","beta",colnames(prdatase[[i]]))
  prdatase[[i]] = as.matrix(prdatase[[i]])
}
fitdata = RubinMat(fitdata,fitdatase)
fitdata[[1]] = as.data.frame(fitdata[[1]])
fitdata[[1]][,sprintf("%sse",colnames(fitdata[[1]]))] = fitdata[[2]]
fitdata = fitdata[[1]]
prdata = RubinMat(prdata,prdatase)
prdata[[1]] = as.data.frame(prdata[[1]])
prdata[[1]][,sprintf("%sse",colnames(prdata[[1]]))] = prdata[[2]]
prdata = prdata[[1]]

save=T
if(save)
{
  write.csv(fitdata,sprintf("%s/data/cox_ph_test_nhanes.csv",outputDir))
}
```

```{r}
#ggplot(prdata,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,ymin=pr-prse,ymax=pr+prse))+
ggplot(fitdata,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=beta,ymin=beta-betase,ymax=beta+betase))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  geom_smooth(method="lm")+
  geom_line(data=prdata)+
  geom_ribbon(data=prdata,alpha=.15)
  
```



# Q1. How well does FI predict FP?

ROC curve
se and metrics should be saved in separate lists for application of Rubins' rules
save as matrix since that's the code I have
```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_fifp_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  print("file found, loading...")
  temp = readRDS(file)
  fiAcc = temp$acc
  fiROC = temp$roc
  rm(temp)
} else
{
  print("file not found, computing...")
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    r = roc(data[[i]][,"fp"]~data[[i]][,"fi"],ci.method="boot",ci=T,direction="<")
  
    #extract curve
    ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
    curve[[i]] = data.frame(specificity = as.numeric(rownames(ciobj)),
                     sensitivity = ciobj[, 2])
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = data.frame(specificity = rep(0,nrow(ciobj)),
                     sensitivity = ciobj[, 3]/2-ciobj[, 1]/2)
    curveSE[[i]] = as.matrix(curveSE[[i]])
  
    a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
    cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
    metrics[[i]] = data.frame(auc=a[2])
    for (j in 1:length(cut)) metrics[[i]][,names(cut)[j]] = cut[[j]][2]
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = data.frame(auc=a[3]/2-a[1]/2)
    for (j in 1:length(cut)) metricsSE[[i]][,names(cut)[j]] = cut[[j]][3]/2 - cut[[j]][1]/2
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiAcc = RubinMat(metrics,lse=metricsSE)
  fiROC = RubinMat(curve,lse=curveSE)
  if(save)   saveRDS(list(acc=fiAcc,roc=fiROC),file)
}
```

```{r}
print(fiAcc)
```

```{r}
plotdata = as.data.frame(fiROC[[1]])
#specificity is user-specific so has no error
plotdata[,"sensitivity_se"] = fiROC[[2]][,"sensitivity"]
g = ggplot(plotdata,aes(x=specificity,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se))+
  geom_line()+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  labs(x="Specificity",y="Sensitivity")+
  annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiAcc[[1]][1,"auc"],fiAcc[[2]][1,"auc"]))+
  scale_x_reverse()+
  theme_minimal()
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/roc_nhanes.pdf",outputDir),
         g,width=8,height=6,dpi=300)
  
  ggsave(sprintf("%s/results/roc_nhanes.png",outputDir),
         g,width=8,height=6,dpi=300)
}
  
```

# Q2. How well do we predict the component parts vs Nfp?
```{r}
fpNames = c("fp",c("bmi","gait","weak","exhausted", "activity"))
names(fpNames) = fpNames
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_agefpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAcc = temp$acc
  agePredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAcc = RubinMat(metrics,lse=metricsSE)
  agePredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAcc,roc=agePredROC),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_male_agefpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccM = temp$acc
  agePredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccM = RubinMat(metrics,lse=metricsSE)
  agePredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccM,roc=agePredROCM),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_female_agefpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccF = temp$acc
  agePredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
            logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccF = RubinMat(metrics,lse=metricsSE)
  agePredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccF,roc=agePredROCF),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_fifpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAcc = temp$acc
  fiPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAcc = RubinMat(metrics,lse=metricsSE)
  fiPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAcc,roc=fiPredROC),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_male_fifpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccM = temp$acc
  fiPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccM = RubinMat(metrics,lse=metricsSE)
  fiPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccM,roc=fiPredROCM),file)
  }
}

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_female_fifpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccF = temp$acc
  fiPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccF = RubinMat(metrics,lse=metricsSE)
  fiPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccF,roc=fiPredROCF),file)
  }
}

```

```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}
plotdata[[length(vars)+1]] = as.data.frame(fiROC[[1]])
colnames(plotdata[[length(vars)+1]])[1] = "specificities"
#specificity is user-specific so has no error
plotdata[[length(vars)+1]][,"sensitivity_se"] = fiROC[[2]][,"sensitivity"]
plotdata[[length(vars)+1]][,"variable"] = "FP"
plotdata[[length(vars)+1]][,"max_youden"] = max(plotdata[[length(vars)+1]][,"sensitivity"]+plotdata[[length(vars)+1]][,"specificities"],na.rm=T)
plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="FP")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()
```



```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_fpfpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAcc = temp$acc
  fpPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  #fpNames = c("bmi","gait","weak","exhausted","activity")
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      Nfpexcl = apply(data[[i]][,fpNames[-j]],1,sum) #N FP excluding jth
      r = roc(data[[i]][,fpNames[j]]~Nfpexcl,ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAcc = RubinMat(metrics,lse=metricsSE)
  fpPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAcc,roc=fpPredROC),file)
  }
}

#set fp to NA
fpPredAcc[[1]]["fp",] = NA
fpPredROC[[1]][,"fp"] = NA

#add empty FP prediction for fp
#fpPredAcc[[1]] = rbind(NA,fpPredAcc[[1]])
#rownames(fpPredAcc[[1]])[1] = "fp"
#fpPredAcc[[2]] = rbind(NA,fpPredAcc[[2]])
#rownames(fpPredAcc[[2]])[1] = "fp"
#fpPredROC[[1]] = cbind(fpPredROC[[1]],NA)
#colnames(fpPredROC[[1]])[ncol(fpPredROC[[1]])] = "fp"
#fpPredROC[[2]] = cbind(fpPredROC[[2]],NA)
#colnames(fpPredROC[[2]])[ncol(fpPredROC[[2]])] = "fp"
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_female_fpfpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccF = temp$acc
  fpPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  fpNames = c("fp","bmi","gait","weak","exhausted","activity")
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      logi = data[[i]][,"sex"]==1
      Nfpexcl = apply(data[[i]][logi,fpNames[-j]],1,sum) #N FP excluding jth
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl,ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccF = RubinMat(metrics,lse=metricsSE)
  fpPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccF,roc=fpPredROCF),file)
  }
}

#set fp to NA
fpPredAccF[[1]]["fp",] = NA
fpPredROCF[[1]][,"fp"] = NA

```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_nhanes_male_fpfpvar_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccM = temp$acc
  fpPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  fpNames = c("fp","bmi","gait","weak","exhausted","activity")
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      print(fpNames[j])
      logi = data[[i]][,"sex"]==0
      Nfpexcl = apply(data[[i]][logi,fpNames[-j]],1,sum) #N FP excluding jth
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl,ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccM = RubinMat(metrics,lse=metricsSE)
  fpPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccM,roc=fpPredROCM),file)
  }
}

#set fp to NA
fpPredAccM[[1]]["fp",] = NA
fpPredROCM[[1]][,"fp"] = NA

```



```{r}
vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
}
plotdata = do.call(rbind,plotdata)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_x_reverse()+
  theme_minimal()
```

```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"])))

plotdata0 = plotdata
plotdata2 = list(plotdata)

vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata2[[2]] = plotdata
plotdata2[[1]][,"group"] = "FI"
plotdata2[[2]][,"group"] = "NFab5"

#avant guard idea: make symmetrical about x=y
#plotdata2[[2]][,"sensitivity"] = 1-plotdata2[[2]][,"sensitivity"]
#plotdata2[[2]][,"specificities"] = 1-plotdata2[[2]][,"specificities"]
plotdata2 = do.call(rbind,plotdata2)

 ################drop FP for historical reasons ################
#plotdata2 = subset(plotdata2,variable != "fp")

#plotdata2[,"variable"] = factor(plotdata2[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
#fpNamesSorted = fpNames[c("Exhaustion","Weakness","Slow gait","Low activity","Low BMI")]
fpNamesSorted = fpNames[c("fp","exhausted","weak","gait","activity","bmi")]

g = ggplot(plotdata2,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable,linetype=group))+
  geom_line()+
  geom_point(data=plotdata2[rep(c(T,rep(F,4)),length=nrow(plotdata2)),],aes(alpha=group))+
  geom_ribbon(alpha=.2,col=NA)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_shape_manual(breaks=fpNamesSorted,values = 1:length(fpNamesSorted)+1,labels=names(fpNamesSorted))+
  scale_fill_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_colour_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_alpha_manual(breaks=c("FI","NFab5"),values=c(1,0))+
  scale_x_reverse()+
  labs(x="Specificity",y="Sensitivity")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.84,.38))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_roc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_roc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

Grid comparing ROCs
```{r}
vars = colnames(fpPredROC[[1]])[-1]
g = list()
for (j in 1:length(vars))
{
  plotdata = list()
  plotdata[[1]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[1]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[1]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[1]][,"variable"] = vars[j]
  plotdata[[1]][,"model"] = "FI"
  
  plotdata[[2]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[2]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[2]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[2]][,"variable"] = vars[j]
  plotdata[[2]][,"model"] = "NFP"
  
  plotdata = do.call(rbind,plotdata)
  
  g[[j]] = ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=model,fill=model,shape=model))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_x_reverse()+
  theme_minimal()+
  theme(legend.title=element_blank())
}
```

```{r}


plotdata = rbind(data.frame(variable=rownames(fiPredAcc[[1]]),auc=fiPredAcc[[1]][,"auc"],se=fiPredAcc[[2]][,"auc"],model="FI"),
                data.frame(variable=rownames(fpPredAcc[[1]]),auc=fpPredAcc[[1]][,"auc"],se=fpPredAcc[[2]][,"auc"],model=sprintf("%s - leave-one-out",gFab5Name)),
                data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],se=agePredAcc[[2]][,"auc"],model="Chronological age")
                )


plotdata[,"variable"] = gsub("fp","FP frailty",plotdata[,"variable"])
plotdata[,"variable"] = gsub("gait","Slow gait",plotdata[,"variable"])
plotdata[,"variable"] = gsub("activity","Low activity",plotdata[,"variable"])
#plotdata[,"variable"] = gsub("weak","Weakness",plotdata[,"variable"])
plotdata[,"variable"] = gsub("weak","Feel weak",plotdata[,"variable"])
plotdata[,"variable"] = gsub("bmi","Low BMI",plotdata[,"variable"])
plotdata[,"variable"] = gsub("exhausted","Exhaustion",plotdata[,"variable"])
ord = unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"variable"])
ord = unique(c("FP frailty",ord))
#ord = c("FP","Slow gait","Low activity","Exhaustion","Feel weak","Low BMI") #hard to read
plotdata[,"variable"] = factor(plotdata[,"variable"],ord)

plotdata[,"model"] = factor(plotdata[,"model"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(2),"grey40")
#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
shapes = c(17,15,18)
#alphas = c(rep(1,4),.5)

g[[6]] = ggplot(plotdata,aes(x=variable,y=auc,ymin=auc-se,ymax=auc+se,colour=model,shape=model,fill=model))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  scale_y_continuous(limits=c(NA,1))+
  labs(x="",y="AUC")+
  geom_hline(yintercept=.5,lty=3,size=1)+ #guess line
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.85))

#with line - easier to compare
#could add labels...
g2 = g[[6]] + geom_line(data=plotdata,aes(x=as.numeric(variable),linetype=model),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(variable)),alpha=.15,colour=NA) #,linetype=model
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAcc[[1]][inds,"auc"][1:2]),
      mean(fpPredAcc[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5),
                       y = y, 
                       l = c("FI","NFab5"),
                       model = levels(plotdata[,"model"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=model),inherit.aes=F) 
}

labelComparison=T
textSize = 8
if(labelComparison)
{
  #annotate FI > NFab5 (leave one out)
  xbox = c(.5,2) #c(.5,1.25)+.35
  ybox =c(.73,.83) #c(.725,.775)+.125
  xend = mean(xbox)#xbox[2]
  yend = max(ybox) #mean(ybox)
  #xbox = c(2.25,3.75) #c(.75,1.5)
  #ybox = c(.85,.95) #c(.725,.775)-0.05
  #xend = mean(xbox) # 2.5
  #yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90") #box
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
}

#match colours with HRS/ELSA
cols = c(gg_color_hue(4)[c(1,3)],"grey40")
g2 = g2 + scale_color_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_fill_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_shape_manual(values=c(17,15,18),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
#https://stackoverflow.com/questions/21739299/default-linetypes-in-ggplot2
#g2 = g2 + scale_linetype_manual(values=c("solid","22","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
g2 = g2 + scale_linetype_manual(values=c("22","44","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))

#annotate the "guess" line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.43,1),breaks=seq(.5,1,by=.1))

#match other plots
g2 = g2 + theme(text=element_text(size=gTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="white"),
        legend.position=c(.75,.85),
        legend.key.size = unit(2.5,"line")
        )

g2

save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_auc.pdf",outputDir),
         g[[6]],width=8,height=6,dpi=300)
  
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_auc.png",outputDir),
         g[[6]],width=8,height=6,dpi=300)
  
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_auc_wline.pdf",outputDir),g2,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_auc_wline.png",outputDir),g2,width=10,height=8,dpi=300)
}
```

```{r}
library(gridExtra)
marrangeGrob(g,nrow=3,ncol=2,top=NULL)
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_fi_vs_fp_roc.pdf",outputDir),
         marrangeGrob(g,nrow=3,ncol=2,top=NULL),width=16,height=16,dpi=300)
  
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_fi_vs_fp_roc.png",outputDir),
         marrangeGrob(g,nrow=3,ncol=2,top=NULL),width=16,height=16,dpi=300)
}
  
```

```{r}
# MALES
# MALES
# MALES
plotdata = rbind(data.frame(variable=rownames(fiPredAccM[[1]]),auc=fiPredAccM[[1]][,"auc"],se=fiPredAccM[[2]][,"auc"],model="FI"),
                data.frame(variable=rownames(fpPredAccM[[1]]),auc=fpPredAccM[[1]][,"auc"],se=fpPredAccM[[2]][,"auc"],model=sprintf("%s - leave-one-out",gFab5Name)),
                data.frame(variable=rownames(agePredAccM[[1]]),auc=agePredAccM[[1]][,"auc"],se=agePredAccM[[2]][,"auc"],model="Chronological age")
                )


plotdata[,"variable"] = gsub("fp","FP frailty",plotdata[,"variable"])
plotdata[,"variable"] = gsub("gait","Slow gait",plotdata[,"variable"])
plotdata[,"variable"] = gsub("activity","Low activity",plotdata[,"variable"])
#plotdata[,"variable"] = gsub("weak","Weakness",plotdata[,"variable"])
plotdata[,"variable"] = gsub("weak","Feel weak",plotdata[,"variable"])
plotdata[,"variable"] = gsub("bmi","Low BMI",plotdata[,"variable"])
plotdata[,"variable"] = gsub("exhausted","Exhaustion",plotdata[,"variable"])
ord = unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"variable"])
ord = unique(c("FP frailty",ord))
#ord = c("FP","Slow gait","Low activity","Exhaustion","Feel weak","Low BMI") #hard to read
plotdata[,"variable"] = factor(plotdata[,"variable"],ord)

plotdata[,"model"] = factor(plotdata[,"model"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(2),"grey40")
#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
shapes = c(17,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=variable,y=auc,ymin=auc-se,ymax=auc+se,colour=model,shape=model,fill=model))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  scale_y_continuous(limits=c(NA,1))+
  labs(x="",y="AUC")+
  geom_hline(yintercept=.5,lty=3,size=1)+ #guess line
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.875,.85))

#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(variable),linetype=model),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(variable)),alpha=.15,colour=NA) #,linetype=model
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAcc[[1]][inds,"auc"][1:2]),
      mean(fpPredAcc[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5),
                       y = y, 
                       l = c("FI","NFab5"),
                       model = levels(plotdata[,"model"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=model),inherit.aes=F) 
}

labelComparison=F
textSize = 8
if(labelComparison)
{
  #annotate FI > NFab5 (leave one out)
  xbox = c(.5,2) #c(.5,1.25)+.35
  ybox =c(.73,.83) #c(.725,.775)+.125
  xend = mean(xbox)#xbox[2]
  yend = max(ybox) #mean(ybox)
  #xbox = c(2.25,3.75) #c(.75,1.5)
  #ybox = c(.85,.95) #c(.725,.775)-0.05
  #xend = mean(xbox) # 2.5
  #yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90") #box
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
}

#match colours with HRS/ELSA
cols = c(gg_color_hue(4)[c(1,3)],"grey40")
g2 = g2 + scale_color_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_fill_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_shape_manual(values=c(17,15,18),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
#https://stackoverflow.com/questions/21739299/default-linetypes-in-ggplot2
#g2 = g2 + scale_linetype_manual(values=c("solid","22","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
g2 = g2 + scale_linetype_manual(values=c("22","44","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))

#annotate the "guess" line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.43,1),breaks=seq(.5,1,by=.1))

#match other plots
g2 = g2 + theme(text=element_text(size=gTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="white"),
        legend.position=c(.8,.9),
        legend.key.size = unit(2.5,"line")
        )

g2

save = T
if(save)
{
  #ggsave(sprintf("%s/results/fi_vs_fp_nhanes_male_auc.pdf",outputDir),
  #       g,width=8,height=6,dpi=300)
  
  #ggsave(sprintf("%s/results/fi_vs_fp_nhanes_male_auc.png",outputDir),
  #       g,width=8,height=6,dpi=300)
  
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_male_auc_wline.pdf",outputDir),g2,width=10,height=8,dpi=300)
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_male_auc_wline.png",outputDir),g2,width=10,height=8,dpi=300)
}

gl = list(g2)

# FEMALES
# FEMALES
# FEMALES
# FEMALES
# FEMALES

plotdata = rbind(data.frame(variable=rownames(fiPredAccF[[1]]),auc=fiPredAccF[[1]][,"auc"],se=fiPredAccF[[2]][,"auc"],model="FI"),
                data.frame(variable=rownames(fpPredAccF[[1]]),auc=fpPredAccF[[1]][,"auc"],se=fpPredAccF[[2]][,"auc"],model=sprintf("%s - leave-one-out",gFab5Name)),
                data.frame(variable=rownames(agePredAccF[[1]]),auc=agePredAccF[[1]][,"auc"],se=agePredAccF[[2]][,"auc"],model="Chronological age")
                )


plotdata[,"variable"] = gsub("fp","FP frailty",plotdata[,"variable"])
plotdata[,"variable"] = gsub("gait","Slow gait",plotdata[,"variable"])
plotdata[,"variable"] = gsub("activity","Low activity",plotdata[,"variable"])
#plotdata[,"variable"] = gsub("weak","Weakness",plotdata[,"variable"])
plotdata[,"variable"] = gsub("weak","Feel weak",plotdata[,"variable"])
plotdata[,"variable"] = gsub("bmi","Low BMI",plotdata[,"variable"])
plotdata[,"variable"] = gsub("exhausted","Exhaustion",plotdata[,"variable"])
#ord = unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"variable"]) #use ord from prev
#ord = unique(c("FP frailty",ord))
#ord = c("FP","Slow gait","Low activity","Exhaustion","Feel weak","Low BMI") #hard to read
plotdata[,"variable"] = factor(plotdata[,"variable"],ord)

plotdata[,"model"] = factor(plotdata[,"model"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(2),"grey40")
#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
shapes = c(17,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=variable,y=auc,ymin=auc-se,ymax=auc+se,colour=model,shape=model,fill=model))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  scale_y_continuous(limits=c(NA,1))+
  labs(x="",y="AUC")+
  geom_hline(yintercept=.5,lty=3,size=1)+ #guess line
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.85))

#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(variable),linetype=model),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(variable)),alpha=.15,colour=NA) #,linetype=model
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAcc[[1]][inds,"auc"][1:2]),
      mean(fpPredAcc[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5),
                       y = y, 
                       l = c("FI","NFab5"),
                       model = levels(plotdata[,"model"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=model),inherit.aes=F) 
}

labelComparison=T
textSize = 8
if(labelComparison)
{
  #annotate FI > NFab5 (leave one out)
  xbox = c(.5,2.25) #c(.5,1.25)+.35
  ybox =c(.7,.8) #c(.725,.775)+.125
  xend = mean(xbox)#xbox[2]
  yend = max(ybox) #mean(ybox)
  #xbox = c(2.25,3.75) #c(.75,1.5)
  #ybox = c(.85,.95) #c(.725,.775)-0.05
  #xend = mean(xbox) # 2.5
  #yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90") #box
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]]["exhausted","auc"]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
}

#match colours with HRS/ELSA
cols = c(gg_color_hue(4)[c(1,3)],"grey40")
g2 = g2 + scale_color_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_fill_manual(values=cols,breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age")) + scale_shape_manual(values=c(17,15,18),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
#https://stackoverflow.com/questions/21739299/default-linetypes-in-ggplot2
#g2 = g2 + scale_linetype_manual(values=c("solid","22","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
g2 = g2 + scale_linetype_manual(values=c("22","44","13"),breaks=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"),labels=c("FI",sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))

#annotate the "guess" line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.43,1),breaks=seq(.5,1,by=.1))

#match other plots
g2 = g2 + theme(text=element_text(size=gTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="white"),
        legend.position=c(.75,.85),
        legend.key.size = unit(2.5,"line")
        )

g2

save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_female_auc.pdf",outputDir),
         g,width=8,height=6,dpi=300)
  
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_female_auc.png",outputDir),
         g,width=8,height=6,dpi=300)
  
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_female_auc_wline.pdf",outputDir),g2,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_nhanes_female_auc_wline.png",outputDir),g2,width=10,height=8,dpi=300)
  
  gl[[2]] = g2+ggtitle("(b) NHANES - Females")
  gl[[1]] = gl[[1]]+ggtitle("(a) NHANES - Males")
  for (i in 1:length(gl)) gl[[i]] = gl[[i]] + scale_y_continuous(limits=c(.39,1))
  gl[[2]] = gl[[2]]+theme(legend.position="none")
  
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_sex_auc_wline.pdf",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=7,dpi=300)
    ggsave(sprintf("%s/results/fi_vs_fp_nhanes_sex_auc_wline.png",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=7,dpi=300)
}
```

Summary plot of important metric(s)


### Multi-roc
```{r}
file = sprintf("%s/data/fi_multiroc_nhanes.rds",outputDir)

load=T
save=T
nboot=2000
if(file.exists(file) & load)
{
  print("file found, loading...")
  rocFit = readRDS(file)
  predROCFI = rocFit[["pr"]]
  cutsFI = rocFit[["cuts"]]
} else
{
  pred = list()
  predSE = list()
  cuts = list()
  cutsSE = list()
  for (i in 1:length(data))
  {
    rocFit = OrdinalROC(y=data[[i]][,"Nfp_ord"],x=data[[i]][,"fi"],best.policy="random",nboot=nboot,direction="<")

    pr = predict.OrdinalROC(rocFit,x=seq(0,1,length=101),fast=F,CI=pnorm(c(-1,1)))
    pred[[i]] = as.matrix(pr[,c("x","ymed")])
    predSE[[i]] = matrix(0,nrow=nrow(pr),ncol=2)
    predSE[[i]][,2] = pr[,"yhigh"]/2-pr[,"ylow"]/2
    colnames(predSE[[i]]) = colnames(pred[[i]])
    cuts[[i]] = apply(rocFit$cuts,2,median,na.rm=T)
    cuts[[i]] = matrix(cuts[[i]],nrow=1,ncol=length(cuts[[i]]))
    colnames(cuts[[i]]) = sprintf("%d",1:5)
    cutsSE[[i]] = apply(rocFit$cuts,2,quantile,probs=pnorm(1),na.rm=T)/2 - apply(rocFit$cuts,2,quantile,probs=pnorm(-1),na.rm=T)/2    
    cutsSE[[i]] = matrix(cutsSE[[i]],nrow=1,ncol=length(cutsSE[[i]]))
    colnames(cutsSE[[i]]) = sprintf("%d",1:5)
  }
  predROCFI = RubinMat(pred,lse=predSE)
  cutsFI = RubinMat(cuts,lse=cutsSE)
  
  if(save) saveRDS(list(cuts=cutsFI,pr=predROCFI),file)
}
```

```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  #Nfp = data[[i]][,"Nfp"]
  Nfp = data[[i]][,"Nfp_qcut"]
  #un = sort(unique(Nfp))
  un = 0:5
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    fi = data[[i]][Nfp == un[j],"fi"]
    mbs = medianBS(fi,nboot=100)
    subdata[[j]] = data.frame(Nfp=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]])
    subdataSE[[j]] = data.frame(Nfp=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]])
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpData = RubinMat(l=fifpData,lse=fifpDataSE)
```


```{r}
cuts=fiPredAcc[[1]][,"threshold"]
cutsSE = fiPredAcc[[2]][,"threshold"]
plotdata = data.frame(fi=seq(0,1,length=101))
plotdata[,"prN"] = 0
plotdata[,"prNhigh"] = 0
plotdata[,"prNlow"] = 0
for (j in 1:length(cuts))
{
  logi = plotdata[,"fi"] >= cuts[j]
  plotdata[logi,"prN"] = plotdata[logi,"prN"] + 1

  logi = plotdata[,"fi"] >= cuts[j]-cutsSE[j]
  plotdata[logi,"prNlow"] = plotdata[logi,"prNlow"] + 1
  
  logi = plotdata[,"fi"] >= cuts[j]+cutsSE[j]
  plotdata[logi,"prNhigh"] = plotdata[logi,"prNhigh"] + 1
}

predROC = data.frame(predROCFI[[1]])
colnames(predROC)[2]="y"
predROC[,"ylow"] = predROCFI[[1]][,"ymed"] - predROCFI[[2]][,"ymed"]
predROC[,"yhigh"] = predROCFI[[1]][,"ymed"] + predROCFI[[2]][,"ymed"]

ggplot(plotdata,aes(x=fi,y=prN,ymin=prNlow,ymax=prNhigh))+
  geom_point()+
  geom_line()+
  geom_ribbon(alpha=.2)+
  #geom_line(inherit.aes=F,data=predPolrW,mapping=aes(x=fi,y=Epr),col="red")+
  #geom_ribbon(inherit.aes=F,data=predPolrW,mapping=aes(x=fi,y=Epr,ymin=Epr-sd,ymax=Epr+sd),fill="red",alpha=.3)+
  #geom_line(inherit.aes=F,data=predLM,mapping=aes(x=fi,y=y),col="green")+
  #geom_ribbon(inherit.aes=F,data=predLM,mapping=aes(x=fi,y=y,ymin=y-se,ymax=y+se),fill="green",alpha=.3)+
  geom_pointrange(inherit.aes=F,data=data.frame(Nfp=fifpData[[1]][,"Nfp"],fi=fifpData[[1]][,"fi_mean"],se=fifpData[[2]][,"fi_mean"]),aes(x=fi,xmin=fi-se,xmax=fi+se,y=Nfp),pch=17,colour="blue",size=1)+
  geom_line(inherit.aes=F,data=predROC,mapping=aes(x=x,y=y),col="orange")+
  geom_ribbon(inherit.aes=F,data=predROC,mapping=aes(x=x,y=y,ymin=ylow,ymax=yhigh),fill="orange",alpha=.3)+
  labs(x="FI",y="Number of FP deficits predicted")+
  scale_x_continuous(limits=c(0,1))+
  theme_minimal()+
  theme()
```

# Q3. How do FP and FI compare in terms of predicting future adverse events?
Check survival hazard as a function of FP/FI

Update: don't include age, I'm getting a negative coefficient. Something is clearly weird.
```{r}
referenceAge=75
referenceSex=0
```

Linear FI
```{r}
hazData = list()
hazDataSE = list()
fitest = seq(0,1,length=101)
#blodgett: FI  0.10 was considered ‘non-frail’, 0.10 < FI  0.21 was ‘vulnerable’, a score of 0.21 < FI  0.45 was ‘frail,’ and FI > 0.45 was ‘most frail’.
#Blodgett, J., Theou, O., Kirkland, S., Andreou, P. & Rockwood, K. Frailty in NHANES: Comparing the frailty index and phenotype. Arch. Gerontol. Geriatr. 60, 464–470 (2015)
#fiCuts = c(-Inf,.1,.21,.45,Inf) #blodgett cuts
#fiCuts = c(-Inf,.05,.1,.2,.3,.4,Inf)
for (i in 1:length(stst))
{
  subdata = data.frame(stst[[i]][,c("age","sex","fi")])
  m = coxph(s~sex+fi,subdata)
  
  #mat = summary(m)$coefficients
  #hazData[[i]] = data.frame(HR=mat[grep("fi",rownames(mat)),"coef"],C=concordance(m)$concordance)
  #hazData[[i]] = as.matrix(hazData[[i]])
  
  #hazDataSE[[i]] = data.frame(HR=mat[grep("fi",rownames(mat)),"se(coef)"],C=sqrt(concordance(m)$var))
  #hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  #update: use predict
  testdata = data.frame(fi=fitest)
  testdata[,"age"] = referenceAge
  testdata[,"sex"] = factor(referenceSex,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") #default is linear predictor DEPENDS ON REFERENCE (defaults to mean)
  hazData[[i]] = data.frame(HR=pr[[1]],pred=fitest,refValue=NA,C=concordance(m)$concordance)
  hazData[[i]] = as.matrix(hazData[[i]])
  
  hazDataSE[[i]] = data.frame(HR=pr[[2]],pred=0,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
}
hazFI = RubinMat(hazData,lse=hazDataSE)
```
FI Quantiles
```{r}
#update: add spline model
library(splines2)
```

```{r}
hazData = list()
hazDataSE = list()
hazDataSP = list()
hazDataSPSE = list()
fitest=seq(0,1,length=101)
#blodgett: FI  0.10 was considered ‘non-frail’, 0.10 < FI  0.21 was ‘vulnerable’, a score of 0.21 < FI  0.45 was ‘frail,’ and FI > 0.45 was ‘most frail’.
#Blodgett, J., Theou, O., Kirkland, S., Andreou, P. & Rockwood, K. Frailty in NHANES: Comparing the frailty index and phenotype. Arch. Gerontol. Geriatr. 60, 464–470 (2015)
#fiCuts = c(-Inf,.1,.21,.45,Inf) #blodgett cuts
#fiCuts = c(-Inf,.05,.1,.2,.3,.4,Inf)
for (i in 1:length(data))
{
  subdata = data.frame(data[[i]][,c("age","sex","fi")])
  #fiCuts = quantile(subdata[,"fi"],probs=seq(0,1,length=9),na.rm=T)
  #fiCuts = c(-Inf,.01,.1,.2,.3,.4,.5,.6,.7,.8,Inf)
  #fiCuts = c(-Inf,.01,.2,.4,.6,.8,Inf)
  #fiCuts = c(-Inf,.01,.125,.25,.375,.5,.625,.750,Inf) #pretty close to NFab5 scale
  #fiCuts = c(-Inf,seq(0.01,.9,length=6))
  fiCuts = c(-Inf,seq(.1,.95,by=.1))
  subdata[,"fiq"] = cut(subdata[,"fi"],fiCuts)

  m = coxph(scut~sex+fiq,subdata)
  

  levs = levels(subdata[,"fiq"])
  #actual observed fis, not just the quantile
  values = numeric()
  for (j in 1:length(levs)) values[j] = mean(subdata[subdata[,"fiq"]==levs[j],"fi"],na.rm=T)
  valuesSE = numeric()
  for (j in 1:length(levs)) valuesSE[j] = SEM(subdata[subdata[,"fiq"]==levs[j],"fi"],na.rm=T)  
  mat = summary(m)$coefficients
  #HR coef needs to be shifted by reference 
    #assume coxph model from 0 to reference value
  #print(values)
  
  #old code -doesn't use predict
  #hazData[[i]] = data.frame(HR=mat[grep("fiq",rownames(mat)),"coef"]+hazFI[[1]][1,"HR"]*values[1],pred=values[-1],refValue=values[1],C=concordance(m)$concordance)
  #hazData[[i]] = as.matrix(hazData[[i]])
  
  #hazDataSE[[i]] = data.frame(HR=sqrt(mat[grep("fiq",rownames(mat)),"se(coef)"]^2+hazFI[[1]][1,"HR"]^2*valuesSE[1]^2+hazFI[[2]][1,"HR"]^2*values[1]^2),pred=valuesSE[-1],refValue=valuesSE[1],C=sqrt(concordance(m)$var))
  #hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  #new code: use predict
    #note: neglects to propagate error in reference into spline (probably small)
  testdata = data.frame(fiq=factor(levs,levs))
  testdata[,"age"] = referenceAge
  testdata[,"sex"] = factor(referenceSex,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") #default is linear predictor DEPENDS ON REFERENCE (defaults to mean)
  hazData[[i]] = data.frame(HR=pr[[1]],pred=values,refValue=NA,C=concordance(m)$concordance)
  hazData[[i]] = as.matrix(hazData[[i]])
  
  hazDataSE[[i]] = data.frame(HR=pr[[2]],pred=valuesSE,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  rm(m)
  rm(testdata)
  
  #spline data
  #sp = bSpline(fitest,df=6,Boundary.knots=c(0,1))
  sp = ibs(fitest,df=6,Boundary.knots=c(0,1))
  #sp = ibs(fitest,knots=c(.1,.25,.5,.75),Boundary.knots=c(0,1))
  #sp = bSpline(subdata[,"fi"],df=6,Boundary.knots=c(0,1))
  #sp = ibs(subdata[,"fi"],df=6)
  subdata[,sprintf("sp%02d",1:ncol(sp))] = predict(sp,subdata[,"fi"])
  
  m = coxph(scut~.,subdata[,c("sex",sprintf("sp%02d",1:ncol(sp)))])
    
  testdata = as.data.frame(predict(sp,fitest))
  colnames(testdata) = sprintf("sp%02d",1:ncol(sp))
  testdata[,"age"] = referenceAge
  testdata[,"sex"] = factor(referenceSex,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") #default is linear predictor DEPENDS ON REFERENCE (defaults to mean)
  
  hazDataSP[[i]] = data.frame(HR=pr[[1]],pred=fitest,refValue=NA,C=concordance(m)$concordance)
  hazDataSP[[i]] = as.matrix(hazDataSP[[i]])
  
  hazDataSPSE[[i]] = data.frame(HR=pr[[2]],pred=0,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSPSE[[i]] = as.matrix(hazDataSPSE[[i]])
}
hazFIQ = RubinMat(hazData,lse=hazDataSE)
hazFISPQ = RubinMat(hazDataSP,lse=hazDataSPSE)
```

Linear NFP
```{r}
hazData = list()
hazDataSE = list()
Nfptest=seq(0,5,length=101)
#blodgett: FI  0.10 was considered ‘non-frail’, 0.10 < FI  0.21 was ‘vulnerable’, a score of 0.21 < FI  0.45 was ‘frail,’ and FI > 0.45 was ‘most frail’.
#Blodgett, J., Theou, O., Kirkland, S., Andreou, P. & Rockwood, K. Frailty in NHANES: Comparing the frailty index and phenotype. Arch. Gerontol. Geriatr. 60, 464–470 (2015)
#fiCuts = c(-Inf,.1,.21,.45,Inf) #blodgett cuts
#fiCuts = c(-Inf,.05,.1,.2,.3,.4,Inf)
for (i in 1:length(data))
{
  subdata = data.frame(data[[i]][,c("age","sex","Nfp")])
  m = coxph(scut~sex+Nfp,subdata)
  
  #mat = summary(m)$coefficients
  #hazData[[i]] = data.frame(HR=mat[grep("Nfp",rownames(mat)),"coef"],C=concordance(m)$concordance)
  #hazData[[i]] = as.matrix(hazData[[i]])
  
  #hazDataSE[[i]] = data.frame(HR=mat[grep("Nfp",rownames(mat)),"se(coef)"],C=sqrt(concordance(m)$var))
  #hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  #update: use predict
  testdata = data.frame(Nfp=Nfptest)
  testdata[,"age"] = referenceAge
  testdata[,"sex"] = factor(referenceSex,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") #default is linear predictor DEPENDS ON REFERENCE (defaults to mean)
  hazData[[i]] = data.frame(HR=pr[[1]],pred=Nfptest,refValue=NA,C=concordance(m)$concordance)
  hazData[[i]] = as.matrix(hazData[[i]])
  
  hazDataSE[[i]] = data.frame(HR=pr[[2]],pred=0,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
}
hazNFP = RubinMat(hazData,lse=hazDataSE)
```

NFP Ordinal
```{r}
#update: add spline model
library(splines2)
```

```{r}
hazData = list()
hazDataSE = list()
hazDataSP = list()
hazDataSPSE = list()
sptest = seq(0,5,length=101)
#blodgett: FI  0.10 was considered ‘non-frail’, 0.10 < FI  0.21 was ‘vulnerable’, a score of 0.21 < FI  0.45 was ‘frail,’ and FI > 0.45 was ‘most frail’.
#Blodgett, J., Theou, O., Kirkland, S., Andreou, P. & Rockwood, K. Frailty in NHANES: Comparing the frailty index and phenotype. Arch. Gerontol. Geriatr. 60, 464–470 (2015)
#fiCuts = c(-Inf,.1,.21,.45,Inf) #blodgett cuts
#fiCuts = c(-Inf,.05,.1,.2,.3,.4,Inf)
for (i in 1:length(data))
{
  subdata = data.frame(data[[i]][,c("age","sex","Nfp")])
  subdata[,"Nfp_ord"] = factor(subdata[,"Nfp"],0:5)

  m = coxph(scut~sex+Nfp_ord,subdata)
  
  levs = levels(subdata[,"Nfp_ord"])
  values = numeric()
  for (j in 1:length(levs)) values[j] = mean(subdata[subdata[,"Nfp_ord"]==levs[j],"Nfp"],na.rm=T)
  valuesSE = numeric()
  for (j in 1:length(levs)) valuesSE[j] = SEM(subdata[subdata[,"Nfp_ord"]==levs[j],"Nfp"],na.rm=T)  
  #mat = summary(m)$coefficients
  #hazData[[i]] = data.frame(HR=mat[grep("Nfp_ord",rownames(mat)),"coef"],pred=values[-1],refValue=values[1],C=concordance(m)$concordance)
  #hazData[[i]] = as.matrix(hazData[[i]])
  
  #hazDataSE[[i]] = data.frame(HR=mat[grep("Nfp_ord",rownames(mat)),"se(coef)"],pred=valuesSE[-1],refValue=valuesSE[1],C=sqrt(concordance(m)$var))
  #hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  #new code: use predict
    #note: neglects to propagate error in reference into spline (probably small)
  testdata = data.frame(Nfp_ord=factor(levs,levs))
  testdata[,"age"] = referenceAge
  testdata[,"sex"] = factor(referenceSex,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") #default is linear predictor DEPENDS ON REFERENCE (defaults to mean)
  hazData[[i]] = data.frame(HR=pr[[1]],pred=values,refValue=NA,C=concordance(m)$concordance)
  hazData[[i]] = as.matrix(hazData[[i]])
  
  hazDataSE[[i]] = data.frame(HR=pr[[2]],pred=valuesSE,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSE[[i]] = as.matrix(hazDataSE[[i]])
  
  rm(m)
  
  #spline data
  #sp = bSpline(sptest,df=6,Boundary.knots=c(0,5))
  sp = ibs(sptest,df=6,Boundary.knots=c(0,5))
  #sp = bSpline(subdata[,"Nfp"],df=6,Boundary.knots=c(0,5))
  #sp = ibs(subdata[,"Nfp"],df=6,Boundary.knots=c(0,5))
  subdata[,sprintf("sp%02d",1:ncol(sp))] = predict(sp,subdata[,"Nfp"])
  
  m = coxph(scut~.,subdata[,c("sex",sprintf("sp%02d",1:ncol(sp)))])
    
  testdata = as.data.frame(predict(sp,sptest))
  colnames(testdata) = sprintf("sp%02d",1:ncol(sp))
  testdata[,"age"] = 0
  testdata[,"sex"] = factor(0,c(0,1))
  
  pr = predict(m,testdata,se.fit=T,reference="zero") 
  
  hazDataSP[[i]] = data.frame(HR=pr[[1]],pred=sptest,refValue=NA,C=concordance(m)$concordance)
  hazDataSP[[i]] = as.matrix(hazDataSP[[i]])
  
  hazDataSPSE[[i]] = data.frame(HR=pr[[2]],pred=0,refValue=NA,C=sqrt(concordance(m)$var))
  hazDataSPSE[[i]] = as.matrix(hazDataSPSE[[i]])
  
}
hazNFPQ = RubinMat(hazData,lse=hazDataSE)
hazNFPSPQ = RubinMat(hazDataSP,lse=hazDataSPSE)
```

Reference subtraction: assume that reference point approximately obeys PH assumption, then you can estimate its contribution to the HR using the Cox PH model.

```{r}
plotdata = rbind(data.frame(HR=hazFIQ[[1]][,"HR"],x=hazFIQ[[1]][,"pred"],HRSE=hazFIQ[[2]][,"HR"],xSE=hazFIQ[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFPQ[[1]][,"HR"],x=hazNFPQ[[1]][,"pred"]/5,HRSE=hazNFPQ[[2]][,"HR"],xSE=hazNFPQ[[2]][,"pred"]/5,model="NFab5")
                      )
#linearData = list()
#linearData[[1]] = data.frame(x=seq(0,1,length=101))
#linearData[[1]][,"HR"] = linearData[[1]][,"x"]*hazFI[[1]][1,"HR"]
#linearData[[1]][,"HRSE"] = linearData[[1]][,"x"]*hazFI[[2]][1,"HR"]
#linearData[[1]][,"model"] = "FI"
#linearData[[2]] = data.frame(x=seq(0,1,length=101))
#linearData[[2]][,"HR"] = linearData[[2]][,"x"]*hazNFP[[1]][1,"HR"]*5
#linearData[[2]][,"HRSE"] = linearData[[2]][,"x"]*hazNFP[[2]][1,"HR"]*5
#linearData[[2]][,"model"] = "NFab5"
#linearData = do.call(rbind,linearData)
#May 2024 - I have no idea wtf I was doing
linearData = rbind(data.frame(HR=hazFI[[1]][,"HR"],x=hazFI[[1]][,"pred"],HRSE=hazFI[[2]][,"HR"],xSE=hazFI[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFP[[1]][,"HR"],x=hazNFP[[1]][,"pred"]/5,HRSE=hazNFP[[2]][,"HR"],xSE=hazNFP[[2]][,"pred"]/5,model="NFab5")
                      )

cols = gg_color_hue(2)

ggplot(plotdata,aes(x=x,y=HR,xmin=x-xSE,xmax=x+xSE,ymin=HR-HRSE,ymax=HR+HRSE,colour=model))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(width=0)+
  labs(x="FI",y="ln(HR)")+
  scale_x_continuous(sec.axis = sec_axis(~ . * 5, name = "Number of fab-5 deficits (NFab5)"))+
  #scale_y_continuous(limits=c(-1,2))+
  geom_line(data=linearData,mapping=aes(x=x,y=HR,ymin=HR-HRSE,ymax=HR+HRSE,colour=model),inherit.aes=F)+
  geom_ribbon(data=linearData,mapping=aes(x=x,y=HR,ymin=HR-HRSE,ymax=HR+HRSE,fill=model),alpha=.2,inherit.aes=F,colour=NA)+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.1,.8),
        axis.line.x = element_line(color = cols[1]), 
       axis.ticks.x = element_line(color = cols[1]),
        axis.line.x.top = element_line(color = cols[2]), 
       axis.ticks.x.top = element_line(color = cols[2]))
```

```{r}
plotdata = rbind(data.frame(HR=hazFIQ[[1]][,"HR"],x=hazFIQ[[1]][,"pred"],HRSE=hazFIQ[[2]][,"HR"],xSE=hazFIQ[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFPQ[[1]][,"HR"],x=hazNFPQ[[1]][,"pred"]/5,HRSE=hazNFPQ[[2]][,"HR"],xSE=hazNFPQ[[2]][,"pred"]/5,model="NFab5")
                      )
#linearData = list()
#linearData[[1]] = data.frame(x=seq(0,1,length=101))
#linearData[[1]][,"HR"] = linearData[[1]][,"x"]*hazFI[[1]][1,"HR"]
#linearData[[1]][,"HRSE"] = linearData[[1]][,"x"]*hazFI[[2]][1,"HR"]
#linearData[[1]][,"model"] = "FI"
#linearData[[2]] = data.frame(x=seq(0,1,length=101))
#linearData[[2]][,"HR"] = linearData[[2]][,"x"]*hazNFP[[1]][1,"HR"]*5
#linearData[[2]][,"HRSE"] = linearData[[2]][,"x"]*hazNFP[[2]][1,"HR"]*5
#linearData[[2]][,"model"] = "NFab5"
#linearData = do.call(rbind,linearData)
#May 2024 - I have no idea wtf I was doing
linearData = rbind(data.frame(HR=hazFI[[1]][,"HR"],x=hazFI[[1]][,"pred"],HRSE=hazFI[[2]][,"HR"],xSE=hazFI[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFP[[1]][,"HR"],x=hazNFP[[1]][,"pred"]/5,HRSE=hazNFP[[2]][,"HR"],xSE=hazNFP[[2]][,"pred"]/5,model="NFab5")
                      )

errorScale = 1 #qnorm(.975)
plotdata[,"HRlow"] = plotdata[,"HR"]-errorScale*plotdata[,"HRSE"]
plotdata[,"HRhigh"] = plotdata[,"HR"]+errorScale*plotdata[,"HRSE"]
linearData[,"HRlow"] = linearData[,"HR"]-errorScale*linearData[,"HRSE"]
linearData[,"HRhigh"] = linearData[,"HR"]+errorScale*linearData[,"HRSE"]

#transform to true HR scale (hazard / baseline per unit increase)
plotdata[,"HR"] = exp(plotdata[,"HR"])
plotdata[,"HRSE"] = plotdata[,"HR"]*plotdata[,"HRSE"]
plotdata[,"HRlow"] = exp(plotdata[,"HRlow"])
plotdata[,"HRhigh"] = exp(plotdata[,"HRhigh"])

linearData[,"HR"] = exp(linearData[,"HR"])
linearData[,"HRSE"] = linearData[,"HR"]*linearData[,"HRSE"]
linearData[,"HRlow"] = exp(linearData[,"HRlow"])
linearData[,"HRhigh"] = exp(linearData[,"HRhigh"])

ggplot(plotdata,aes(x=x,y=(HR),xmin=x-xSE,xmax=x+xSE,ymin=HRlow,ymax=HRhigh,colour=model))+
  labs(x="FI",y="HR")+
  scale_x_continuous(sec.axis = sec_axis(~ . * 5, name = "Number of fab-5 deficits (NFab5)"))+
  scale_y_continuous(limits=c(NA,12))+
  geom_line(data=linearData,mapping=aes(x=x,y=(HR),colour=model),inherit.aes=F)+
  geom_ribbon(data=linearData,mapping=aes(x=x,y=(HR),ymin=HRlow,ymax=HRhigh,fill=model),alpha=.2,inherit.aes=F,colour=NA)+
  geom_smooth(method="lm",formula=y~x,se=F,lty=2)+
  geom_point(size=4,mapping=aes(shape=model))+
  geom_errorbar(width=0,size=1)+
  geom_errorbarh(height=0,size=1)+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.1,.8),
        axis.line.x = element_line(color = cols[1]), 
       axis.ticks.x = element_line(color = cols[1]),
        axis.line.x.top = element_line(color = cols[2]), 
       axis.ticks.x.top = element_line(color = cols[2]),
       legend.key.size = unit(3,"line")
       )
```
#spline vs linear
#sub-sample the spline a bit  for visualization
```{r}

plotdata = rbind(data.frame(HR=hazFIQ[[1]][,"HR"],x=hazFIQ[[1]][,"pred"],HRSE=hazFIQ[[2]][,"HR"],xSE=hazFIQ[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFPQ[[1]][,"HR"],x=hazNFPQ[[1]][,"pred"]/5,HRSE=hazNFPQ[[2]][,"HR"],xSE=hazNFPQ[[2]][,"pred"]/5,model="NFab5")
                      )

#linearData = list()
#linearData[[1]] = data.frame(x=seq(0,1,length=101))
#linearData[[1]][,"HR"] = linearData[[1]][,"x"]*hazFI[[1]][1,"HR"]
#linearData[[1]][,"HRSE"] = linearData[[1]][,"x"]*hazFI[[2]][1,"HR"]
#linearData[[1]][,"model"] = "FI"
#linearData[[2]] = data.frame(x=seq(0,1,length=101))
#linearData[[2]][,"HR"] = linearData[[2]][,"x"]*hazNFP[[1]][1,"HR"]*5
#linearData[[2]][,"HRSE"] = linearData[[2]][,"x"]*hazNFP[[2]][1,"HR"]*5
#linearData[[2]][,"model"] = "NFab5"
#linearData = do.call(rbind,linearData)
#May 2024 - I have no idea wtf I was doing
linearData = rbind(data.frame(HR=hazFI[[1]][,"HR"],x=hazFI[[1]][,"pred"],HRSE=hazFI[[2]][,"HR"],xSE=hazFI[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFP[[1]][,"HR"],x=hazNFP[[1]][,"pred"]/5,HRSE=hazNFP[[2]][,"HR"],xSE=hazNFP[[2]][,"pred"]/5,model="NFab5")
                      )

spData = rbind(data.frame(HR=hazFISPQ[[1]][,"HR"],x=hazFISPQ[[1]][,"pred"],HRSE=hazFISPQ[[2]][,"HR"],xSE=hazFISPQ[[2]][,"pred"],model="FI"),
                data.frame(HR=hazNFPSPQ[[1]][,"HR"],x=hazNFPSPQ[[1]][,"pred"]/5,HRSE=hazNFPSPQ[[2]][,"HR"],xSE=hazNFPSPQ[[2]][,"pred"]/5,model="NFab5")
                      )

spData[,"type"] = "spline"
linearData[,"type"] = "linear"
#linearData = rbind(spData,linearData)

#transform to true HR scale (hazard / baseline per unit increase)
#plotdata[,"HR"] = exp(plotdata[,"HR"])
#plotdata[,"HRSE"] = plotdata[,"HR"]*plotdata[,"HRSE"]
#linearData[,"HR"] = exp(linearData[,"HR"])
#linearData[,"HRSE"] = linearData[,"HR"]*linearData[,"HRSE"]
plotdata[,"type"] = NA
ggplot(plotdata,aes(x=x,y=(HR),xmin=x-xSE,xmax=x+xSE,ymin=(HR-HRSE),ymax=(HR+HRSE),colour=model,fill=model))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  labs(x="FI",y="HR")+
  scale_x_continuous(sec.axis = sec_axis(~ . * 5, name = "Number of fab-5 deficits (NFab5)"))+
  scale_y_continuous(limits=c(-.1,3))+
  geom_line(data=linearData,mapping=aes(x=x,y=(HR),colour=model),inherit.aes=F,lty=2)+
  #geom_ribbon(data=linearData,mapping=aes(x=x,y=(HR),ymin=(HR-HRSE),ymax=(HR+HRSE),fill=model),alpha=.2,inherit.aes=F,colour=NA)+
  geom_line(data=spData,mapping=aes(x=x,y=(HR),colour=model),inherit.aes=F)+
  geom_ribbon(data=spData,mapping=aes(x=x,y=(HR),ymin=(HR-HRSE),ymax=(HR+HRSE),fill=model),alpha=.2,inherit.aes=F,colour=NA)+
  #geom_smooth(method="lm",formula=y~x,se=F)+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.1,.8),
        axis.line.x = element_line(color = cols[1]), 
       axis.ticks.x = element_line(color = cols[1]),
        axis.line.x.top = element_line(color = cols[2]), 
       axis.ticks.x.top = element_line(color = cols[2]))
```


# Q4. Do we fail to diagnose frail individuals?

```{r}
survData = list()
survDataSE = list()
C = list()
for (i in 1:length(data))
{
  fi = data[[i]][,"fi"]
  Nfp = data[[i]][,"Nfp"]
  groups = rep("robust",length(fi))
  badFI = fi > 0.45 #fiAcc[[1]][1,"threshold"] #.45 blodgett
  
  C[[i]] = xtabs(~I(Nfp >= 3)+badFI)
  
  groups[Nfp >= 3 & badFI] = "Both high"  
  groups[Nfp >= 3 & !badFI] = "FP high" 
  groups[Nfp < 3 & badFI] = "FI high" 
  groups[Nfp < 3 & !badFI] = "Both low" 
  groupsf = factor(groups,unique(groups))
  sf = survfit(scut~groupsf,conf.int=pnorm(1)-pnorm(-1))
  
  t = seq(59,100,length=101)
  survData[[i]] = data.frame(age=t)
  survDataSE[[i]] = data.frame(age=t)
  unGroup = unique(groups)
  for(j in 1:length(unGroup))
  {
    sInd = grep(unGroup[j],names(sf$strata))
    inds = 1:sf$strata[sInd]
    if(sInd > 1) inds = inds + sum(sf$strata[1:(sInd-1)])
    lf = approxfun(x=sf$time[inds],y=sf$surv[inds],yleft=1,yright=0)
    survData[[i]][,unGroup[j]] = lf(survData[[i]][,"age"])
    lflow = approxfun(x=sf$time[inds],y=sf$lower[inds],yleft=1,yright=0)
    lfhigh = approxfun(x=sf$time[inds],y=sf$upper[inds],yleft=1,yright=0)
    survDataSE[[i]][,unGroup[j]] = lfhigh(survDataSE[[i]][,"age"])/2-lflow(survDataSE[[i]][,"age"])/2
  }
  survData[[i]] = as.matrix(survData[[i]])
  survDataSE[[i]] = as.matrix(survDataSE[[i]])  
}
survCurves = RubinMat(survData,lse=survDataSE)
C = RubinMat(C)
```
```{r}
print(C)
```

```{r}
plotdata = list()
for (j in 1:length(unGroup))
{
  plotdata[[j]] = data.frame(survCurves[[1]][,c("age",unGroup[j])])
  colnames(plotdata[[j]])[2] = "y"
  plotdata[[j]][,"se"] = survCurves[[2]][,unGroup[j]]
  plotdata[[j]][,"group"] = unGroup[j]
}
plotdata = do.call(rbind,plotdata)

ggplot(plotdata,aes(x=age,y=y,ymin=y-se,ymax=y+se,colour=group,fill=group,shape=group))+
  geom_line()+
  geom_point(data=subset(plotdata,age%%3==0))+
  geom_ribbon(alpha=.2)+
  labs(y="Survival",x="Age")+
  theme_minimal()+
  theme(legend.title=element_blank())
```

```{r}
save=F
if(save)
{
  ggsave(sprintf("%s/results/group_surv.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/group_surv.png",outputDir),g,width=10,height=8,dpi=300)
}
```

# Q5. Does the FI interpolate the FP?
Need to consider uncertainty in both FI and FP, meaning we can't simply bin by NFP.

```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  fifpData[[i]] = as.matrix(data[[i]][,c("fi","Nfp")])
}
fifpData = RubinMat(l=fifpData)
#fifpData = do.call(rbind,fifpData)

#plotdata=data.frame(fifpData)
#plotdata[,"fi_se"] = 0
#plotdata[,"Nfp_se"] = 0
plotdata = data.frame(fifpData[[1]])
plotdata[,"fi_se"] = fifpData[[2]][,"fi"]
plotdata[,"Nfp_se"] = fifpData[[2]][,"Nfp"]
ggplot(plotdata,aes(x=Nfp,xmin=Nfp-Nfp_se,xmax=Nfp+Nfp_se,
                    y=fi,ymin=fi-fi_se,ymax=fi+fi_se))+
  #geom_jitter(width=.1)+
  geom_point()+
  geom_errorbar(width=0,alpha=.1)+
  geom_errorbarh(alpha=.1)+
  scale_x_continuous(limits=c(0,5))+
  scale_y_continuous(limits=c(0,1))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1))+
  #annotation_logticks(sides = "l") +
  #geom_smooth(mapping=aes(weight=1/(fi_se^2+Nfp_se^2)),method="gam",formula=y~s(x,k=3),fullrange=T) +
  #geom_smooth(mapping=aes(weight=1/(fi_se^2+Nfp_se^2)),method="lm",formula=y~x,fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T) +
  #geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/fi_se^2)) +
  labs(y="FI",x="Number of fab-5 deficits (NFP)")+
  theme_minimal()
```
Maybe this approach is okay... 

```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  #Nfp = data[[i]][,"Nfp"]
  Nfp = data[[i]][,"Nfp_qcut"]
  #un = sort(unique(Nfp))
  un = 0:5
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    fi = data[[i]][Nfp == un[j],"fi"]
    mbs = medianBS(fi,nboot=100)
    subdata[[j]] = data.frame(Nfp=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]])
    subdataSE[[j]] = data.frame(Nfp=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]])
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpData = RubinMat(l=fifpData,lse=fifpDataSE)
save=T
if(save)
{
  saveRDS(fifpData,sprintf("%s/data/fifpData_nhanes.rds",outputDir))
}
```
```{r}
plotdata = data.frame(fifpData[[1]])
plotdata[,"fi_mean_se"] = fifpData[[2]][,"fi_mean"]
plotdata[,"fi_median_se"] = fifpData[[2]][,"fi_median"]
plotdata[,"weights"] = 1/plotdata[,"fi_mean_se"]^2
#ggplot(plotdata,aes(x=Nfp,y=fi_median,ymin=fi_median-fi_median_se,ymax=fi_median+fi_median_se))+
ggplot(plotdata,aes(x=Nfp,y=fi_mean,ymin=fi_mean-fi_mean_se,ymax=fi_mean+fi_mean_se))+
  geom_pointrange()+
  scale_x_continuous(limits=c(0,5))+
  scale_y_continuous(limits=c(0,1.5))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1))+
  #annotation_logticks(sides = "l") +
  geom_smooth(mapping=aes(weight=1/fi_mean_se^2),method="gam",formula=y~s(x,k=3),fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/fi_mean_se^2),colour="red") +
  labs(y="FI",x="Number of fab-5 deficits (NFP)")+
  theme_minimal()
```

# Prediction models

Do the FI and NFP contain complementary information or redundant? Using them both in a survival model we can get an idea.

#add new columns for binary death
we have all deaths/censors up for 13 years
```{r}
tcuts = c(2,4)
for (i in 1:length(data))
{
  for (j in 1:length(tcuts))
  {
    dead = (scut[,2] < scut[,1]  + tcuts[j]) & scut[,3]==1 #died within interval
    data[[i]][,sprintf("dead_by_%02d",tcuts[j])] = as.integer(dead)
  }
}
```

```{r}
Nreps = 10
Nfolds = 10
mc.cores = 1 #12
print(fpNames)
outTypes = rep("binary",length(fpNames)+length(tcuts))
names(outTypes) = c(fpNames,sprintf("dead_by_%02d",tcuts))
outTypes = c(outTypes)
gLoad=T
gSave=T
gUseSurvival=F
```
```{r}
fits = list()
```

```{r}
baseName = "nhanes_age_sex_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$age_sex = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$age_sex = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "nhanes_fi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$fi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```


```{r}
baseName = "nhanes_barefi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$barefi = readRDS(file)
} else
{
  dataTypes = c(fi="continuous",fi="continuous") #trick to get it to run without error
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)

  fits$barefi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "nhanes_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "nhanes_fi_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi_Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$fi_Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "nhanes_all_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$all = readRDS(file)
} else
{
  fpVarTypes = rep("binary",length(fpNames))
  names(fpVarTypes) = fpNames
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous",fpVarTypes)
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$all = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "nhanes_fifp_calc" #uses fifp i.e. fi including FP deficits
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fifp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fifp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$fifp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```




```{r}
scores = list()
for (i in 1:length(fits))
{
  scores[[i]] = fits[[i]]$score
  scores[[i]][,sprintf("%s_se",colnames(fits[[i]]$scoreSE))] = fits[[i]]$scoreSE
  scores[[i]][,"outcome"] = rownames(fits[[i]]$score)
  scores[[i]][,"model"] = names(fits)[i]
}
scores = do.call(rbind,scores)

scores[,"clean_name"] = gsub("age_sex","Covariates only (age and sex)",scores[,"model"])
scores[,"clean_name"] = gsub("all","All predictors",scores[,"clean_name"])
scores[,"clean_name"] = gsub("fi_Nfp","FI and NFab5",scores[,"clean_name"])
scores[scores[,"model"]=="fi_onehotNfp","clean_name"] = "FI and NFab5 (onehot encoded)"
scores[scores[,"model"]=="fi","clean_name"] = "FI"
scores[scores[,"model"]=="Nfp","clean_name"] = "NFab5"
scores[scores[,"model"]=="fifp","clean_name"] = "FI - including fab-5 varibles"
```



make a table
should add survival too; maybe make its own table
```{r}
bestFit = fits[["fi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
#C[,"Outcome"] = rownames(C)
#for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
#C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

#C2[,"Outcome"] = rownames(C2)
#for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
#C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/nhanes_glm.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/nhanes_glm_v2.csv",outputDir),row.names=FALSE)
```

```{r}
bestFit = fits[["barefi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
#C[,"Outcome"] = rownames(C)
#for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
#C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

#C2[,"Outcome"] = rownames(C2)
#for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
#C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/glm_nhanes_bare.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/glm_nhanes_bare_v2.csv",outputDir),row.names=FALSE)
```



what if we use everything we know about the current health state? kitchen skin model
```{r}
baseName = "nhanes_fi_fab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$sink = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",bmi="binary",
                weak="binary", gait="binary", exhausted="binary", activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  for (i in 1:length(reshapedData)) reshapedData[[i]][["data"]][,"sex"] = as.integer(as.character(reshapedData[[i]][["data"]][,"sex"]))
  fits$sink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "nhanes_fi_barefab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$baresink = readRDS(file)
} else
{
    dataTypes = c(fi="continuous",bmi="binary",
                weak="binary", gait="binary", exhausted="binary", activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)],survival=scut)
  fits$baresink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=gUseSurvival,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

kitchen sink tileplot
qualitative structure seems more important than quantitative
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()
Clow = list()
Chigh =  list()
for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  Clow[[k]] = C[[k]]
  Chigh[[k]] = C[[k]]
  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"])
        Clow[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]-errorScale*subFitSE[jj,"Coef"])
        Chigh[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]+errorScale*subFitSE[jj,"Coef"])
      }
    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
  Clow[[k]][,setdiff(vars,colnames(Clow[[k]]))] = NA
  Chigh[[k]][,setdiff(vars,colnames(Chigh[[k]]))] = NA
}
C = do.call(rbind,C)
Clow = do.call(rbind,Clow)
Chigh = do.call(rbind,Chigh)
Clow = Clow[sort.list(C[,"sort_column"]),]
Chigh = Chigh[sort.list(C[,"sort_column"]),]
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]
Clow = C[,setdiff(colnames(Clow),"sort_column")]
Chigh = Chigh[,setdiff(colnames(Chigh),"sort_column")]
#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]
  Clow = C[,setdiff(colnames(Clow),"fi.1")]
  Chigh = Chigh[,setdiff(colnames(Chigh),"fi.1")]
}

#sort columns
ord = rev(c(2:4,5:ncol(C),1))
C = C[,ord]
Clow = Clow[,ord]
Chigh = Chigh[,ord]

#cover ugly x:
Clow[is.na(C)] = 1-1/10^6
Chigh[is.na(C)] = 1+1/10^6
C[is.na(C)] = 1
g = TilePlot(log(C,10),mcilow=log(Clow,10),mcihigh=log(Chigh,10),na.value="grey90",pointSize=8,dropNonSig = T)
#fix labels
nms = colnames(C)
nms = gsub("auc","AUC",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
nms = gsub("activity","Low activity",nms)
nms = gsub("bmi","Low BMI",nms)
nms = gsub("exhausted","Exhaustion",nms)
nms = gsub("gait","Slow gait",nms)
nms = gsub("weak","Feel weak",nms)
g = g + scale_y_discrete(breaks=colnames(C),labels=nms)
nms = rownames(C)
for (j in 1:2) nms = gsub(sprintf("next%d",j),"next",nms)
nms = gsub("activity","Low activity",nms)
nms = gsub("bmi","Low BMI",nms)
nms = gsub("exhausted","Exhaustion",nms)
nms = gsub("gait","Slow gait",nms)
nms = gsub("weak","Feel weak",nms)
nms = gsub(sprintf("fp"),"FP",nms,fixed=T)
g = g + scale_x_discrete(breaks=rownames(C),labels=nms)
#fix scale
g = g + scale_colour_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0, limit = c(-.3,1.3),
                               name="Odds Ratio", na.value="grey90",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=c("0.5","1","2","5","10"))
g = g + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0, limit =  c(-.3,1.3),
                               name="Odds Ratio", na.value="grey90",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=c("0.5","1","2","5","10"))
g = g + theme(legend.title=element_text())
#add x/y labels
g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=16),axis.title.y=element_text(size=16,angle=90))
#g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=16))
g
save=T
if(save)
{
  ggsave(sprintf("%s/results/fp_tileplot_nhanes.pdf",outputDir),g,width=12,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_tileplot_nhanes.png",outputDir),g,width=12,height=8,dpi=300)
}
```


tabular form
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()

for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  for (j in 1:length(sc)) C[[k]][,sc[j]] = sprintf("$%.3f_{%.3f}^{%.3f}$",theseFits[[k]][["score"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]-qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]+qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]])

  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      
          #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]),exp(subFit[jj,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[jj,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      }

    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
}
C = do.call(rbind,C)
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]

#drop OR
colnames(C) = gsub(" OR","",colnames(C))
#clean up names
nms = colnames(C)
nms = gsub("auc","AUC",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
nms = gsub("activity","Low activity",nms)
nms = gsub("bmi","Low BMI",nms)
nms = gsub("exhausted","Exhaustion",nms)
nms = gsub("gait","Slow gait",nms)
nms = gsub("weak","Feel weak",nms)
colnames(C) = nms

#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]

}

#add outcome column
C[,"Outcome"] = rownames(C)
C[grep("frail",C[,"Outcome"] ),"Outcome"]      = "FP frailty"
C[grep("weight",C[,"Outcome"] ),"Outcome"]     = "Weight loss"
C[grep("grip",C[,"Outcome"] ),"Outcome"]       = "Weakness"
C[grep("gait",C[,"Outcome"] ),"Outcome"]       = "Slow gait"
C[grep("exhaustion",C[,"Outcome"] ),"Outcome"] = "Exhaustion"
C[grep("activity",C[,"Outcome"] ),"Outcome"]   = "Low activity"

#sort columns
ord = c("Outcome",setdiff(colnames(C),"Outcome"))
C = C[,ord]

#drop NAs
C[is.na(C)] = ""


write.csv(C,sprintf("%s/results/fp_nhanes.csv",outputDir),row.names=FALSE)
```

kitchen sink model
```{r}
bestFit = fits[["sink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 100
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/nhanes_glm_sink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/nhanes_glm_sink_v2.csv",outputDir),row.names=FALSE)
```

```{r}
bestFit = fits[["baresink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 100
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/nhanes_glm_baresink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/nhanes_glm_baresink_v2.csv",outputDir),row.names=FALSE)
```


```{r}
warning("temp")
gLoad=F
```
# Demographic stuff

Change in FI/FP w.r.t age
```{r}
mat = list()
matSE = list()
for (i in 1:length(data))
{
  age = data[[i]][,"age"]
  un = sort(unique(age))
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    fi = data[[i]][age == un[j],"fi"]
    fp = data[[i]][age ==  un[j],"Nfp"]
    sex = as.numeric(as.character(data[[i]][age ==  un[j],"sex"]))
    mbs = medianBS(fi,nboot=100)
    subdata[[j]] = data.frame(age=un[j],sex=mean(sex,na.rm=T),Nfp_mean=mean(fp,na.rm=T),fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]])
    subdataSE[[j]] = data.frame(age=un[j],sex=mean(sex,na.rm=T),Nfp_mean=SEM(fp,na.rm=T),fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]])
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  mat[[i]] = as.matrix(subdata)
  matSE[[i]] = as.matrix(subdataSE)
}
fifpAgeData = RubinMat(l=mat,lse=matSE)
```

```{r}
cols = gg_color_hue(2)
plotdata = data.frame(fifpAgeData[[1]][,c("age","sex")])
plotdata[,"y"] = fifpAgeData[[1]][,"fi_mean"]
plotdata[,"se"] = fifpAgeData[[2]][,"fi_mean"]
#plotdata[,"y"] = fifpAgeData[[1]][,"fi_median"]
#plotdata[,"se"] = fifpAgeData[[2]][,"fi_median"]
plotdata[,"weights"] = 1/plotdata[,"se"]^2
plotdata[,"model"] = "FI"
plotdata = list(plotdata)
plotdata[[2]] = data.frame(fifpAgeData[[1]][,c("age","sex")])
plotdata[[2]][,"y"] = fifpAgeData[[1]][,"Nfp_mean"]/5
plotdata[[2]][,"se"] = fifpAgeData[[2]][,"Nfp_mean"]
plotdata[[2]][,"weights"] = 1/plotdata[[2]][,"se"]^2
plotdata[[2]][,"model"] = "NFP" 
plotdata = do.call(rbind,plotdata)
#ggplot(plotdata,aes(x=age,y=fi_median,ymin=fi_median-fi_median_se,ymax=fi_median+fi_median_se))+
ggplot(plotdata,aes(x=age,y=y,ymin=y-se,ymax=y+se,shape=model,colour=model))+
  geom_pointrange()+
  scale_x_continuous()+
  scale_y_continuous(limits=c(0,.5),sec.axis = sec_axis(~ . * 5, name = "Number of phenotypic deficits (NFP)"))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1),sec.axis = sec_axis(~ . * 5, name = "Number of phenotypic deficits (NFP)"))+
  annotation_logticks(sides = "l") +
  geom_smooth(mapping=aes(weight=1/se^2),method="gam",formula=y~s(x,k=3),fullrange=T) + #,
  #geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/se^2)) +
  labs(y="FI",x="Age (truncated at 85)")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.1,.8),
        axis.line.y = element_line(color = cols[1]), 
       axis.ticks.y = element_line(color = cols[1]),
        axis.line.y.right = element_line(color = cols[2]), 
       axis.ticks.y.right = element_line(color = cols[2])
        )
```

# Cox modelling
```{r}
mat = list()
matSE = list()
for (i in 1:length(data))
{
  C = numeric()
  se = C
  
  #baseline variables
  m = coxph(s~age+sex,data[[i]])
  C[1] = concordance(m)$concordance
  se[1] = sqrt(concordance(m)$var)
  
  
  #just fi
  m = coxph(s~age+sex+fi,data[[i]])
  C[2] = concordance(m)$concordance
  se[2] = sqrt(concordance(m)$var)
  
  #just Nfp
  m = coxph(s~age+sex+Nfp,data[[i]])
  C[3] = concordance(m)$concordance
  se[3] = sqrt(concordance(m)$var)
  
  m = coxph(s~age+sex+fifp,data[[i]])
  C[4] = concordance(m)$concordance
  se[4] = sqrt(concordance(m)$var)
  
  m = coxph(s~age+sex+fi+Nfp,data[[i]])
  C[5] = concordance(m)$concordance
  se[5] = sqrt(concordance(m)$var)
  
  m = coxph(s~age+sex+fi+Nfp+bmi+gait+weak+exhausted+activity,data[[i]])
  C[6] = concordance(m)$concordance
  se[6] = sqrt(concordance(m)$var)
  
  mat[[i]] = as.matrix(data.frame(C=C))
  rownames(mat[[i]]) = c("Age + sex","FI","NFab5","FI - including fab-5","FI + Nfp","All")
  matSE[[i]] = as.matrix(data.frame(C=se))
  rownames(matSE[[i]]) =   rownames(mat[[i]])
}
cph = RubinMat(mat,lse=matSE)
```

```{r}
plotdata = data.frame(C=cph[[1]][,"C"],se=cph[[2]][,"C"],model=rownames(cph[[1]]))

plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"C"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=C,ymin=C-se,ymax=C+se))+
  geom_pointrange(position=position_dodge(.2))+
  geom_hline(yintercept=max(plotdata[,"C"]-plotdata[,"se"],na.rm=T),colour="red",lty=3)+
  labs(x="",y="C-index")+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```

#############################################
#############################################
#############################################
# spare code
#############################################
#############################################
```{r}
library(glmnet)
weights = rep(1,length(fi))
Nfrail = sum(outcomes$frail==1,na.rm=T)
Nnon = sum(outcomes$frail==0,na.rm=T)
weights[outcomes$frail==1] = Nnon/Nfrail
fit = glm(frail~fi,data.frame(frail=outcomes[,"frail"],fi=fi),family="binomial",weights=weights)
print(fit)
xtabs(~outcomes[,"frail"]+I(predict(fit) > 0.5) )
```

```{r}
#should be perfect predictor
fit = glm(frail~fp,data.frame(frail=outcomes[,"frail"],fp=apply(fp,1,mean,na.rm=T)),family="binomial",weights=weights)
print(fit)
xtabs(~outcomes[,"frail"]+I(predict(fit) > 0.5) )
```

```{r}
z = data.frame(fp,fi=fi,mufp=apply(fp,1,mean,na.rm=T))
acc = list()
methods = c("fp","mufp","fi")
for (i in 1:3) acc[[i]] = data.frame(var=colnames(fp),method=methods[i])
names(acc)=methods
scores = c("sensitivity","specificity","accuracy","youden")
for (j in 1:length(colnames(fp)))
{
  print(colnames(fp)[j])
  gt = factor(z[,colnames(fp)[j]],c(0,1))
    
  weights = rep(1,nrow(z))
  Nfrail = sum(z[,colnames(fp)[j]]==1,na.rm=T)
  Nnon = sum(z[,colnames(fp)[j]]==0,na.rm=T)
  weights[z[,colnames(fp)[j]]==1] = Nnon/Nfrail
  
  #all FP predictors
    print("fp")
  f = sprintf("%s~.",colnames(fp)[j])
  fit = glm(as.formula(f),z[,colnames(fp)],family="binomial",weights=weights)
  
  pr = factor(1*(predict(fit,z) > 0.5),c(0,1))
  ass = Assess(xtabs(~gt+pr))
  for (jj in 1:length(scores)) acc[[1]][j,scores[jj]] = ass[1,scores[jj]]
  rm(fit)
   
  #poor man's FI
    print("mufp")
  fit = glm(bmi~mufp,z,family="binomial",weights=weights)
  
  pr = factor(1*(predict(fit,z) > 0.5),c(0,1))
  ass = Assess(xtabs(~gt+pr))
  for (jj in 1:length(scores)) acc[[2]][j,scores[jj]] = ass[1,scores[jj]]
  rm(fit)
  
  # FI
  print("fi")
  fit = glm(bmi~fi,z,family="binomial",weights=weights)
  
  pr = factor(1*(predict(fit,z) > 0.5),c(0,1))
  ass = Assess(xtabs(~gt+pr))
  for (jj in 1:length(scores)) acc[[3]][j,scores[jj]] = ass[1,scores[jj]]
  rm(fit)
}
acc = do.call(rbind,acc)
```

# Extra

Show NFP response based on cuts i.e. NFP vs FI
```{r}
#train a polr model
i = 1
newdata = data.frame(fi=seq(0,1,length=101))
pred = newdata
  weights = rep(1,nrow(data[[i]]))
  for (j in 0:5) weights[data[[i]][,"Nfp"]==j] = 1/mean(data[[i]][,"Nfp"]==j,na.rm=T)

  fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           summaryFunction = SummaryNfp
                           )
  
  marsGrid =  expand.grid(degree=1:2,nprune=c(2,3,5)) #default is 1 for degree; 2,3,5 for nprine
  
  marsFI =  train(Nfp ~ fi, data = data[[i]], 
                 method = c("bagEarth"), 
                 trControl = fitControl,
                 #metric="Mean_Youden",
                 #maximize=T,
                 tuneGrid=marsGrid,
                 var.method="const"
                 )
  marsFI$results[,"model"] = "mars"
  marsFI$results[,"weighted"] = F
  marsFI$results[,"metrics"] = "fi"
  marsFI$pred = predict(marsFI,newdata=newdata)
  predMarsFI=data.frame(newdata,marsFI$pred)
  

  gamFI =  train(Nfp ~ fi, data = data[[i]], 
                 method = c("gam"), 
                 metric="Mean_Youden",
                 maximize=T,
                 trControl = fitControl)
  gamFI$results[,"model"] = "gam"
  gamFI$results[,"weighted"] = F
  gamFI$results[,"metrics"] = "fi"
  gamFI$pred = predict(gamFI$finalModel,newdata=newdata,se.fit=T)
  #gamFI$pred = predict(gamFI,newdata=newdata)
  predGamFI=data.frame(newdata,y=gamFI$pred[[1]],se=gamFI$pred[[2]])
  
  polrFI =  train(Nfp_ord ~ fi, data = data[[i]], 
                 method = c("polr"), 
                 trControl = fitControl)
  polrFI$results[,"model"] = "polr"
  polrFI$results[,"weighted"] = F
  polrFI$results[,"metrics"] = "fi"
  polrFI$pred = ExpectationPr(predict(polrFI,newdata=newdata,type="prob"))
  predPolr=data.frame(newdata,polrFI$pred)
  
  #hideous
  #rfFI =  train(Nfp_ord ~ fi, data = data[[i]], 
  #               method = c("rf"), 
  #               trControl = fitControl)
  #rfFI$results[,"model"] = "rf"
  #rfFI$results[,"weighted"] = T
  #rfFI$results[,"metrics"] = "fi"
  #rfFI$pred = ExpectationPr(predict(rfFI,newdata=newdata,type="prob"))
  #predRfFI=data.frame(pred,rfFI$pred)
  #ordinal RF: #too slow
  #rfFI =  train(Nfp_ord ~ fi, data = data[[i]], 
  #               method = c("ordinalRF"), 
  #               trControl = fitControl)
  #rfFI$results[,"model"] = "rf"
  #rfFI$results[,"weighted"] = T
  #rfFI$results[,"metrics"] = "fi"
  #rfFI$pred = ExpectationPr(predict(rfFI,newdata=newdata,type="prob"))
  #predRfFI=data.frame(pred,rfFI$pred)
  
  #ordinary cart
  #rfFI =  train(Nfp_ord ~ fi, data = data[[i]], 
  #               method = c("rpartScore"), 
  #               trControl = fitControl)
  #rfFI$results[,"model"] = "rf"
  #rfFI$results[,"weighted"] = T
  #rfFI$results[,"metrics"] = "fi"
  #rfFI$pred = ExpectationPr(predict(rfFI,newdata=newdata,type="prob"))
  #predRfFI=data.frame(pred,rfFI$pred)

  polrFIW =  train(Nfp_ord ~ fi, data = data[[i]], 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
  polrFIW$results[,"model"] = "polr"
  polrFIW$results[,"weighted"] = T
  polrFIW$results[,"metrics"] = "fi"
  polrFIW$pred = ExpectationPr(predict(polrFIW,newdata=newdata,type="prob"))
  predPolrW=data.frame(newdata,polrFIW$pred)
  
  
  #linear model
  fit = lm(Nfp~fi,data=data[[i]])
  predLM = data.frame(newdata,predict(fit,newdata=newdata,se=T))
  colnames(predLM)[2:3] = c("y","se")
  
```

#RF
```{r}
library(ranger)

preds = c("sex","age","fi","bmi","gait","weak","exhausted","activity")

names(preds)=c("Female","Age per 10","FI per 0.1","Low BMI","Slow","Weakness","Exhaustion","Low activity")
use = list()
use[[1]] = preds %in% c("fi")
use[[2]] = preds %in% c("age","sex")
use[[3]] = preds %in% c("age","sex","fi")
use[[4]] = preds == preds


s2 = s
s2 = Surv(s[,2]-s[,1],s[,3]) #subtract baseline age
slogi = !is.na(s2[,1]) #ranger hates NAs
    
C = list()
Cse = list()
for (ii in 1:length(stst))
{
    s2 = s2[slogi,]
  
  C[[ii]] = matrix(NA,ncol=length(preds)+1,nrow=length(use))
  colnames(C[[ii]]) = c("C",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]]))
  Cse[[ii]] = C[[ii]]
  for (j in 1:length(use))
  {
    temp = stst[[ii]][slogi,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = ranger(s2~.,temp)
    C[[ii]][j,"C"] = 1 - mod[["prediction.error"]]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2 = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2) = dimnames(C[[1]])
for (j in 1:length(preds)) C2[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2[is.na(C[[1]])] = ""
C2[,"BIC"] = sprintf("%.0f",C[[1]][,"BIC"])
C2[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2)[colnames(C2)==preds[j]] = names(preds)[j]

write.csv(C2,sprintf("%s/results/nhanes_rf_survival.csv",outputDir),row.names=FALSE)
```

#random forest model for survival
```{r}
cihigh = pnorm(1)
cilow = pnorm(-1)
preds = c("sex","age","fi","bmi","gait","weak","exhausted","activity")
vals = list(sex=c(0,1),age=seq(60,100,by=5),fi=seq(0,1,by=.05),
            bmi=c(0,1),gait=c(0,1),weak=c(0,1),exhausted=c(0,1),activity=c(0,1)
            )
#preds = c("Nfp")
#vals = list(Nfp=0:5)
#preds = c("fi")
#vals = list(fi=c(seq(0,1,by=.05)))

s2 = s
s2 = Surv(s[,2]-s[,1],s[,3]) #subtract baseline age
slogi = !is.na(s2[,1]) #ranger hates NAs
s2 = s2[slogi,]

ex = expand.grid(vals)
C = list()
Clow = list()
Chigh = list()
Cind=list()
Cmu = list()
Csd = list()
for (ii in 1:length(stst))
{
  temp = stst[[ii]][slogi,preds,drop=F]
  if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
  mod = ranger(s2~.,temp,oob.error=TRUE)
  pr = predict(mod,ex,predict.all=TRUE) #chf: cumulative hazard function #predict.all=TRUE to get 3d array including probs
  ind = which.min(abs(pr$unique.death.times-4))
  print(sprintf("survival time: %.2f",pr[["unique.death.times"]][ind]))
  C[[ii]] = ex
  C[[ii]][,"s"] = apply(pr[["survival"]][,ind,],1,median)
  Cse[[ii]] = ex*0
  Cmu[[ii]] = ex
  Cmu[[ii]][,"s"] = apply(pr[["survival"]][,ind,],1,mean)
  Cse[[ii]][,"s"] = apply(pr[["survival"]][,ind,],1,sd)
  Clow[[ii]] = ex*0
  Clow[[ii]][,"s"] = apply(pr[["survival"]][,ind,],1,quantile,probs=cilow)
  Chigh[[ii]] = ex*0
  Chigh[[ii]][,"s"] = apply(pr[["survival"]][,ind,],1,quantile,probs=cihigh)
  C[[ii]] = as.matrix(C[[ii]])
  Clow[[ii]] = as.matrix(C[[ii]])
  Chigh[[ii]] = as.matrix(C[[ii]])
  Cind[[ii]] = matrix(1-mod[["prediction.error"]],1,1)
  colnames(Cind[[ii]])="C"
  #keep memory lean and mean
  rm(mod)
  rm(pr)
}
C2 = RubinMat(C)
Clow2 = RubinMat(Clow)
Chigh2 = RubinMat(Chigh)
Cind = RubinMat(Cind)
Cmu = RubinMat(Cmu,lse=Cse) #errorbars are huge for FI alone (???) #maybe because it's continuous #try mars
```

plot out the highest and lowest risk and vary
```{r}
plotdata = as.data.frame(C2[[1]])
plotdata[,"slow"] = Clow2[[1]][,"s"] - Clow2[[2]][,"s"] #imputation errors are surprisingly big
plotdata[,"shigh"] = Chigh2[[1]][,"s"] + Chigh2[[2]][,"s"]

#plotdata[,"Nfp"] = apply(plotdata[,c("bmi","gait","weak","exhausted","activity")],1,sum,na.rm=T)

#incl = c(Age="age",FI="fi",Nfab5="Nfp")
#incl = c(Nfab5="Nfp")
incl = c(FI="fi")
g = list()

for (i in 1:length(incl))
{
  temp = plotdata
  temp[,"x"] = plotdata[,incl[i]]
  temp[,"pr"] = 1-temp[,"s"]
  temp[,"prlow"] = 1-temp[,"shigh"]
  temp[,"prhigh"] = 1-temp[,"slow"]
  #auto method
  maxind = which.max(temp[,"pr"])
  minind = which.min(temp[,"pr"])
  #now we take everybody that has the same covariates as the max risk
  if(incl[i]=="nfp")  vars = setdiff(incl,c(incl[i],"sex")) #has trouble with everybody...
  else vars = setdiff(preds,incl[i]) #has trouble with Nfab5...
  
  maxlogi = apply(temp[rep(maxind,nrow(temp)),vars] == temp[,vars],1,all)
  minlogi = apply(temp[rep(minind,nrow(temp)),vars] == temp[,vars],1,all)

  maxtemp = temp[maxlogi,]
  maxtemp[,"Risk"] = "Highest"
  mintemp = temp[minlogi,]
  mintemp[,"Risk"] = "Lowest"
  temp = rbind(maxtemp,mintemp)
  temp[,"female"] = temp[,"sex"]==1
    
  g[[i]] = ggplot(temp,aes(x=x,y=pr,ymin=prlow,ymax=prhigh,colour=Risk,shape=female))+
    geom_pointrange()+
    geom_smooth()+
    labs(x=names(incl)[i])
}


```


```{r}
plotdata = subset(scores,model%in%c("fi","Nfp","all","fi_Nfp","fifp","age_sex"))
plotdata = subset(plotdata,outcome=="survival")
plotdata[,"clean_name"] = factor(plotdata[,"clean_name"],unique(plotdata[sort.list(plotdata[,"C"],decreasing=T),"clean_name"]))
g = ggplot(plotdata,aes(x=clean_name,y=c,ymin=c-c_se,ymax=c+c_se))+
  geom_pointrange(position=position_dodge(.2))+
  geom_hline(yintercept=max(plotdata[,"c"]-plotdata[,"c_se"],na.rm=T),colour="red",lty=3)+
  labs(x="",y="C-index")+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```
```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/nhanes_cox.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/nhanes_cox.png",outputDir),g,width=10,height=8,dpi=300)
}
```