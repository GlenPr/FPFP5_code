---
title: "fi_vs_fp hrs"
output: html_document
date: "2023-06-10"
---

Glen Pridham, June 2023

Start with CART imputed

I use every other wave since that's how often gait/grip are measured

```{r}
outputDir = "/home/glen/analysis/fi_vs_fp"
gRootDir = "/home/glen/Documents/r" #where scripts are
#gFab5Name = "NPheno5"
#gFab5NameNoN = "Pheno5"
gFab5Name = "NFPFP5"
gFab5NameNoN = "FPFP5"

setwd(outputDir)
print(getwd())

source(sprintf("%s/nhanes.R",gRootDir),verbose=0)
source(sprintf("%s/goodness_of_fit.R",gRootDir),verbose=0)
source(sprintf("%s/pca.R",gRootDir),verbose=0)
source(sprintf("%s/pca_fi.R",gRootDir),verbose=0)
source(sprintf("%s/roc.R",gRootDir),verbose=0)
source(sprintf("%s/survival.R",gRootDir),verbose=0)
```

```{r}
gTextSize = 20
gAxisTextSize = 12
gPointSize = 4
gLineWidth = 1.5
#gColours = function(n,space="ag_GrnYl") return(colorspace::sequential_hcl(n,space))
gColours = function(n) 
{
    hues = seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 90)[1:n]
}
```

```{r}
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}
SummaryNfp = function(data,lev=NULL,model=NULL)
{
  #based on defaultSummary()
  #no assumptions on data
  
  #continuous metrics:
  prnum = as.numeric(as.character(data[,"pred"]))
  gtnum = as.numeric(as.character(data[,"obs"]))
  rmse = sqrt(mean((gtnum-prnum)^2,na.rm=T))
  mae = mean(abs(gtnum-prnum),na.rm=T)
  
  contMetrics = c(rmse,mae)
  names(contMetrics) =   c("RMSE","MAE")
  
  #discrete metrics:
  prin = round(as.numeric(as.character(data[,"pred"])))
  prin[prin < 0] = 0
  prin[prin > 5] = 5
  prin = ordered(prin,0:5)
  gtin = round(as.numeric(as.character(data[,"obs"])))
  gtin = ordered(gtin,0:5)
  
  #C = xtabs(~gtin+prin)
  #multiClassSummary uses sens/spec of pairs then averages together
  discMetrics = multiClassSummary(data=data.frame(obs=gtin,pred=prin),lev=lev,model=model)
  
  youden = discMetrics["Mean_Sensitivity"] + discMetrics["Mean_Specificity"] - 1
  names(youden) = "Mean_Youden"
  
  gtfact = factor(as.integer(gtnum >= 2.99),c(0,1))
  prfact = factor(as.integer(prnum >= 2.99),c(0,1))
  binMetrics = twoClassSummary(data=data.frame(obs=gtfact,pred=prfact),lev=c(0,1),model=NULL) #can't compute AUC since it'll spit out non-binary data so set model=NULL
  binMetrics =  c(binMetrics,binMetrics["Sens"]+binMetrics["Spec"]-1) #add Youden
  names(binMetrics)[length(binMetrics)] = "Youden"
  
  names(binMetrics) = sprintf("%s_fp",names(binMetrics))
  
  
  metrics = c(contMetrics,discMetrics,youden,binMetrics)
  
  return(metrics)
}
```

```{r}
#m = readRDS(sprintf("%s/data/hrs_fi_vs_fp_mice_cart.rds",outputDir))
m = readRDS(sprintf("%s/data/hrs_rand_fi_vs_fp_mice_cart_fpfi.rds",outputDir))
```

```{r}
codex = read.csv(sprintf("%s/rand_fi.csv",outputDir),row.names=1)
fiVar = c("nhmliv", "shlt",   "hibpe",  "diabe",  "cancre", "lunge",  "hearte", "stroke", "arthre",
          "walksa", "walk1a", "chaira", "climsa", "clim1a", "stoopa", "armsa",  "pusha",  "lifta",
          "dimea","dressa", "dressh", "walkra", "walkre", "walkrh", "batha",  "bathh",  "eata",
          "eath",   "beda",   "bede",   "bedh",   "toilta", "toilth", "shopa",  "phonea", "moneya",
          "hosp",   "nrshom", "outpt",  "homcar", "spcfac")
names(fiVar) = codex[fiVar,"Label"]
#clean up names
for (j in 1:length(fiVar)) names(fiVar)[j] = strsplit(names(fiVar)[j],"w5 ",fixed=T)[[1]][2]
for (j in 1:length(fiVar)) names(fiVar)[j] = gsub("r ","",names(fiVar)[j])

fpVar = c('fp1_weight','fp2_grip','fp3_gait','fp4_exhaustion','fp5_low_activity')
names(fpVar) = c("Weight loss","Weakness","Slow gait","Exhaustion","Low activity")

auxVar = c("age","sex") #"walk_time_ave","height","weight" # I'm worried about overfitting #"fi_prev" probably good but I'm concerned I'll get pushback

gAgeCut = 60 #minimum age - doesn't seem to be a max (???)
```

do survival
note: ToStartStop implicitly drops all ages prior to the first measurement (which is right!)
sloooooooow - should save and load later
```{r}
sstst = readRDS(sprintf("%s/data/hrs_survival_startstop.rds",outputDir))
#revert back to non-start stop
ids = unique(sstst[,"id"])

first = rep(NA,length(ids))
last = first
status = first
for (i in 1:length(ids))
{
  logi = sstst[,"id"]==ids[i]
  first[i] = min(sstst[logi,"tstart"])
  last[i] = max(sstst[logi,"tstop"])
  ind = which.max(sstst[logi,"measurement"])
  status[i] = sstst[logi,"status"][ind]
}
#s = Surv(first-1/365.25,last+1/365.25,status)
s = Surv(first,last,status)
rownames(s) = ids
rm(sstst) #plot(s);lines(survfit(s~1),col=2) #perfect agreement


load=T
save=T
file = sprintf("%s/data/hrs_survival_long.rds",outputDir)
if(load & file.exists(file))
{
  slong = readRDS(file)
} else
{
  #stretch out to match long format
  long = mice::complete(m,1)
  longstart = numeric(nrow(long))
  longstop = longstart
  longstatus = longstart
  for (ii in 1:nrow(s)) #go through each individual
  {
    logi = long[,"id"] == rownames(s)[ii]
    longstart[logi] = s[ii,"start"]
    longstop[logi] = s[ii,"stop"]
    longstatus[logi] = s[ii,"status"]
  }
  slong = Surv(longstart,longstop,longstatus)
  #rownames(slong)=long[,"id"]
  if(save) saveRDS(slong,file)
}


#data stores by imputation so many duplicates
load=T
save=T
file = sprintf("%s/data/hrs_survival_startstop_mice.rds",outputDir)
if(load & file.exists(file))
{
  stst = readRDS(file)
} else
{
  stst = list() #start-stop version of data
  for (i in 1:m$m)
  {
    long = mice::complete(m,i)
    long[,colnames(slong)] = slong

  
  
    warning("how does top-coding work? did I already throw those out? I don't see it in the data")
    #logi = long[,"age"] == 99
    #logi[is.na(logi)] = F
    #print(sprintf("dropping %d top-coded individuals",sum(logi)))
    #long = long[!logi,]
  
    logi = apply(is.na(long[,colnames(slong)]),1,any)
    print(sprintf("dropping %d individuals without survival",sum(logi)))
    long = long[!logi,]
  
    long[,"fi"] = apply(long[,fiVar],1,mean,na.rm=T)
    long[,"fifp"] = apply(long[,c(fiVar,fpVar)],1,mean,na.rm=T)
    long[,"Nfp"] = apply(long[,fpVar],1,sum,na.rm=F)
  
    #drops tons, like 17000
    ageLogiCut = slong[,"start"] >= gAgeCut
    #print(sprintf("dropping %d data points from individuals too young for age cut (gAgeCut=%.0f)",sum(!ageLogiCut),gAgeCut))
    print(sprintf("dropping %d individuals too young for age cut (gAgeCut=%.0f)",unlen(long[,"id"])-unlen(long[ageLogiCut,"id"]),gAgeCut))
    long = long[ageLogiCut,]
  
    long[,"fp_frail"] = as.integer(long[,"Nfp"] > 2.99)
    
    stst[[i]] = ToStartStop(long[,c("id","age","sex","fi","fifp","Nfp","fp_frail",fpVar,colnames(s))])
  }
  if(save) saveRDS(stst,file)
}

hrs_surv = s
s = Surv(s[,1],s[,2],s[,3])
rownames(s) = rownames(hrs_surv)
#applty age cut
s = s[s[,1]>=gAgeCut,]

#if(length(stst)!=length(data)) stop("problem")
```


# Reshape into Markovian

```{r}
data = list()
waves = unique(mice::complete(m,1)[,"wave"])

#must be over age gAgeCut at baseline
ageLogiCut = slong[,1] >= gAgeCut
for (i in 1:m$m)
{
  long = mice::complete(m,i)
  data[[i]] = list()
  for (k in 1:(length(waves)-2))
  {
    current_wave = long[long[,"wave"]==waves[k],]
    rownames(current_wave)=current_wave[,"id"]
    next_wave = long[long[,"wave"]==waves[k+2],] #shift by 2 because we never have back-to-back gait nor grip measurements (imputation could handle but... doesn't seem to) #much better but still bad
    rownames(next_wave)=next_wave[,"id"]
    
    #cuts
      #I figure that gait and grip have plenty of overlap and could both reasonably be MAR, so better to impute
    #logiCut = !m$where[long[,"wave"]==waves[k],"fp2_grip"] | !m$where[long[,"wave"]==waves[k],"fp3_gait"] #must have at least one #doesn't make much of a difference
    #logiCut = apply(!m$where[long[,"wave"]==waves[k],fpVar],1,all) #must have ALL fp var
    logiCut = apply(!m$where[long[,"wave"]==waves[k],c("fp1_weight","fp4_exhaustion", "fp5_low_activity")],1,all) & (!m$where[long[,"wave"]==waves[k],"fp2_grip"] | !m$where[long[,"wave"]==waves[k],"fp3_gait"]) #must have weight, exhaustion and low activity AND grip OR gait
    logiCut = logiCut & ageLogiCut[long[,"wave"]==waves[k]] #age cut
    current_wave = current_wave[logiCut,]
    #logiCut = !m$where[long[,"wave"]==waves[k+2],"fp2_grip"] | !m$where[long[,"wave"]==waves[k+2],"fp3_gait"] #must have at least one #doesn't make much of a difference
    #logiCut = apply(!m$where[long[,"wave"]==waves[k+2],fpVar],1,all) #must have ALL fp var
    logiCut = apply(!m$where[long[,"wave"]==waves[k+2],c("fp1_weight","fp4_exhaustion", "fp5_low_activity")],1,all) & (!m$where[long[,"wave"]==waves[k+2],"fp2_grip"] | !m$where[long[,"wave"]==waves[k+2],"fp3_gait"]) #must have weight, exhaustion and low activity AND grip OR gait
    logiCut = logiCut & ageLogiCut[long[,"wave"]==waves[k]] #age cut
    next_wave = next_wave[logiCut,]
    #print(sprintf("Dropping %d due to missingness of grip or gait",sum(!logiCut)))
  
    
    #processing
    pt = intersect(rownames(current_wave),rownames(next_wave))
    current_wave = current_wave[pt,]
    next_wave = next_wave[pt,]
    print(dim(current_wave))

    current_wave[,"Nfp"] = apply(current_wave[,fpVar],1,sum,na.rm=F)
    next_wave[,"Nfp"] = apply(next_wave[,fpVar],1,sum,na.rm=F)
  
    #keepVars = c("age","wave",fpVar,"Nfp")#"fp_robust","fp_prefrail","fp_frail")
    keepVars = c("age","wave",fpVar,fiVar,"Nfp") #temp: keep fiVar too
    #keepVars = c("age","wave",fpVar,fiVar,"Nfp",sprintf("%s_next",c(fpVar,fiVar))) #temp: keep next too

    data[[i]][[k]] = current_wave[,c("id","sex",keepVars)]
    data[[i]][[k]][,"fi"] = apply(current_wave[,fiVar],1,mean,na.rm=T)
    data[[i]][[k]][,"fifp"] = apply(current_wave[,c(fiVar,fpVar)],1,mean,na.rm=T)

    data[[i]][[k]][,sprintf("%s_next",keepVars)] = next_wave[,keepVars]
    data[[i]][[k]][,"fi_next"] = apply(next_wave[,fiVar],1,mean,na.rm=T)
  
    #Must have all 5 FP in wave 4 AND wave 6
    logi = apply(!is.na(data[[i]][[k]][,c(fpVar,sprintf("%s_next",fpVar))]),1,all)
    print(sprintf("dropping %d (%.0f%%) for complete case",sum(!logi),mean(!logi)*100))
    data[[i]][[k]] = data[[i]][[k]][logi,]
  
    #add ordinal variable
    fpclass = rep(NA,nrow(data[[i]][[k]]))
    fpclass[data[[i]][[k]][,"Nfp"] < 0.01] = "robust"
    fpclass[data[[i]][[k]][,"Nfp"] > 0.01 & data[[i]][[k]][,"Nfp"] < 2.99] = "prefrail"
    fpclass[data[[i]][[k]][,"Nfp"]>= 2.99] = "frail"
    fpclass = ordered(fpclass,c("robust","prefrail","frail"))
    data[[i]][[k]][,"fpclass"] = fpclass
    rm(fpclass)


    fpclass = rep(NA,nrow(data[[i]][[k]]))
    fpclass[data[[i]][[k]][,"Nfp_next"] < 0.01] = "robust"
    fpclass[data[[i]][[k]][,"Nfp_next"] > 0.01 & data[[i]][[k]][,"Nfp_next"] < 2.99] = "prefrail"
    fpclass[data[[i]][[k]][,"Nfp_next"]>= 2.99] = "frail"
    fpclass = ordered(fpclass,c("robust","prefrail","frail"))
    data[[i]][[k]][,"fpclass_next"] = fpclass
    rm(fpclass)
  
    data[[i]][[k]][,"fp_frail"] = as.integer(data[[i]][[k]][,"Nfp"] > 2.99)
    data[[i]][[k]][,"fp_frail_next"] = as.integer(data[[i]][[k]][,"Nfp_next"] > 2.99)
    data[[i]][[k]][,"newly_frail"] = as.integer(data[[i]][[k]][,"Nfp"] < 2.99 & data[[i]][[k]][,"Nfp_next"] > 2.99)
  
    data[[i]][[k]][,"Nfp_ord"] = ordered(data[[i]][[k]][,"Nfp"],0:5)
    data[[i]][[k]][,"Nfp_next_ord"] = ordered(data[[i]][[k]][,"Nfp_next"],0:5)
    
    #convert sex to binary
    data[[i]][[k]][,"sex"] = as.integer(data[[i]][[k]][,"sex"] == "female")
  
    
  }

  data[[i]] = do.call(rbind,data[[i]])

}
```
```{r}
df = data[[1]][,c(fiVar[-1],fpVar)]
#df = data[[1]][,c(fiVar[-1],fpVar,sprintf("%s_next",c(fiVar[-1],fpVar)))]
for (j in 1:ncol(df)) df[,j] = as.numeric(as.character(df[,j]))
C = cov2(df,use='pairwise.complete',center=F)
#C = cov2(df[,c(fiVar[-1],fpVar)],df[,sprintf("%s_next",c(fiVar[-1],fpVar))],use='pairwise.complete',center=F)
C = C/sqrt(outer(diag(C),diag(C)))
TilePlot(C)
ord=seriate(C,method="PCA")
TilePlot(C[ord[[1]],ord[[1]]])
ord=seriate(C,method="PCA_angle")
TilePlot(C[ord[[1]],ord[[1]]])


C = cor(df,use='pairwise.complete')
ord=seriate(C,method="PCA")
TilePlot(C[ord[[1]],ord[[1]]])
ord=seriate(C,method="PCA_angle")
TilePlot(C[ord[[1]],ord[[1]]])

pc = prcomp2(df,center=F,scale=F)
#outer(P[,1],Pinv[1,])
#z= y%*%t(Pinv)
#p = x%*%rotation = x%*%t(rotation_inv)
#rotation_inv = t(rotation)
#rotation = P
#should be outer(basis,basis)
g = list()
for (i in 1:9){
  g[[i]] = TilePlot(outer(pc$rotation[,i],pc$rotation[,i]))+ggtitle(sprintf("PC%02d",i))
}

marrangeGrob(g,nrow=3,ncol=3,top=NULL)

C = outer(pc$rotation[,3],pc$rotation[,3])
ord=seriate(abs(C),method="PCA")
inds = ord[[1]]
#inds = c(ord[[1]][-1],ord[[1]][1])
TilePlot(C[inds,inds])
```

Demographic stuff
post imputation, from functional deficit preprocessed data
```{r}
vars = c(Age="age",Females="sex",FI="fi",NFab5="Nfp",FP="fp_frail",fpVar)
prevalence = rep(T,length(vars)) #scale to % 
prevalence[vars %in% c("age","fi","Nfp")] = F
Ndigits = rep(0,length(vars))
Ndigits[vars %in% c("fi","Nfp")] = 2

#prevalence
pr = list()
prse = list()
prsd = list()
for (i in 1:length(data))
{
  pr[[i]] = matrix(NA,nrow=length(vars),ncol=1)
  rownames(pr[[i]]) = names(vars)
  colnames(pr[[i]]) = "Frequency"
  prse[[i]] = pr[[i]]
  prsd[[i]] = pr[[i]]
  for (j in 1:length(vars)) 
  {
    pr[[i]][j,1] = mean(data[[i]][,vars[j]],na.rm=T)
    if(prevalence[j]) #binary variables
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    else  #non-binary
    {
      prsd[[i]][j,1] = sd(data[[i]][,vars[j]],na.rm=T)
      prse[[i]][j,1] = SEM(data[[i]][,vars[j]],na.rm=T)
    }
    
  }
}

pr = RubinMat(pr,prse)
prsd = RubinMat(prsd)

demo = matrix(NA,nrow=nrow(pr[[1]])+2,ncol=2)

colnames(demo) = c("","Frequency/Mean")
demo[1,1] = "Individuals"
demo[1,2] = unlen(data[[1]][,"id"])
demo[2,1] = "Entries"
demo[2,2] = nrow(data[[1]])
skip = 1:2
demo[-skip,1] = rownames(pr[[1]])
demo[-skip,2][prevalence] = sprintf("%.1f%%",100*pr[[1]][prevalence,1]) #,100*prsd[[1]][prevalence,1])  #errors from imputation are small relative to sd so just ignore
demo[-skip,2][!prevalence] = sprintf("%.0f (%.0f)",pr[[1]][!prevalence,1],prsd[[1]][!prevalence,1]) 

demo[-skip,2][Ndigits == 2] = sprintf("%.2f (%.2f)",pr[[1]][Ndigits == 2,1],prsd[[1]][Ndigits == 2,1]) 

save=T
if(save)
{
  write.csv(demo,sprintf("%s/data/demographics_hrs.csv",outputDir),row.names = F)
}
```

combine
```{r}
files = c("hrs","elsa","nhanes")
demo = read.csv(sprintf("%s/data/demographics_hrs.csv",outputDir))
demo = data.frame(var=demo[,1])
for (i in 1:length(files))
{
   demo[,files[i]] = read.csv(sprintf("%s/data/demographics_%s.csv",outputDir,files[i]))[,2]
}
colnames(demo) = toupper(colnames(demo))
colnames(demo)[1] = ""

save=T
if(save)
{
  write.csv(demo,sprintf("%s/data/demographics_all.csv",outputDir),row.names = F)
}
```

# compare survival to ELSA
```{r}
#option 1 (default) #option doesn't seem to matter which one I use
selsa = read.csv(sprintf("%s/data/elsa_cleaned_aug3_survival.csv",outputDir),row.names=1)
selsa = selsa[selsa[,1] >= 60,] #older individuals only
selsa[selsa[,1] >= 90,1] = NA #drop top-coded ages

#data stores by imputation so many duplicates
load=T
save=T
file = sprintf("%s/data/elsa_survival_startstop_mice.rds",outputDir)
if(load & file.exists(file))
{
  ststelsa = readRDS(file)
} else ststelsa = NULL

elsa_surv = selsa
selsa = Surv(selsa[,1],selsa[,2],selsa[,3])
rownames(selsa) = rownames(elsa_surv)
```

```{r}
snhanes = readRDS(sprintf("%s/data/nhanes01_60plus_survival.rds",outputDir))
snhanes = snhanes[snhanes[,1] >= 60,] #older individuals only
snhanes[snhanes[,1] >= 85,1] = NA #drop top-coded ages
```

#why I don't trust elsa survival
```{r}
plotdata = list()
sf = survfit(selsa~1)
plotdata[[1]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="ELSA (all)")
sf = survfit(ststelsa[[1]][[2]]~1)
plotdata[[2]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="ELSA waves 4-6")
sf = survfit(stst[[1]][[2]]~1)
plotdata[[3]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="HRS (all)")
sf = survfit(snhanes~1)
plotdata[[4]] = data.frame(Age=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,group="NHANES (all)")
plotdata =do.call(rbind,plotdata)

plotdata[,"group"] = factor(plotdata[,"group"],c("ELSA waves 4-6","ELSA (all)","HRS (all)","NHANES (all)"))

g = ggplot(plotdata,aes(x=Age,y=S,ymin=Smin,ymax=Smax,colour=group,fill=group,linetype=group))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    scale_y_continuous(limits=c(0,1))+
    #scale_x_continuous(limits=c(60,NA))+
    scale_linetype_manual(values=1:4)+
    labs(x="Age",y="Survival")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize),
          legend.title=element_blank(),
          legend.position=c(.2,.3),
          legend.background = element_rect(fill="white",colour=NA),
          legend.key.size = unit(3,"line")
          )
           
g

save=T
if(save)
{
  ggsave(sprintf("%s/results/s_elsa_w_hrs_nhanes.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/s_elsa_w_hrs_nhanes.png",outputDir),g,width=10,height=8,dpi=300)
}
```

# Q0. What does survival / health look like for individuals missing the fab-5?
```{r}
where = m$where
rownames(where) = mice::complete(m,1)[,"id"]
overlap = intersect(rownames(s),rownames(where))
where = where[overlap,]
stemp = s[overlap,]
complete = apply(where[,fpVar],1,sum) == 0
complete = factor(complete,c(F,T),labels=c("Incomplete","Complete (fab-5)"))
thalf = summary(survfit(stemp~complete))$table[,"median"]
dt = round(diff(thalf),1)
pval = summary(coxph(stemp~complete))$sctest[3]
print(sprintf("p-value (score/logrank test): %s",pval))
g = ggsurv(survfit(stemp~complete),CI=T,plot.cens=F)+
    scale_x_continuous(limits=c(60,NA))+
    labs(x="Age",y="Survival")+
    annotate("segment",x=thalf[1],xend=thalf[2],y=.5,yend=.5,arrow = arrow(ends = "both", angle = 30, length = unit(.2,"cm")))+
    annotate("text",x=mean(thalf),y=.55,label=bquote(Delta*t[1/2]*"="*.(dt)))+
    annotate("text",x=mean(thalf),y=.475,label="***")+
    theme_minimal()+
    theme(title=element_text(),
          legend.title=element_blank(),
          legend.position=c(.8,.8))
g

print(summary(coxph(stemp~complete)))
```

#FI vs FP

```{r}
medianBS = function(x,nboot=100)
{
  m = numeric(nboot)
  for (i in 1:nboot)
  {
    m[i] = median(sample(x,length(x),replace=T),na.rm=T)
  }
  return(list(est=mean(m),se=sd(m)))
}

ExpectationPr = function(pr,newdata=NULL) 
{
  #pr: data.frame from predict e.g. pr = predict(rf,newdata=data[[1]],type="prob")
  cl = as.numeric(colnames(pr))
  
  #most likely class
  maxPr = cl[apply(pr,1,which.max)]
  
  #expectation value of classes
  E = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl),1,sum,na.rm=T)
  #second moment
  E2 = apply(as.matrix(pr)*outer(rep(1,nrow(pr)),cl)^2,1,sum,na.rm=T)  
  #sd
  s = sqrt(E2-E^2)

  if(!is.null(newdata))
  {
  df = matrix(NA,nrow=nrow(pr),ncol=3+ncol(newdata))
  colnames(df) = c(colnames(newdata),"class","Epr","sd")
  df[,1:ncol(newdata)] = as.matrix(newdata)
  df[,1+ncol(newdata)] = maxPr
  df[,2+ncol(newdata)] = E
  df[,3+ncol(newdata)] = s
  }
  else
  {
      df = matrix(NA,nrow=nrow(pr),ncol=3)
    colnames(df) = c("class","Epr","sd")
    df[,1] = maxPr
    df[,2] = E
    df[,3] = s
  }
  return(df)
}
```

# FI and NFP predicting FUTURE NFP
```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  Nfp_pred = data[[i]][,"Nfp_next"]
  un = 0:5 #sort(unique(Nfp_pred))
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    logi = Nfp_pred == un[j]
    if(sum(logi) < 2)
    {
      #problem: NA doesn't work...
      subdata[[j]] = data.frame(Nfp_next=un[j],fi_mean=NA,fi_median=NA,
                              Nfp_mean=NA,Nfp_median=NA)
      subdataSE[[j]] = data.frame(Nfp_next=0,fi_mean=0,fi_median=0,
                                Nfp_mean=0,Nfp_median=0)
      next
    }
    fi = data[[i]][logi,"fi"]
    Nfp = data[[i]][logi,"Nfp"]
    mbs = medianBS(fi,nboot=100)
    mNfp = medianBS(Nfp,nboot=100)
    subdata[[j]] = data.frame(Nfp_next=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]],
                              Nfp_mean=mean(Nfp,na.rm=T),Nfp_median=mNfp[[1]])
    subdataSE[[j]] = data.frame(Nfp_next=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]],
                                Nfp_mean=SEM(Nfp,na.rm=T),Nfp_median=mNfp[[2]])
    rm(logi)
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpNextData = RubinMat(l=fifpData,lse=fifpDataSE,na.rm=T) #na.rm = T not working...
save=T
if(save)
{
  saveRDS(fifpNextData,sprintf("%s/data/fifpData_fp_next_hrs.rds",outputDir))
}
```

```{r}
m1 = lm(Nfp_next~fi_mean,data.frame(fifpNextData[[1]]))
m2 = lm(Nfp_next~Nfp_mean,data.frame(fifpNextData[[1]]))
scale = predict(m1,data.frame(fi_mean=1))/predict(m2,data.frame(Nfp_mean=1))
plotdata = list()
plotdata[[1]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[1]][,"y"] = fifpNextData[[1]][,"fi_mean"]
plotdata[[1]][,"se"] = fifpNextData[[2]][,"fi_mean"]
plotdata[[1]][,"weights"] = 1/plotdata[[1]][,"se"]^2
plotdata[[1]][,"model"] = "FI"
plotdata[[2]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[2]][,"y"] = fifpNextData[[1]][,"Nfp_mean"]/scale
plotdata[[2]][,"se"] = fifpNextData[[2]][,"Nfp_mean"]/scale
plotdata[[2]][,"weights"] = 1/plotdata[[2]][,"se"]^2
plotdata[[2]][,"model"] = "NFab5"
plotdata = do.call(rbind,plotdata)
cols = gg_color_hue(2)
g = ggplot(plotdata,aes(x=Nfp_next,y=y,ymin=y-se,ymax=y+se,colour=model,fill=model,shape=model,linetype=model))+
  geom_pointrange()+
  scale_x_continuous(limits=c(0,5))+
  scale_y_continuous(limits=c(0,NA),
            sec.axis=sec_axis(~ . * scale, name = "Number of fab-5 deficits (NFab5)"))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1),
  #                   sec.axis=sec_axis(~ . * 5, name = "Number of phenotypic deficits (NFP)",breaks=c(.1,1,10)))+
  annotation_logticks(sides = "lr") +
  #geom_smooth(mapping=aes(weight=1/se^2),method="gam",formula=y~s(x,k=3),fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/se^2)) +
  labs(y="FI",x="Number of fab-5 deficits at followup")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.2,.8),
        axis.line.y = element_line(color = cols[1]), 
       axis.ticks.y = element_line(color = cols[1]),
        axis.line.y.right = element_line(color = cols[2]), 
       axis.ticks.y.right = element_line(color = cols[2]))

g
```

```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/fp_next_hrs.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_next_hrs.png",outputDir),g,width=10,height=8,dpi=300)
}
```

#hclust

```{r}
d = list()
C = list()
for (i in 1:m$m)
{

  temp = data[[i]][,c(fpVar,fiVar)]
  #colnames(temp)[1:length(fiVar)+length(fpVar)] = names(fiVar)
  for (j in 1:ncol(temp)) temp[,j] = as.integer(as.numeric(as.character(temp[,j])) > .49) #binarize and drop type

  #binary: #https://en.wikipedia.org/wiki/Jaccard_index
    #binary is >= 0 and <= 1
    #sum( (x[x | y] | y[x | y]) & !(x[x | y] & y[x | y]) )/sum(x | y)
    #considers only when at least x or y == 1
      #proportion of the time you have x or y but not x and y
      #This is same is |intersection|/|union|
  d[[i]] = dist(t(temp),"binary") #canberra is for counts, binary is for binary
  d[[i]] = as.matrix(d[[i]])
  
  C[[i]] = cov2(temp,use='pairwise.complete',center=F)
  
  #could put cluster membership stuff in here to get errorbar
    #both for bootstrap and imputation error
}

d = RubinMat(d)
#d = ListMeanSD(d)
#d = Reduce("+",d)/length(d)
C = RubinMat(C)
```

```{r}
TilePlot(d[[1]])
TilePlot(1-C[[1]])
plot(c(d[[1]]),c(C[[1]]))
plot(c(d[[1]]),c(cov2cor(C[[1]])))
```

```{r}
h = hclust(as.dist(d[[1]]),method="average") #average looks better than default (complete)
plot(h)
```

#ggdendro - for ggplot dendrograms
```{r}
library(ggplot2)
library(ggdendro)
```

```{r}
ggdendrogram(h, rotate = FALSE, size = 2)
```
what is the smallest cluster that contains all 5 FP?
```{r}
library(dendextend)
i = 1
for (i in 1:length(h$labels))
{
  k = length(h$labels)-i+1
  cl = cutree(h, k=k)
  #are all the FP vars in the same cluster?
  if(length(unique(cl[fpVar]))==1)
  {
    print(sprintf("cut at %d",k))
    print("cluster members:")
    clNum = cl[fpVar][1]
    print(cl[cl==clNum]) #who all is in your group
    print("non-cluster members:")
    print(cl[cl!=clNum])
    break
  }
}

plot(color_branches(h, k=k))#leaflab="none")
```

```{r}
#inds = sort.list(cl)
inds = h$labels[h$order]
TilePlot(1-d[[1]][inds,inds])
```

```{r}
ColourLabels = function(labs)
{
  types = codex[labs,"Type"]
  for (j in 1:length(fpVar)) types[labs==fpVar[j]] = "Pheno5"
  types = factor(types)
  cols = gg_color_hue(length(levels(types)))[as.numeric(types)]
  return(data.frame(label=types,colour=cols))
}
```

```{r}
inds = h$labels[h$order]
#ddf = segment(dendro_data(h,type="rectangle"))
ddf = segment(dendro_data(h)) #looks same to me
#ddf[,"colour"] = ordered(cl)
dsort = d[[1]][inds,inds]
nms = rownames(dsort)
nms = codex[rownames(dsort),"Terse"]
rnms = nms
cnms=nms
for (j in 1:length(fpVar)) 
{
  cnms[rownames(dsort)==fpVar[j]] = sprintf("%s \u2190",tolower(names(fpVar)[j])) #
  rnms[rownames(dsort)==fpVar[j]] = sprintf("\u2192  %s",tolower(names(fpVar)[j])) #
}
rownames(dsort) = rnms
colnames(dsort) = cnms
diag(dsort) = NA
alpha = 1 #bigger makes it easier to see connections; smaller makes it harder; 1 = default
gamma = 8 #stretches out
g = TilePlot(1-dsort,na.value="grey89",zname="Similarity") +  geom_segment(data=ddf, aes(x=(y)^alpha*gamma+length(h$labels)+.5, y=x, xend=(yend)^alpha*gamma+length(h$labels)+.5, yend=xend),inherit.aes=F) + #theme(panel.background = element_rect(fill='white', colour="white"))
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(),
        legend.background=element_rect(fill="white",colour="grey60"), 
        #axis.text.x=element_blank(),
        axis.text.x=element_text(angle=90,vjust=.5,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"]),
        axis.text.y=element_text(angle=0,colour=ColourLabels(rownames(d[[1]][inds,inds]))[,"colour"])
        )

#fix legend
#g = g + labs(fill="Proximity",colour="Proximity")
g = g + theme(legend.title=element_text())

#donor plot for labels
df = ColourLabels(rownames(d[[1]][inds,inds]))
df[,"x"] = 1
df[,"y"] = 1
gd = ggplot(df,aes(x=x,y=y,colour=label))+geom_point()+theme(legend.title=element_blank())

#add little arrows beside Pheno5
#r = (1:ncol(dsort))[which(colnames(dsort)%in%tolower(names(fpVar)))]
#for (i in 1:length(r))
#{
#  g = g + annotate("segment",y=r[i],yend=r[i],x=-2,xend=-1,
#                   arrow = arrow(length = unit(0.5, "cm")),colour=gg_color_hue(8)[7]
#                   )
#}
#turn clipping off - to do (I'm trying another solution by changing labels directly)

library(cowplot)
g = list(ggdraw(cowplot::get_legend(gd)),g)



#add box?
#g[[2]] = g[[2]]+annotate("rect",xmin=1.5,ymin=1.5,xmax=28.5,ymax=28.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=28.5,ymin=28.5,xmax=46.5,ymax=46.5,fill=NA,colour="grey50")

#g[[2]] = g[[2]]+annotate("rect",xmin=1.5,ymin=1.5,xmax=18.5,ymax=18.5,fill=NA,colour="grey50")
#g[[2]] = g[[2]]+annotate("rect",xmin=18.5,ymin=18.5,xmax=46.5,ymax=46.5,fill=NA,colour="grey50")

#g[[2]] = g[[2]]+annotate("rect",xmin=8.5,ymin=8.5,xmax=46.5,ymax=46.5,fill=NA,colour="grey50") #big box


marrangeGrob(g,nrow=1,ncol=2,widths=c(.1,.9),top=NULL)


save=T
if(save)
{
  ggsave(sprintf("%s/results/hrs_clustering.pdf",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300,device=cairo_pdf) #cairo for unicode
  ggsave(sprintf("%s/results/hrs_clustering.png",outputDir),marrangeGrob(g,nrow=1,ncol=2,widths=c(.075,.9),top=NULL),width=10,height=8,dpi=300)
}
```

visualize in 2D
not sure what MDS is...
```{r}
fit = isoMDS(as.dist(d[[1]]), k=2) # k is the number of dim
fit # view results

# plot solution
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Nonmetric MDS", type="n")
text(x, y, labels = row.names(d[[1]]),col=1+row.names(d[[1]])%in%fpVar, cex=.7)
```

#correlation matrix
we know it's linear so use pearson
```{r}
BootCor = function(x,nboot=100,...)
{
  C = list()
  for (i in 1:nboot)
  {
    inds = sample(1:nrow(x),replace=T)
    C[[i]] = cor(x[inds,],...)
  }
  C = ListMeanSD(C)
  return(list(C=C[[1]],se=C[[2]]))
}
```

```{r}
C = list()
Cse = list()
vars = c("Nfp","fi","fifp","age")
#method = "pearson"
method = "spearman"
for (i in 1:length(data))
{
  C[[i]] = BootCor(data[[i]][,vars],use='pairwise.complete',method=method) 
  Cse[[i]] = C[[i]][[2]]
  C[[i]] = C[[i]][[1]]
}
C = RubinMat(C,Cse)

save=T
if(save)
{
  write.csv(C[[1]],sprintf("%s/results/%s_hrs.csv",outputDir,method),row.names=T)
  write.csv(C[[2]],sprintf("%s/results/%s_hrs_se.csv",outputDir,method),row.names=T)
}
```

combined correlation matrices
```{r}
method="pearson"
files = c("hrs","elsa","nhanes")
dat = list()
datSE = list()
ord = c("age","fi","fifp","Nfp")
for (i in 1:length(files))
{
  dat[[i]] = read.csv(sprintf("%s/results/%s_%s.csv",outputDir,method,files[i]),row.names=1)
  datSE[[i]]= read.csv(sprintf("%s/results/%s_%s_se.csv",outputDir,method,files[i]),row.names=1)
  dat[[i]] = dat[[i]][ord,ord]
  datSE[[i]] = datSE[[i]][ord,ord]

  #drop everything below diagonal
  dat[[i]][lower.tri(dat[[i]],diag=T)] = NA
  datSE[[i]][lower.tri(datSE[[i]],diag=T)] = NA
    
  #add dataset label
  dat[[i]][,"dataset"] = files[i]
  datSE[[i]][,"dataset"] = files[i]
  
  #add var column
  dat[[i]][,"var"] = rownames(dat[[i]])
  datSE[[i]][,"var"] = rownames(datSE[[i]])
}
dat = do.call(rbind,dat)
datSE = do.call(rbind,datSE)
#no reason to keep first one since no upper tri
if(all(is.na(dat[,1])))
{
  dat = dat[,-1]
  datSE = datSE[,-1]
}


#convert to table
C = matrix("",nrow=nrow(dat),ncol=ncol(dat))
dimnames(C) = dimnames(dat)
for (j in 1:ncol(C)) 
{
  if(colnames(C)[j]%in%c("dataset","var")) next
  C[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",dat[,j],dat[,j]-qnorm(.975)*datSE[,j],dat[,j]+qnorm(.975)*datSE[,j])
}
C[is.na(dat)] = ""
C[,"dataset"] = dat[,"dataset"]
C[,"var"] = dat[,"var"]
C = C[,c("dataset","var",setdiff(colnames(C),c("dataset","var")))]


#clean up names
C[,"dataset"] = toupper(C[,"dataset"])
C[,"var"] = gsub("age","Age",C[,"var"])
C[,"var"][C[,"var"]=="fifp"] = "FI /w fab-5"
C[,"var"] = gsub("fi","FI",C[,"var"])
C[,"var"] = gsub("Nfp","NFab5",C[,"var"])

colnames(C) = gsub("age","Age",colnames(C))
colnames(C)[colnames(C)=="fifp"] = "FI /w fab-5"
colnames(C) = gsub("fi","FI",colnames(C))
colnames(C) = gsub("Nfp","NFab5",colnames(C))
colnames(C) = gsub("dataset","Dataset",colnames(C))
colnames(C) = gsub("var","Variable",colnames(C))

write.csv(C,sprintf("%s/results/%s_cor.csv",outputDir,method),row.names=FALSE)

print(C)
```

# FI predicting NFP

```{r}
fifpData = list()
fifpDataSE = list()
for (i in 1:length(data))
{
  Nfp_pred = data[[i]][,"Nfp"]
  un = 0:5 #sort(unique(Nfp_pred))
  subdata = list()
  subdataSE = list()
  for (j in 1:length(un))
  {
    logi = Nfp_pred == un[j]
    if(sum(logi) < 2)
    {
      #problem: NA doesn't work...
      subdata[[j]] = data.frame(Nfp=un[j],fi_mean=NA,fi_median=NA,
                              Nfp_mean=NA,Nfp_median=NA)
      subdataSE[[j]] = data.frame(Nfp=0,fi_mean=0,fi_median=0,
                                Nfp_mean=0,Nfp_median=0)
      next
    }
    fi = data[[i]][logi,"fi"]
    Nfp = data[[i]][logi,"Nfp"]
    mbs = medianBS(fi,nboot=100)
    mNfp = medianBS(Nfp,nboot=100)
    subdata[[j]] = data.frame(Nfp=un[j],fi_mean=mean(fi,na.rm=T),fi_median=mbs[[1]],
                              Nfp_mean=mean(Nfp,na.rm=T),Nfp_median=mNfp[[1]])
    subdataSE[[j]] = data.frame(Nfp=0,fi_mean=SEM(fi,na.rm=T),fi_median=mbs[[2]],
                                Nfp_mean=SEM(Nfp,na.rm=T),Nfp_median=mNfp[[2]])
    rm(logi)
  }
  subdata = do.call(rbind,subdata)
  subdataSE = do.call(rbind,subdataSE)
  fifpData[[i]] = as.matrix(subdata)
  fifpDataSE[[i]] = as.matrix(subdataSE)
}
fifpData = RubinMat(l=fifpData,lse=fifpDataSE,na.rm=T)
save=T
if(save)
{
  saveRDS(fifpData,sprintf("%s/data/fifpData_hrs.rds",outputDir))
}
```

```{r}
plotdata = data.frame(fifpData[[1]])
plotdata[,"fi_mean_se"] = fifpData[[2]][,"fi_mean"]
plotdata[,"fi_median_se"] = fifpData[[2]][,"fi_median"]
plotdata[,"weights"] = 1/plotdata[,"fi_mean_se"]^2
#ggplot(plotdata,aes(x=Nfp,y=fi_median,ymin=fi_median-fi_median_se,ymax=fi_median+fi_median_se))+
ggplot(plotdata,aes(x=Nfp,y=fi_mean,ymin=fi_mean-fi_mean_se,ymax=fi_mean+fi_mean_se))+
  geom_pointrange()+
  scale_x_continuous(limits=c(0,5))+
  #scale_y_continuous(limits=c(0,1.5))+
  #scale_y_continuous(trans="log10",limits=c(0.03,3),breaks=c(0.01,0.1,1))+
  #annotation_logticks(sides = "l") +
  #geom_smooth(mapping=aes(weight=1/fi_mean_se^2),method="gam",formula=y~s(x,k=3),fullrange=T) +
  geom_smooth(method="lm",formula=y~x,fullrange=T,mapping=aes(weight=1/fi_mean_se^2)) +
  labs(y="FI",x="Number of fab-5 deficits (NFab5)")+
  theme_minimal()
```

```{r}
mat = list()
for (i in 1:length(data))
{
  mat[[i]] = as.matrix(data[[i]][,c("fi","Nfp")])
}
mat = do.call(rbind,mat)

plotdata = data.frame(mat)
plotdata[,"Nfp"] = ordered(plotdata[,"Nfp"],0:5)
ggplot(plotdata,aes(x=Nfp,y=fi))+
  geom_boxplot()+
  geom_smooth(method="lm",formula=y~x,fullrange=T,data=as.data.frame(mat),mapping=aes(x=I(Nfp+1),y=fi),inherit.aes=F) +
  labs(y="FI",x="Number of fab-5 deficits (NFab5)")+
  theme_minimal()
```

```{r}
fpNames = sprintf("%s_next",c("fp_frail",fpVar))
names(fpNames) = c("FP",names(fpVar))
```

```{r}
hist(data[[1]][,"age_next"]-data[[1]][,"age"])
print(meansd(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T))
```

### age / sex dependence
```{r}
LogLinEps = function(fi,
                     age,
                     a0=0.065,
                     weights=NULL, 
                     newdata=data.frame(age=age)
                     )
{
  #fit linear model with skew thing
    #i.e. log(fi+a0) = age
  
  #step 1. find optimal a0 by minimizing residual skew
  obj = function(par)
  {
    mod  = lm(log(fi+par)~age)
    return(abs(skew(mod$residuals)))
  }
  
  op = optim(a0,obj,method="Brent",lower=0.001,upper=.2)
  
  a = op[["par"]]
  
  #step 2. fit model
  if(is.null(weights)) mod = lm(log(fi+a)~age)
  else mod = lm(log(fi+a)~age,weights=weights)
  
  pr = predict(mod,newdata,se.fit=T)
  pr[[1]] = exp(pr[[1]])-a
  pr[[2]] = (exp(pr[[1]]))*pr[[2]]
  
  return(list(pr=pr,mod=mod,op=op,a=a))
}
```

```{r}
agg = list()
aggse = list()
age_cuts = seq(60,90,by=5)
fimodelM = list()
fimodelseM = list()
fimodelF = list()
fimodelseF = list()
fimodel2M = list()
fimodel2seM = list()
fimodel2F = list()
fimodel2seF = list()
testage = seq(60,90,by=1)
for (i in 1:length(data))
{
  agg[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),mean,na.rm=T)
  aggse[[i]] = aggregate(data[[i]][,c("fi","Nfp","age"),drop=F],by=list(age_cut=cut(data[[i]][,"age"],age_cuts,include.lowest=T),sex=data[[i]][,"sex"]),SEM,na.rm=T)
   #drop age_cut and clean up type
  agg[[i]]=agg[[i]][,-1]
  aggse[[i]]=aggse[[i]][,-1]
  for (j in 1:ncol(agg[[i]]))
  {
    agg[[i]][,j] = as.numeric(as.character(agg[[i]][,j]))
    aggse[[i]][,j] = as.numeric(as.character(aggse[[i]][,j]))
  }
  
  agg[[i]] = as.matrix(agg[[i]])
  aggse[[i]] = as.matrix(aggse[[i]])
  
  
  
  fimodelM[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelM[[i]]) = c("age","fi")
  fimodelseM[[i]] = fimodelM[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==0))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelM[[i]][,1] = testage
  fimodelM[[i]][,2] = exp(pr[[1]])
  fimodelseM[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  fimodelF[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodelF[[i]]) = c("age","fi")
  fimodelseF[[i]] = fimodelF[[i]]
  mod = lm(log(fi)~age,subset(data[[i]],fi>0 & sex==1))
  pr=predict(mod,data.frame(age=testage),se.fit=T)
  fimodelF[[i]][,1] = testage
  fimodelF[[i]][,2] = exp(pr[[1]])
  fimodelseF[[i]][,2] = exp(pr[[1]])*pr[[2]]
  
  
  fimodel2M[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2M[[i]]) = c("age","fi")
  fimodel2seM[[i]] = fimodel2M[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==0)[,"fi"],age=subset(data[[i]],sex==0)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2M[[i]][,1] = testage
  fimodel2M[[i]][,2] = pr[[1]]
  fimodel2seM[[i]][,2] = pr[[2]]
  
  fimodel2F[[i]] = matrix(0,nrow=length(testage),ncol=2)
  colnames(fimodel2F[[i]]) = c("age","fi")
  fimodel2seF[[i]] = fimodel2F[[i]]
  mod = LogLinEps(fi=subset(data[[i]],sex==1)[,"fi"],age=subset(data[[i]],sex==1)[,"age"],newdata=data.frame(age=testage))
  pr=mod[["pr"]]
  fimodel2F[[i]][,1] = testage
  fimodel2F[[i]][,2] = pr[[1]]
  fimodel2seF[[i]][,2] = pr[[2]]
}

ageData = RubinMat(agg,aggse)
ageData[[1]] = data.frame(ageData[[1]])
ageData[[1]][,sprintf("%sse",colnames(ageData[[1]]))] = ageData[[2]]
ageData = ageData[[1]]

fiDataM = RubinMat(fimodelM,fimodelseM)
fiDataM[[1]] = data.frame(fiDataM[[1]])
fiDataM[[1]][,sprintf("%sse",colnames(fiDataM[[1]]))] = fiDataM[[2]]
fiDataM = fiDataM[[1]]
fiDataM[,"sex"] = "Male"
fiDataF = RubinMat(fimodelF,fimodelseF)
fiDataF[[1]] = data.frame(fiDataF[[1]])
fiDataF[[1]][,sprintf("%sse",colnames(fiDataF[[1]]))] = fiDataF[[2]]
fiDataF = fiDataF[[1]]
fiDataF[,"sex"] = "Female"
fiData = rbind(fiDataM,fiDataF)

fiData2M = RubinMat(fimodel2M,fimodel2seM)
fiData2M[[1]] = data.frame(fiData2M[[1]])
fiData2M[[1]][,sprintf("%sse",colnames(fiData2M[[1]]))] = fiData2M[[2]]
fiData2M = fiData2M[[1]]
fiData2M[,"sex"] = "Male"
fiData2F = RubinMat(fimodel2F,fimodel2seF)
fiData2F[[1]] = data.frame(fiData2F[[1]])
fiData2F[[1]][,sprintf("%sse",colnames(fiData2F[[1]]))] = fiData2F[[2]]
fiData2F = fiData2F[[1]]
fiData2F[,"sex"] = "Female"
fiData2 = rbind(fiData2M,fiData2F)

sex = rep("Female",nrow(ageData))
sex[ageData[,"sex"]==0] = "Male"
ageData[,"sex"] = sex

ggplot(ageData,aes(x=age,xmin=age-agese,xmax=age+agese,y=fi,ymin=fi-fise,ymax=fi+fise,colour=sex,fill=sex))+
  geom_point()+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  geom_line(data=fiData)+
  geom_ribbon(data=fiData,alpha=.15,colour=NA)+
  geom_line(data=fiData2)+ #log-linear with intercept #looks same
  geom_ribbon(data=fiData2,alpha=.15,colour=NA)

save=T
if(save)
{
  write.csv(ageData,sprintf("%s/results/age_dependence_hrs.csv",outputDir),row.names=T)
  write.csv(fiData,sprintf("%s/results/age_dependence_hrs_logfi.csv",outputDir),row.names=T)
  write.csv(fiData2,sprintf("%s/results/age_dependence_hrs_logepsfi.csv",outputDir),row.names=T)
}
```

combine all files
```{r}
#testage = seq(60,90,by=1)
files = c("hrs","nhanes","elsa")
ageData = list()
agg = list()

for (i in 1:length(files))
{
  ageData[[i]] = read.csv(sprintf("%s/results/age_dependence_%s.csv",outputDir,files[i]))
  ageData[[i]][,"dataset"] = files[i]
}
ageData = do.call(rbind,ageData)

fimodelM = data.frame(age=testage,fi=NA)
weights = 1/subset(ageData,sex=="Male" & fi> 0)[,"fise"]^2
mod = lm(log(fi)~age,subset(ageData,fi>0 & sex=="Male"),weights=weights)
pr=predict(mod,data.frame(age=testage),se.fit=T)
fimodelM[,"fi"] = exp(pr[[1]])
fimodelM[,"fise"] = exp(pr[[1]])*pr[[2]]
  
fimodelF = data.frame(age=testage,fi=NA)
weights = 1/subset(ageData,sex=="Female" & fi> 0)[,"fise"]^2
mod = lm(log(fi)~age,subset(ageData,fi>0 & sex=="Female"),weights=weights)
pr=predict(mod,data.frame(age=testage),se.fit=T)
fimodelF[,"fi"] = exp(pr[[1]])
fimodelF[,"fise"] = exp(pr[[1]])*pr[[2]]

fimodel2M = data.frame(age=testage,fi=NA)
#weights = 1/(subset(ageData,sex=="Male")[,"fise"]^2+subset(ageData,sex=="Male")[,"agese"]^2)
weights = 1/subset(ageData,sex=="Male")[,"fise"]^2
mod = LogLinEps(fi=subset(ageData,sex=="Male")[,"fi"],age=subset(ageData,sex=="Male")[,"age"],newdata=fimodel2M,weights=weights)
pr=mod[["pr"]]
fimodel2M[,"fi"] = pr[[1]]
fimodel2M[,"fise"] = pr[[2]]
  
fimodel2F = data.frame(age=testage,fi=NA)
#weights = 1/(subset(ageData,sex=="Female")[,"fise"]^2+subset(ageData,sex=="Female")[,"agese"]^2)
weights = 1/subset(ageData,sex=="Female")[,"fise"]^2
mod = LogLinEps(fi=subset(ageData,sex=="Female")[,"fi"],age=subset(ageData,sex=="Female")[,"age"],newdata=fimodel2F,weights=weights)
pr=mod[["pr"]]
fimodel2F[,"fi"] = pr[[1]]
fimodel2F[,"fise"] = pr[[2]]
  
fimodelM[,"sex"] = "Male"
fimodelF[,"sex"] = "Female"
fiData = rbind(fimodelM,fimodelF)

fimodel2M[,"sex"] = "Male"
fimodel2F[,"sex"] = "Female"
fiData2 = rbind(fimodel2M,fimodel2F)

ageData[,"dataset"] = toupper(ageData[,"dataset"])

g = list()
g[[1]] = ggplot(ageData,aes(x=age,xmin=age-agese,xmax=age+agese,y=fi,ymin=fi-fise,ymax=fi+fise,colour=sex,fill=sex,shape=dataset))+
  geom_point(size=3)+
  geom_errorbar(size=1,width=0)+
  geom_errorbarh(size=1,height=0)+
  #geom_smooth(data=ageData,aes(x=age,y=fi,fill=sex,colour=sex),inherit.aes=F)+
  geom_line(data=fiData,aes(x=age,y=fi,colour=sex,linetype=sex),inherit.aes=F)+
  geom_ribbon(data=fiData,aes(x=age,ymin=fi-fise,ymax=fi+fise,fill=sex),inherit.aes=F,alpha=.15,colour=NA)+
  #geom_line(data=fiData2,aes(x=age,y=fi,colour=sex),inherit.aes=F)+ #log-linear with intercept #looks same but much bigger errorbars
  #geom_ribbon(data=fiData2,aes(x=age,ymin=fi-fise,ymax=fi+fise,fill=sex),inherit.aes=F,alpha=.15,colour=NA)+
  labs(y="FI",x="Age")+
  guides(colour=guide_legend(ncol=2,byrow=FALSE))+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
        legend.background = element_rect(fill="white",colour=NA),
          legend.position= c(.25,.79),
          legend.key.size = unit(2,"line"),
          legend.text=element_text(size=gTextSize*.9),
          legend.title=element_blank()
        )

```

```{r}
NfpmodelM = data.frame(age=testage,Nfp=NA)
weights = 1/subset(ageData,sex=="Male" & Nfp> 0)[,"fise"]^2
mod = lm(log(Nfp)~age,subset(ageData,Nfp>0 & sex=="Male"),weights=weights)
pr=predict(mod,data.frame(age=testage),se.fit=T)
NfpmodelM[,"Nfp"] = exp(pr[[1]])
NfpmodelM[,"Nfpse"] = exp(pr[[1]])*pr[[2]]
  
NfpmodelF = data.frame(age=testage,Nfp=NA)
weights = 1/subset(ageData,sex=="Female" & Nfp> 0)[,"fise"]^2
mod = lm(log(Nfp)~age,subset(ageData,Nfp>0 & sex=="Female"),weights=weights)
pr=predict(mod,data.frame(age=testage),se.fit=T)
NfpmodelF[,"Nfp"] = exp(pr[[1]])
NfpmodelF[,"Nfpse"] = exp(pr[[1]])*pr[[2]]

NfpmodelM[,"sex"] = "Male"
NfpmodelF[,"sex"] = "Female"
nfpData = rbind(NfpmodelM,NfpmodelF)



g[[2]] = ggplot(ageData,aes(x=age,xmin=age-agese,xmax=age+agese,y=Nfp,ymin=Nfp-Nfpse,ymax=Nfp+Nfpse,colour=sex,fill=sex,shape=dataset))+
  geom_point(size=3)+
  geom_errorbar(size=1,width=0)+
  geom_errorbarh(size=1,height=0)+
  #geom_smooth(data=ageData,aes(x=age,y=Nfp,fill=sex,colour=sex),inherit.aes=F)+
  geom_line(data=nfpData,aes(x=age,y=Nfp,colour=sex,linetype=sex),inherit.aes=F)+
  geom_ribbon(data=nfpData,aes(x=age,ymin=Nfp-Nfpse,ymax=Nfp+Nfpse,fill=sex),inherit.aes=F,alpha=.15,colour=NA)+
  labs(y=gFab5Name,x="Age")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
        legend.background = element_rect(fill="white",colour=NA),
          legend.position="none", #c(.2,.8),
          legend.key.size = unit(2,"line"),
          legend.text=element_text(size=gTextSize*.9),
          legend.title=element_blank()
        )


marrangeGrob(g,nrow=1,ncol=2,top=NULL)
```

```{r}
save=T
if(save)
{
    
  g[[1]] = g[[1]]+ggtitle("(a) FI")
  g[[2]] = g[[2]]+ggtitle(sprintf("(b) %s",gFab5Name))
  
  ggsave(sprintf("%s/results/age_dependence_fi.pdf",outputDir),g[[1]],width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_dependence_fi.png",outputDir),g[[1]],width=10,height=8,dpi=300)
  
  
  ggsave(sprintf("%s/results/age_dependence_nfp.pdf",outputDir),g[[2]],width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_dependence_nfp.png",outputDir),g[[2]],width=10,height=8,dpi=300)
  
  g[[1]] = g[[1]]+ggtitle("(a) FI")
  g[[2]] = g[[2]]+ggtitle(sprintf("(b) %s",gFab5Name))
  
  ggsave(sprintf("%s/results/age_dependence.pdf",outputDir),marrangeGrob(g,nrow=1,ncol=2,top=NULL),width=16,height=7,dpi=300)
  ggsave(sprintf("%s/results/age_dependence.png",outputDir),marrangeGrob(g,nrow=1,ncol=2,top=NULL),width=16,height=7,dpi=300)
  
}
```

################
# prevalence curves
################

```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - spline
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    b = predict(bMat,data[[ii]][,"fi"])
    temp = data.frame(b)
    colnames(temp) = colnames(bMat)
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~.,data=temp,family=binomial)
    pr = predict(md,testMat,se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]

  plotdata = list(pr_agg,pr_agg_sq)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=names(outcomes)[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/%s_prevalence_hrs_logit_pragg.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/%s_prevalence_hrs_logit_pragg_sq.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(agg,sprintf("%s/data/%s_prevalence_hrs_logit_agg.csv",outputDir,names(outcomes)[i]),row.names=F)
  }
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)


save=T
if(save)
{
  ggsave(sprintf("%s/results/prevalence_hrs.pdf",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/prevalence_hrs.png",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  

}
```

```{r}
library(splines2)
include="linear"
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.05),1)
fi_labs = levels(cut(seq(-1,1,by=.01),fi_cuts))
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
nms = names(fpNames)
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  pr_agg[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~fi,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_aggF = RubinMat(l,lse)
  pr_aggF[[1]] = data.frame(pr_aggF[[1]])
  pr_aggF[[1]][,sprintf("%sse",colnames(pr_aggF[[2]]))] = pr_aggF[[2]]
  pr_aggF = pr_aggF[[1]]
  pr_aggF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  pr_agg_sq[,"sex"] = "Male"
  rm(l)
  rm(lse)
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"y"]  = data[[ii]][logi,outcomes[i]]
    
    md = glm(y~sqrt(fi),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sqF = RubinMat(l,lse)
  pr_agg_sqF[[1]] = data.frame(pr_agg_sqF[[1]])
  pr_agg_sqF[[1]][,sprintf("%sse",colnames(pr_agg_sqF[[2]]))] = pr_agg_sqF[[2]]
  pr_agg_sqF = pr_agg_sqF[[1]]
  pr_agg_sqF[,"sex"] = "Female"
  rm(l)
  rm(lse)
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 0
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    agg = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(agg[,"fi_cut"]),] = agg[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(agg)
    rm(aggse)
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]
  agg[,"sex"] = "Male"

  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    logi = data[[ii]][,"sex"] == 1
    temp = data[[ii]][logi,]
    temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
    df = data.frame(fi=rep(NA,length(fi_labs)))
    df[,outcomes[i]] = NA
    rownames(df) = fi_labs
    aggtemp = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)
    df[as.character(aggtemp[,"fi_cut"]),] = aggtemp[,c("fi",outcomes[i])]
    l[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    aggse = aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)
    df[as.character(aggse[,"fi_cut"]),] = aggse[,c("fi",outcomes[i])]
    lse[[ii]] = as.matrix(df[,c("fi",outcomes[i])])
    rm(aggtemp)
    rm(aggse)
  }
  aggF = RubinMat(l,lse)
  for (j in 1:length(aggF)) colnames(aggF[[j]])[2] = "pr"
  aggF[[1]] = data.frame(aggF[[1]])
  aggF[[1]][,sprintf("%sse",colnames(aggF[[2]]))] = aggF[[2]]
  aggF = aggF[[1]]
  aggF[,"sex"] = "Female"
  
  plotdata = list(pr_agg,pr_aggF,pr_agg_sq,pr_agg_sqF)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]][,"model"] = "sqrt"
  plotdata[[4]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%include)
  plotdata[,"sex"] = factor(plotdata[,"sex"],c("Female","Male"))
  
  agg = rbind(agg,aggF)
  
  #frequencies
  if(length(include)>1) 
  {
    g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))
  }   else g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,fill=sex,colour=sex,linetype=sex,shape=sex))
  g[[i]] = g[[i]] + geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=sex,shape=sex),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,colour=sex,shape=sex),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=sprintf("(%s) %s",letters[i], nms[i]))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
  
}

#clean up legends
g[[1]] = g[[1]] + theme(legend.position=c(.25,.8),legend.title=element_blank())
for (i in 2:length(g)) g[[i]] = g[[i]] + theme(legend.position="none")

layout = matrix(1:6,nrow=2,ncol=3)
for (i in 1:nrow(layout)) layout[i,] = 1:ncol(layout)+(i-1)*ncol(layout)
marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout)




save=T
if(save)
{
  ggsave(sprintf("%s/results/prevalence_hrs_sex.pdf",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/prevalence_hrs_sex.png",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  

}
```


Combine all 2 longitudinal datasets
```{r}
library(splines2)
files = c("hrs","elsa")
include = c("linear","sqrt")
#include = c("sqrt") #sqrt
#include = "linear"
scale=F #scale prevalence assuming exponential (by dt)
outcomes = fpNames
plotnames = names(fpNames)
plotnames[plotnames=="FP"] = "FP frailty"
ylim = list()
for (i in 1:length(outcomes)) ylim[[outcomes[i]]] = c(0,1)
ylim[["fp1_weight_next"]] = c(0,.5)
g = list()
for (i in 1:length(outcomes))
{


  pr_agg = list()
  pr_agg_sq = list()
  agg = list()
  for (ii in 1:length(files))
  {
    pr_agg[[ii]] = read.csv(sprintf("%s/data/%s_prevalence_%s_logit_pragg.csv",outputDir,names(outcomes)[i],files[ii]))
    pr_agg_sq[[ii]] = read.csv(sprintf("%s/data/%s_prevalence_%s_logit_pragg_sq.csv",outputDir,names(outcomes)[i],files[ii]))
    agg[[ii]] = read.csv(sprintf("%s/data/%s_prevalence_%s_logit_agg.csv",outputDir,names(outcomes)[i],files[ii]))
    pr_agg[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sq[[ii]][,"dataset"] = toupper(files[ii])
    agg[[ii]][,"dataset"] = toupper(files[ii])
  }
  agg = do.call(rbind,agg)
  pr_agg = do.call(rbind,pr_agg)
  pr_agg_sq = do.call(rbind,pr_agg_sq)

  plotdata = list(pr_agg_sq)
  plotdata[[1]][,"model"] = "sqrt"
  plotdata[[2]] = pr_agg
  plotdata[[2]][,"model"] = "linear"
  plotdata = do.call(rbind,plotdata)
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  plotdata[,"prlowse"] = plotdata[,"pr"]-plotdata[,"prse"]
  plotdata[,"prhighse"] = plotdata[,"pr"]+plotdata[,"prse"]
  agg[,"prlowse"] = agg[,"pr"]-agg[,"prse"]
  agg[,"prhighse"] = agg[,"pr"]+agg[,"prse"]
  
  if(scale)
  {
    plotdata[,"pr"] = 1-exp(log(1-plotdata[,"pr"])/plotdata[,"dt"])
    plotdata[,"prlowse"] = 1-exp(log(1-plotdata[,"prlowse"])/plotdata[,"dt"])
    plotdata[,"prhighse"] = 1-exp(log(1-plotdata[,"prhighse"])/plotdata[,"dt"])
    
    agg[,"pr"] = 1-exp(log(1-agg[,"pr"])/agg[,"dt"])
    agg[,"prlowse"] = 1-exp(log(1-agg[,"prlowse"])/agg[,"dt"])
    agg[,"prhighse"] = 1-exp(log(1-agg[,"prhighse"])/agg[,"dt"])
  }
  
  agg[agg[,"prhighse"] > ylim[[i]][2],"prhighse"] = ylim[[i]][2]
  
  #drop 0 zero points, 0 sd means probably no data
  agg = subset(agg,prse > 0)
  
  #frequencies
  if(length(include)>1) 
  {
    g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=model))
  } else 
  {
    g[[i]] = ggplot(plotdata,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=dataset))
  }
  g[[i]] = g[[i]]+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,shape=dataset,colour=dataset),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,colour=dataset),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=sprintf("(%s) %s",letters[i], plotnames[i]))+
    scale_y_continuous(limits=ylim[[i]])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
}

#clean up legends
  #drop them all - use labels instead
cols = gg_color_hue(2)[1:2]
g[[1]] = g[[1]] + theme(legend.position=c(.2,.7),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")
for (i in 1:length(g))
{
  #g[[i]] = g[[i]] + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
  #g[[i]] = g[[i]] + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
  if(length(include)>1) g[[i]] = g[[i]] + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
}
for (i in 2:length(g)) g[[i]] = g[[i]]+theme(legend.position="none")

#labels
#library(ggrepel)
if(length(include)>1) for (i in 1:length(g)) g[[i]] = g[[i]] + labs(x=bquote("FI,"~f),y=bquote("Prevalence,"~p))


layout = matrix(1:6,nrow=2,ncol=3)
for (i in 1:nrow(layout)) layout[i,] = 1:ncol(layout)+(i-1)*ncol(layout)
marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout)


save=T
if(save)
{
  nm = "prevalence"
  if(scale) nm = "prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  ggsave(sprintf("%s/results/%s.pdf",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s.png",outputDir,nm),marrangeGrob(g,nrow=2,ncol=3,top=NULL,layout_matrix = layout),width=16,height=8,dpi=300)
  

}
```


################
# prevalence w.r.t age
################

```{r}
library(splines2)
testage = seq(60,100,by=1)

age_cuts = c(seq(60,100,by=5))
#outcomes = unique(sp[["importance"]][,"Outcome"])
outcomes = fpNames
g = list()
for (i in 1:length(outcomes))
{
  #glm - linear
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~age,data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,age=testage),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(age=testage,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=pr[["se.fit"]]))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"y"]  = data[[ii]][,outcomes[i]]
    
    md = glm(y~sqrt(age),data=temp,family=binomial)
    pr = predict(md,data.frame(y=NA,age=testage),se.fit=T,type="response")
    l[[ii]] = as.matrix(data.frame(age=testage,pr=pr[["fit"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=pr[["se.fit"]]))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  


  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
  l = list()
  lse = list()
  for(ii in 1:length(data))
  {
    temp = data[[ii]]
    temp[,"age_cut"] = cut(temp[,"age"],age_cuts,include.lowest=T)
    l[[ii]] = as.matrix(aggregate(temp[,c("age",outcomes[i])],by=list(age_cut=temp[,"age_cut"]),mean,na.rm=T)[,c("age",outcomes[i])])
    lse[[ii]] = as.matrix(aggregate(temp[,c("age",outcomes[i])],by=list(age_cut=temp[,"age_cut"]),SEM,na.rm=T)[,c("age",outcomes[i])])
  }
  agg = RubinMat(l,lse)
  for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
  agg = agg[[1]]

  plotdata = list(pr_agg,pr_agg_sq)#,pr_agg_sp) #spline is just overfitting
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  #plotdata[[3]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g[[i]] = ggplot(plotdata,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Prevalence"),title=names(outcomes)[i])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/%s_age_prevalence_hrs_logit_pragg.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/%s_age_prevalence_hrs_logit_pragg_sq.csv",outputDir,names(outcomes)[i]),row.names=F)
    write.csv(agg,sprintf("%s/data/%s_age_prevalence_hrs_logit_agg.csv",outputDir,names(outcomes)[i]),row.names=F)
  }
}

marrangeGrob(g,nrow=2,ncol=3,top=NULL)


save=T
if(save)
{
  ggsave(sprintf("%s/results/age_prevalence_hrs.pdf",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_prevalence_hrs.png",outputDir),marrangeGrob(g,nrow=2,ncol=3,top=NULL),width=16,height=8,dpi=300)
  

}
```


Combine all 2 longitudinal datasets
```{r}
library(splines2)
files = c("hrs","elsa")
include = c("sqrt")
scale=F #scale prevalence assuming exponential (by dt)
outcomes = fpNames
ylim = list()
for (i in 1:length(outcomes)) ylim[[outcomes[i]]] = c(0,1)*NA
ylim[["fp1_weight_next"]] = c(0,.35)
g = list()
for (i in 1:length(outcomes))
{


  pr_agg = list()
  pr_agg_sq = list()
  agg = list()
  for (ii in 1:length(files))
  {
    pr_agg[[ii]] = read.csv(sprintf("%s/data/%s_age_prevalence_%s_logit_pragg.csv",outputDir,names(outcomes)[i],files[ii]))
    pr_agg_sq[[ii]] = read.csv(sprintf("%s/data/%s_age_prevalence_%s_logit_pragg_sq.csv",outputDir,names(outcomes)[i],files[ii]))
    agg[[ii]] = read.csv(sprintf("%s/data/%s_age_prevalence_%s_logit_agg.csv",outputDir,names(outcomes)[i],files[ii]))
    pr_agg[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sq[[ii]][,"dataset"] = toupper(files[ii])
    agg[[ii]][,"dataset"] = toupper(files[ii])
  }
  agg = do.call(rbind,agg)
  pr_agg = do.call(rbind,pr_agg)
  pr_agg_sq = do.call(rbind,pr_agg_sq)

  plotdata = list(pr_agg_sq)
  plotdata[[1]][,"model"] = "sqrt"
  plotdata[[2]] = pr_agg
  plotdata[[2]][,"model"] = "linear"
  plotdata = do.call(rbind,plotdata)
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  plotdata[,"prlowse"] = plotdata[,"pr"]-plotdata[,"prse"]
  plotdata[,"prhighse"] = plotdata[,"pr"]+plotdata[,"prse"]
  agg[,"prlowse"] = agg[,"pr"]-agg[,"prse"]
  agg[,"prhighse"] = agg[,"pr"]+agg[,"prse"]
  
  if(scale)
  {
    plotdata[,"pr"] = 1-exp(log(1-plotdata[,"pr"])/plotdata[,"dt"])
    plotdata[,"prlowse"] = 1-exp(log(1-plotdata[,"prlowse"])/plotdata[,"dt"])
    plotdata[,"prhighse"] = 1-exp(log(1-plotdata[,"prhighse"])/plotdata[,"dt"])
    
    agg[,"pr"] = 1-exp(log(1-agg[,"pr"])/agg[,"dt"])
    agg[,"prlowse"] = 1-exp(log(1-agg[,"prlowse"])/agg[,"dt"])
    agg[,"prhighse"] = 1-exp(log(1-agg[,"prhighse"])/agg[,"dt"])
  }
  
  if(!all(is.na(ylim[[i]]))) agg[agg[,"prhighse"] > ylim[[i]][2],"prhighse"] = ylim[[i]][2]
  
  #drop 0 zero points, 0 sd means probably no data
  agg = subset(agg,prse > 0)
  
  #frequencies
  if(length(include)>1) 
  {
    g[[i]] = ggplot(plotdata,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=model))
  } else 
  {
    g[[i]] = ggplot(plotdata,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=dataset))
  }
  g[[i]] = g[[i]]+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,shape=dataset,colour=dataset),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr,colour=dataset),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Prevalence"),title=names(outcomes)[i])+
    scale_y_continuous(limits=ylim[[i]])+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize*.8)
          )
}

#clean up legends
  #drop them all - use labels instead
cols = gg_color_hue(2)[1:2]
g[[1]] = g[[1]] + theme(legend.position=c(.2,.7),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")
for (i in 1:length(g))
{
  #g[[i]] = g[[i]] + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*a),bquote(logit(p)*"~"*sqrt(a))))
  #g[[i]] = g[[i]] + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*a),bquote(logit(p)*"~"*sqrt(a))))
  if(length(include)>1) g[[i]] = g[[i]] + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*a),bquote(logit(p)*"~"*sqrt(a))))
}
for (i in 2:length(g)) g[[i]] = g[[i]]+theme(legend.position="none")

#labels
#library(ggrepel)
if(length(include)>1) for (i in 1:length(g)) g[[i]] = g[[i]] + labs(x=bquote("Age,"~a),y=bquote("Prevalence,"~p))



marrangeGrob(g,nrow=2,ncol=3,top=NULL)


save=T
if(save)
{
  nm = "age_prevalence"
  if(scale) nm =  sprintf("%s_scaled",nm)
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  ggsave(sprintf("%s/results/%s.pdf",outputDir,nm),marrangeGrob(g,nrow=nrow(layout),ncol=ncol(layout),top=NULL,layout_matrix=layout),width=16,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s.png",outputDir,nm),marrangeGrob(g,nrow=nrow(layout),ncol=ncol(layout),top=NULL,layout_matrix=layout),width=16,height=8,dpi=300)
  

}
```


################
# survival (hazard) curve
################

```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.1),1)
#fi_cuts = c(0,seq(0.01,.6,by=.1),1) #bad idea... very low FI have basically 0 risk


#coxph linear
l = list()
lse = list()
for(ii in 1:length(stst))
{
  md = coxph(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]])
  pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg = RubinMat(l,lse)
pr_agg[[1]] = data.frame(pr_agg[[1]])
pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
pr_agg = pr_agg[[1]]
rm(l)
rm(lse)
  
  
#glm - sqrt
l = list()
lse = list()
for(ii in 1:length(stst))
{
  md = coxph(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]])
  pr = predict(md,data.frame(y=NA,fi=testfi),se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg_sq = RubinMat(l,lse)
pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
pr_agg_sq = pr_agg_sq[[1]]
rm(l)
rm(lse)


#glm - spline
l = list()
lse = list()
for(ii in 1:length(stst))
{
  b = predict(bMat,stst[[ii]][[1]][,"fi"])
  temp = data.frame(b)
  colnames(temp) = colnames(bMat)
  
  md = coxph(stst[[ii]][["s"]]~.,data=temp)
  pr = predict(md,testMat,se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["se.fit"]]))
}
pr_agg_sp = RubinMat(l,lse)
pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
pr_agg_sp = pr_agg_sp[[1]]
rm(l)
rm(lse)

#population stats
#still has to use coxph because of censorship
l = list()
lse = list()
for(ii in 1:length(stst))
{
  temp = stst[[ii]][[1]]
  temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
  
  md = coxph(stst[[ii]][["s"]]~fi_cut,data=temp)
  
  test = data.frame(y=NA,fi=testfi)
  test[,"fi_cut"] = cut(test[,"fi"],fi_cuts,include.lowest=T)
  test = aggregate(test[,c("y","fi")],by=list(fi_cut=test[,"fi_cut"]),mean,na.rm=T) #compress down into 1 / unique value
  test[,"fise"] = aggregate(test[,c("fi"),drop=F],by=list(fi_cut=test[,"fi_cut"]),SEM,na.rm=T)[,"fi"]
  pr = predict(md,test,se.fit=T,type="risk")
  l[[ii]] = as.matrix(data.frame(fi=test[,"fi"],pr=pr[["fit"]]))
  lse[[ii]] = as.matrix(data.frame(fi=test[,"fise"],pr=pr[["se.fit"]]))
  
  #l[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),mean,na.rm=T)[,c("fi",outcomes[i])])
  #lse[[ii]] = as.matrix(aggregate(temp[,c("fi",outcomes[i])],by=list(fi_cut=temp[,"fi_cut"]),SEM,na.rm=T)[,c("fi",outcomes[i])])
}
agg = RubinMat(l,lse)
for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
agg[[1]] = data.frame(agg[[1]])
agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
agg = agg[[1]]

plotdata = list(pr_agg,pr_agg_sq,pr_agg_sp) #spline is just overfitting
plotdata[[1]][,"model"] = "linear"
plotdata[[2]][,"model"] = "sqrt"
plotdata[[3]][,"model"] = "spline"
plotdata = do.call(rbind,plotdata)


g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="HRS")+
  #scale_y_log10()+
  #annotation_logticks(sides="l")+
  theme_minimal()+
  theme()


g

save=T
if(save)
{
  ggsave(sprintf("%s/results/hazard_hrs_coxph.pdf",outputDir),g,width=9,height=8,dpi=300)
  ggsave(sprintf("%s/results/hazard_hrs_coxph.png",outputDir),g,width=9,height=8,dpi=300)
}
```





Parametric survival
add a bit more flexibility (Sr looks bad, so maybe this will help)
```{r}
library(eha)
mg = phreg(stst[[1]][[2]][stst[[1]][[2]][,"start"] >= 60,]~1,dist = "gompertz",param="rate")

```

```{r}
plot(stst[[1]][[2]][stst[[1]][[2]][,"start"] >= 60,],xlim=c(60,100),ylim=c(0,1))
s0 = exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*60))/coef(mg)["rate"]) #looks a little better #we know they survived to 60
#s0 = 1 # looks very similar
curve(exp(exp(coef(mg)["log(level)"])*(1-exp(coef(mg)["rate"]*x))/coef(mg)["rate"])/s0,add=T,col=2) #using eha fit
curve(exp(-Hgompertz(x,rate=coef(mg)["rate"],shape=exp(coef(mg)["log(level)"]),param="rate"))/s0,col=3,lty=3,add=T)
```

```{r}
mgr = phreg(stst[[1]][[2]]~1,dist = "gompertz",param="rate")
mgc = phreg(stst[[1]][[2]]~1,dist = "gompertz",param="canonical")
plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(0,1))
curve(exp(-Hgompertz(x,rate=coef(mgr)["rate"],shape=exp(coef(mgr)["log(level)"]),param="rate")),col=2,lty=1,add=T)
curve(exp(-Hgompertz(x,scale=exp(coef(mgc)["log(scale)"]),shape=exp(coef(mgc)["log(shape)"]),param="canonical")),col=3,lty=3,add=T)

curve(hgompertz(x,rate=coef(mgr)["rate"],shape=exp(coef(mgr)["log(level)"]),param="rate"),col=2,lty=1,add=F)
curve(hgompertz(x,scale=exp(coef(mgc)["log(scale)"]),shape=exp(coef(mgc)["log(shape)"]),param="canonical"),col=3,lty=3,add=T)
```
to get confidence intervals...
```{r}
library(MASS)
PHConfInt = function(ttest = seq(60,100,by=.1),
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    x=NULL, #named vector
                    t0=0
                    )
{

  
  errorsFailed=F
  if(grepl("error",tolower(class(fit[["var"]])[1]))) #fit failed
  {
    warning("Fit failed")
    errorsFailed=T
    Sigma = diag(1,length(coef(fit)))
  }
  else Sigma = fit[["var"]]
  
  fits = matrix(NA,nrow=N,ncol=length(ttest))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=Sigma)
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[names(x)]
      fits[i,] = exp(sum(beta*x))*Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
  
  if(errorsFailed)
  {
    Hsd = Hsd*NA
    Hmin = Hmin*NA
    Hmax = Hmax*NA
    Smin = Smin*NA
    Smax = Smax*NA
  }
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,t=ttest,x=x,t0=t0))
}

PHConfInt2VecX = function(x, #vector of values
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    t0=0
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hgompertz(t0,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
    
    if(is.null(x)) fits[i,] = Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    else 
    {
      beta = par[1]
      fits[i,] = exp(beta*x)*Hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate") - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,x=x,ttest=ttest,t0=t0))
}

PHConfInt2VecX.weibull = function(x, #vector of values
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    t0=0
                    )
{

  fits = matrix(NA,nrow=N,ncol=length(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(t0)) H0 = 0
    else H0 = Hweibull(t0,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]))
    
    if(is.null(x)) fits[i,] = Hweibull(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"])) - H0
    else 
    {
      beta = par[1]
      fits[i,] = exp(beta*x)*Hweibull(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"])) - H0
    }
  }
  H = apply(fits,2,mean,na.rm=T)
  Hsd = apply(fits,2,sd,na.rm=T)
  Hmin = H-errorScale*Hsd
  Hmax = H+errorScale*Hsd
  S = exp(-H)
  Smin = exp(-Hmax)
  Smax = exp(-Hmin)
    
  return(list(H=H,Hsd=Hsd,Hmin=Hmin,Hmax=Hmax,S=S,Smin=Smin,Smax=Smax,fit=fit,N=N,x=x,ttest=ttest,t0=t0))
}

PHConfInt.hazard = function(x, #matrix or data.frame of covariates
                    N = 1000,
                    fit,
                    errorScale=qnorm(.975),
                    ttest = 70,
                    param="rate" #phreg lets you fit differently
                    )
{
  x = as.matrix(x)
  param  = tolower(param)

  fits = matrix(NA,nrow=N,ncol=nrow(x))
  for (i in 1:N)
  {
    par = mvrnorm(1,mu=coef(fit),Sigma=fit[["var"]])
    
    if(is.null(x)) 
    {
      if(param=="rate") fits[i,] = hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
    else 
    {
      #print(par)
      #print(colnames(x))
      beta = par[colnames(x)]
      #print(beta)
      #print(head(x%*%beta))
      #fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      if(param=="rate") fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,rate=par["rate"],shape=exp(par["log(level)"]),param="rate")
      else  fits[i,] = exp((x%*%beta)[,1])*hgompertz(ttest,scale=exp(par["log(scale)"]),shape=exp(par["log(shape)"]),param=param)
    }
  }
  h = apply(fits,2,mean,na.rm=T)
  hsd = apply(fits,2,sd,na.rm=T)
  hmin = h-errorScale*hsd
  hmax = h+errorScale*hsd

    
  return(list(h=h,hsd=hsd,hmin=hmin,hmax=hmax,fit=fit,N=N,x=x,ttest=ttest,t0=t0,param=param))
}

t = PHConfInt(fit=mg)

plot(stst[[1]][[2]],xlim=c(60,100),ylim=c(0,1))
lines(t[["t"]],t[["S"]],col=2)
lines(t[["t"]],t[["Smin"]],col=2,lty=2)
lines(t[["t"]],t[["Smax"]],col=2,lty=2)
```

```{r}
GompertzHazard = function(t,fit)
{
  #survival:
  #plot(s)
  #curve(exp(baselineHazard*exp(beta*x)*(1-exp(alpha*t))/alpha)/s0,add=T,col=2)
  h = exp(coef(fit)["log(level)"])*exp(coef(fit)["rate"]*t)*exp(coef(fit)["rate"])
  return(h)
    
}
```

eha looks better even though it's a pain to use
```{r}
library(eha)
fit = phreg(stst[[1]][[2]]~fi,data=stst[[1]][[1]],dist = "gompertz",param="rate")

```

```{r}
library(scico)
st = stst[[1]][[1]]
sst = stst[[1]][[2]]
conf.int = pnorm(1)-pnorm(-1)
#conf.int = .95
#cuts = c(-Inf,-2:1+.5,Inf)
#zq = cut(st[,"z01"],cuts)
probs = seq(0,1,length=3)
cuts = quantile(st[,"fi"],probs=probs)

zq = cut(st[,"fi"],cuts,labels = sprintf("%.0f%%",round(probs[-1]*100)))
cols = scico(length(levels(zq)), palette = 'roma')
t = seq(60,100,by=1)
fitdata = list()
for (j in 1:length(levels(zq)))
{
  muzq = mean(st[zq==levels(zq)[j],"fi"],na.rm=T)
  H = PHConfInt(ttest=t,N=1000,fit=fit,errorScale=qnorm(.975),x=c(fi=muzq),t0=0)
  
  fitdata[[j]] = data.frame(strata=levels(zq)[j],
                            #t=t,
                            t=H[["t"]],
                            #H=exp(coef(fit)[1]*muzq)*Hgompertz(t,rate=coef(fit)["rate"],shape=exp(coef(fit)["log(level)"]),param="rate")
                            H=H[["H"]],
                            Hmin=H[["Hmin"]],
                            Hmax=H[["Hmax"]],
                            dH=H[["Hsd"]]
                  )
}
fitdata=do.call(rbind,fitdata)
#fitdata[,"dH"] = 0
fitdata[,"S"] = exp(-fitdata[,"H"])
#fitdata[,"dS"] = 0
fitdata[,"Smin"] = exp(-fitdata[,"Hmin"])
fitdata[,"Smax"] = exp(-fitdata[,"Hmax"])
fitdata[,"strata"]= factor(fitdata[,"strata"],levels(zq))

sf = survfit(sst ~ z,data=data.frame(z=zq),conf.int=conf.int)
group = rep("unknown",length(sf$cumhaz))
ind = 0
for (j in 1:length(sf$strata))
{
  group[1:sf$strata[j]+ind] = gsub("z=","",names(sf$strata)[j])
  ind = ind + sf$strata[j]
}
group = factor(group,levels(zq))
  
#survival
logi = !is.na(sf$upper) & !is.na(sf$lower)
g = ggplot(data.frame(t=sf$time,S=sf$surv,Smin=sf$lower,Smax=sf$upper,strata=group)[logi,],
       aes(x=t,y=S,ymin=Smin,ymax=Smax,colour=strata,fill=strata))+
  geom_line(lty=2)+
  geom_ribbon(alpha=.5,colour=NA)+
  #scale_colour_manual(breaks=levels(group),values=cols)+
  #scale_fill_manual(breaks=levels(group),values=cols)+
  #scale_colour_discrete_diverging("Blue-Red")+
  #scale_fill_discrete_diverging("Blue-Red")+
  scico::scale_color_scico_d(palette="roma")+
  scico::scale_fill_scico_d(palette="roma")+
  labs(y="Survival",x="Years on dialysis",colour="Percentile",fill="Percentile",linetype="")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
          axis.text.x = element_text(size=gAxisTextSize,angle=90,vjust=.5),
          axis.text.y=element_text(size=gAxisTextSize), #hjust=0 left aligns text
          axis.title.x = element_text(size=gTextSize),
          axis.title.y = element_text(size=gTextSize),
          legend.position= "right", #c(.6,.3), #
          legend.key.size = unit(4,"line"),
          legend.text=element_text(size=gTextSize*.9)#,
          #legend.title=element_blank()
        )


g = g + geom_line(data=fitdata,lwd=1,inherit.aes=F,mapping=aes(x=t,y=S,colour=strata,linetype="Fit"))
g = g + geom_ribbon(data=fitdata,colour=NA,alpha=.15)

g = g + scale_x_continuous(limits=c(60,100))
g = g + scale_y_continuous(limits=c(NA,1))

g


save = T
if(save)
{
  ggsave(sprintf("%s/results/survival_diagnostic_fi_hrs.pdf",outputDir),
           g,width=8,height=6,dpi=300)
  ggsave(sprintf("%s/results/survival_diagnostic_fi_hrs.png",outputDir),
           g,width=8,height=6,dpi=300)
}

```

```{r}
library(splines2)
ttest = 60
t0 = 0
testfi = seq(0,.75,by=.01)
#might have to set specific knots, because there's *knot* enough info for high FI and it just blows up
#bMat = bSpline(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
#bMat = splines2::ibs(seq(0,1,by=.01), df = 4, Boundary.knots = c(0, 1),
#                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)
fi_cuts = c(seq(0,.6,by=.1),1)
#fi_cuts = c(0,seq(0.01,.6,by=.1),1) #bad idea... very low FI have basically 0 risk


#linear
l = list()
lse = list()
param = list()
paramse = list()
paramsemat = list()
for(ii in 1:length(stst))
{
  #md = phreg(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]],dist = "gompertz",param="rate")
  md = phreg(stst[[ii]][["s"]]~fi,data=stst[[ii]][[1]],dist = "gompertz",param="canonical") #very similar

  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=data.frame(fi=testfi),param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
  
  param[[ii]] = matrix(coef(md),nrow=1,ncol=length(coef(md)))
  colnames(param[[ii]]) = names(coef(md))
  paramse[[ii]] = matrix(diag(md[["var"]]),nrow=1,ncol=length(coef(md)))
  colnames(paramse[[ii]]) = names(coef(md))
  paramsemat[[ii]] = as.matrix(md[["var"]])
}
pr_agg = RubinMat(l,lse)
pr_agg[[1]] = data.frame(pr_agg[[1]])
pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
pr_agg = pr_agg[[1]]
rm(l)
rm(lse)
  
param = RubinMat(param,paramse,checkAlignment = F)
paramsemat = RubinMat(paramsemat)
  
#gompertz - sqrt
l = list()
lse = list()
for(ii in 1:length(stst))
{
  #md = phreg(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]],dist = "gompertz",param="rate") #fails
  md = phreg(stst[[ii]][["s"]]~sqrt(fi),data=stst[[ii]][[1]],dist = "gompertz",param="canonical") #probably wrong

  test = data.frame(testfi)
  colnames(test) = "sqrt(fi)"
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=test,param=md[["param"]])
  l[[ii]] = as.matrix(data.frame(fi=testfi,pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
}
pr_agg_sq = RubinMat(l,lse)
pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
pr_agg_sq = pr_agg_sq[[1]]
rm(l)
rm(lse)



#population stats
#still has to use coxph because of censorship
l = list()
lse = list()
for(ii in 1:length(stst))
{
  temp = stst[[ii]][[1]]
  temp[,"fi_cut"] = cut(temp[,"fi"],fi_cuts,include.lowest=T)
  
  #md = phreg(stst[[ii]][["s"]]~fi_cut,data=temp,dist = "gompertz",param="rate")
  md = phreg(stst[[ii]][["s"]]~fi_cut,data=temp,dist = "gompertz",param="canonical") #very similar
    
  test = data.frame(y=NA,fi=testfi)
  test[,"fi_cut"] = cut(test[,"fi"],fi_cuts,include.lowest=T)
  test = aggregate(test[,c("y","fi")],by=list(fi_cut=test[,"fi_cut"]),mean,na.rm=T) #compress down into 1 / unique value
  test[,"fise"] = aggregate(test[,c("fi"),drop=F],by=list(fi_cut=test[,"fi_cut"]),SEM,na.rm=T)[,"fi"]
  #one-hot:
  beta = coef(md)[!(names(coef(md))%in%c("rate","log(level)","log(scale)","log(shape)"))]
  onehot = matrix(0,nrow=nrow(test),ncol=length(beta))
  nms = character()
  for (jj in 1:length(beta)) nms[jj] = strsplit(names(beta)[jj],"fi_cut")[[1]][2]
  for (jj in 1:nrow(test)) 
  {
      onehot[jj,] = as.integer(nms == test[jj,"fi_cut"])
  }
    
  colnames(onehot) = names(beta)

  
  pr = PHConfInt.hazard(ttest=ttest,N = 1000,fit=md,x=onehot,param=md[["param"]])

  l[[ii]] = as.matrix(data.frame(fi=test[,"fi"],pr=pr[["h"]]))
  lse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[["hsd"]]))
}
agg = RubinMat(l,lse)
for (j in 1:length(agg)) colnames(agg[[j]])[2] = "pr"
agg[[1]] = data.frame(agg[[1]])
agg[[1]][,sprintf("%sse",colnames(agg[[2]]))] = agg[[2]]
agg = agg[[1]]

plotdata = list(pr_agg,pr_agg_sq) #spline is just overfitting #
plotdata[[1]][,"model"] = "linear"
plotdata[[2]][,"model"] = "sqrt"

plotdata = do.call(rbind,plotdata)


g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="HRS")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()


g = ggplot(pr_agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse))+
  geom_line()+
  geom_ribbon(alpha=.15,colour=NA)+
  geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
  geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
  labs(x="FI",y=bquote("Hazard"),title="HRS")+
  scale_y_log10()+
  annotation_logticks(sides="l")+
  theme_minimal()+
  theme()

g

save=T
if(save)
{
  ggsave(sprintf("%s/results/hazard_hrs_gompertz.pdf",outputDir),g,width=9,height=8,dpi=300)
  ggsave(sprintf("%s/results/hazard_hrs_gompertz.png",outputDir),g,width=9,height=8,dpi=300)
  
  #table of coefficients
  #tb = data.frame(beta=sprintf("%.3f pm %.3f",param[[1]][1,"fi"],param[[2]][1,"fi"]),
  #                alpha=sprintf("%.3f pm %.3f",param[[1]][1,"rate"],param[[2]][1,"rate"]),
  #                lnh0=sprintf("%.3f pm %.3f",param[[1]][1,"log(level)"],param[[2]][1,"log(level)"]),
  #                h0=sprintf("%.3f pm %.3f",exp(param[[1]][1,"log(level)"]),exp(param[[1]][1,"log(level)"])*param[[2]][1,"log(level)"])
  #                )
  #  write.csv(tb,sprintf("%s/results/hazard_hrs_gompertz.csv",outputDir))
  write.csv(param[[1]],sprintf("%s/results/hazard_hrs_gompertz_errors.csv",outputDir))
  write.csv(param[[2]],sprintf("%s/results/hazard_hrs_gompertz_errors.csv",outputDir))
  write.csv(paramsemat,sprintf("%s/results/hazard_hrs_gompertz_errors.csv",outputDir))
  #print("fit parameters:")
  #print(tb)
  
  #will load these in elsewhere to compare to HRS 
  write.csv(pr_agg,sprintf("%s/results/hazard_hrs_gompertz_pragg.csv",outputDir),row.names=F)
  write.csv(agg,sprintf("%s/results/hazard_hrs_gompertz_agg.csv",outputDir),row.names=F)
}


```

Combine all 3 datasets
```{r}
files = c("hrs","nhanes","elsa")
pr_agg = list()
agg = list()
for (i in 1:length(files))
{
  pr_agg[[i]] = read.csv(sprintf("%s/results/hazard_%s_gompertz_pragg.csv",outputDir,files[i]))
  agg[[i]] = read.csv(sprintf("%s/results/hazard_%s_gompertz_pragg.csv",outputDir,files[i]))
  pr_agg[[i]][,"dataset"] = files[i]
  agg[[i]][,"dataset"] = files[i]  
}
agg = do.call(rbind,agg)
pr_agg = do.call(rbind,pr_agg)
```


################
# death prevalence curves
################
probability of dying within the followup time (4 years)

use kaplan-meier non-parametric estimator for points
linear interpolator
problem: apparently the estimator is biased. but forcing gompertz is also biased. only solution is to use survpen and make sure I recover kaplan meier result

```{r}
library(eha)
library(survPen)
```

```{r}
#note: survfit(s~x) is same as just splitting up by x strata
NonParSurv = function(s,t,conf.int=pnorm(1)-pnorm(-1))
{
  sf = survfit(s~1,conf.int=conf.int)
  app = approxfun(x=sf$time,y=sf$surv,yleft = 1,yright=NA)
  applow = approxfun(x=sf$time,y=sf$lower,yleft = 1,yright=NA)
  apphigh = approxfun(x=sf$time,y=sf$upper,yleft = 1,yright=NA)
  return(data.frame(pr=app(t),prlow=applow(t),prhigh=apphigh(t)))
}


NonParSurv.cox = function(s,
                        pr, #coxph model predicted risk #pr = predict(fit,data.frame(my$x),type="risk")
                        t=4,
                        t0=0,
                        conf.int=pnorm(1)-pnorm(-1))
{
  #returns probablity of surviving form t0 to t
  #assumes proportional hazard -> S = (S0)^(exp(beta*x)) = (S0)^pr
  #Q. do I need to center the predictors? Answer: no.
  #returns data.frame with nrow = length(pr)  
    #i.e. individual baseline survival probabilities
  sf = survfit(s~1,conf.int=conf.int)
  app = approxfun(x=sf$time,y=sf$surv,yleft = 1,yright=NA)
  applow = approxfun(x=sf$time,y=sf$lower,yleft = 1,yright=NA)
  apphigh = approxfun(x=sf$time,y=sf$upper,yleft = 1,yright=NA)

  if(t0 != 0)
  {
    pr = 1-(app(t)/app(t0))^pr
    prlow = 1-(applow(t)/applow(t0))^pr
    prhigh = 1-(apphigh(t)/apphigh(t0))^pr
  }
  else
  {
    pr = 1-(app(t))^pr
    prlow = 1-(applow(t))^pr
    prhigh = 1-(apphigh(t))^pr
  }
  
    return(data.frame(pr=pr,prlow=prlow,prhigh=prhigh))
}

```



```{r}
library(splines2)
testfi = seq(0,.75,by=.01)
ttest = 4 #followup time
fi_cuts = c(seq(0,.6,by=.1),1)

bMat = bSpline(seq(0,1,by=.01), knots=c(.1,.2,.3), Boundary.knots = c(0, 1),
                  intercept = FALSE, periodic = FALSE)
colnames(bMat) = sprintf("fi_sp%02d",1:ncol(bMat))
testMat = data.frame(predict(bMat,testfi))
colnames(testMat) = colnames(bMat)

  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~fi,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~fi,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testfi,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(fi),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testfi),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["Smax"]]/2-pr[["Smin"]]/2)))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  #spline #I want to make sure I recover kaplain-meier if I crank up fit (since it's purportedly biased)
    #gotta use survpen since we don't know if Gompertz is right
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    #b = predict(bMat,stst[[ii]][[1]][,"fi"])
    #temp = data.frame(b)
    #colnames(temp) = colnames(bMat)
    
    #md = phreg(s2~.,data=temp,dist="gompertz",param="rate")
    #prS = numeric()
    #prSse = numeric()
    #for (kk in 1:nrow(testMat))
    #{
    #  pr = PHConfInt(ttest=ttest,t0=0,N = 100,fit=md,errorScale=1,x=testMat[kk,])
    #  prS[kk] = pr[["S"]]
    #  prSse[kk] = abs(pr[["Smax"]]/2-pr[["Smin"]]/2)
    #}
    #l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-prS))
    #lse[[ii]] = as.matrix(data.frame(fi=0,pr=prSse))
    temp = stst[[ii]][[1]]
    temp[,"status"] = stst[[ii]][[2]][,"status"] #stst[[ii]][1] is final status; [[2]] is current status
    temp[,"tstart"] =  stst[[ii]][[2]][,"start"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    temp[,"tstop"] =  stst[[ii]][[2]][,"stop"] - stst[[ii]][[1]][,"start"] #subtract baseline age
    md = survPen(~smf(tstop)+smf(fi),data=temp,t0=tstart,t1=tstop,event=status)
    pr = predict(md,newdata=data.frame(tstop=ttest,fi=testfi,tstart=t0),conf.int=pnorm(1)-pnorm(-1))
    l[[ii]] = as.matrix(data.frame(fi=testfi,pr=1-pr[["surv"]]))
    lse[[ii]] = as.matrix(data.frame(fi=0,pr=abs(pr[["surv.inf"]]/2-pr[["surv.sup"]]/2)))
  }
  pr_agg_sp = RubinMat(l,lse)
  pr_agg_sp[[1]] = data.frame(pr_agg_sp[[1]])
  pr_agg_sp[[1]][,sprintf("%sse",colnames(pr_agg_sp[[2]]))] = pr_agg_sp[[2]]
  pr_agg_sp = pr_agg_sp[[1]]
  rm(l)
  rm(lse)

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    fic = cut(stst[[ii]][[1]][,"fi"],fi_cuts,include.lowest=T)
    temp = data.frame(fi_cut=levels(fic))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = fic == temp[jj,"fi_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = abs(pr[["prhigh"]]/2-pr[["prlow"]]/2)
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"fi"] = mean(stst[[ii]][[1]][logi,"fi"],na.rm=T)
      temp[jj,"fise"] = SEM(stst[[ii]][[1]][logi,"fi"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("fi","pr")])
    lse[[ii]] = as.matrix(temp[,c("fise","prse")])
    
    logitmod = lm(log(pr/(1-pr))~sqrt(fi),temp,weights=1/(temp[,"prse"]^2+temp[,"fise"]^2)) #weights look worse (overfit) #sqrt > linear (closer to spline)
    pr = predict(logitmod,data.frame(fi=testfi),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(fi=testfi,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(fi=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit,pr_agg_sp)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = subset(plotdata,model%in%c("logit","spline"))
  
  #frequencies
  g = ggplot(plotdata,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  
  g
  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sp[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/death_prevalence_hrs_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/death_prevalence_hrs_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_sp,sprintf("%s/data/death_prevalence_hrs_logit_pragg_sp.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/death_prevalence_hrs_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/death_prevalence_hrs_logit_agg.csv",outputDir),row.names=F)
  }

save=T
if(save)
{
  ggsave(sprintf("%s/results/death_prevalence_hrs.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/death_prevalence_hrs.png",outputDir),g,width=8,height=8,dpi=300)
}
```

combined plot with NHANES
```{r}
library(splines2)
files = c("hrs","nhanes")
#include = c("linear","sqrt")
include = c("logit") #sqrt
#include = c("linear")
scale=F #scale prevalence assuming exponential (by dt)
#outcomes = fpNames


  pr_agg = list()
  pr_agg_sq = list()
  pr_agg_sp = list()
  pr_agg_logit = list()
  agg = list()
  for (ii in 1:length(files))
  {
    pr_agg[[ii]] = read.csv(sprintf("%s/data/death_prevalence_%s_logit_pragg.csv",outputDir,files[ii]))
    pr_agg_sq[[ii]] = read.csv(sprintf("%s/data/death_prevalence_%s_logit_pragg_sq.csv",outputDir,files[ii]))
    pr_agg_logit[[ii]] = read.csv(sprintf("%s/data/death_prevalence_%s_logit_pragg_logit.csv",outputDir,files[ii]))
    pr_agg_sp[[ii]] = read.csv(sprintf("%s/data/death_prevalence_%s_logit_pragg_sp.csv",outputDir,files[ii]))
    agg[[ii]] = read.csv(sprintf("%s/data/death_prevalence_%s_logit_agg.csv",outputDir,files[ii]))
    pr_agg[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sq[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_logit[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sp[[ii]][,"dataset"] = toupper(files[ii])
    agg[[ii]][,"dataset"] = toupper(files[ii])
  }
  agg = do.call(rbind,agg)
  pr_agg = do.call(rbind,pr_agg)
  pr_agg_sq = do.call(rbind,pr_agg_sq)
  pr_agg_sp = do.call(rbind,pr_agg_sp)
  pr_agg_logit = do.call(rbind,pr_agg_logit)

  plotdata = list(pr_agg_sq)
  plotdata[[1]][,"model"] = "sqrt"
  plotdata[[2]] = pr_agg
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]] = pr_agg_logit
  plotdata[[3]][,"model"] = "logit"
  plotdata[[4]] = pr_agg_sp
  plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  plotdata[,"prlowse"] = plotdata[,"pr"]-plotdata[,"prse"]
  plotdata[,"prhighse"] = plotdata[,"pr"]+plotdata[,"prse"]
  agg[,"prlowse"] = agg[,"pr"]-agg[,"prse"]
  agg[,"prhighse"] = agg[,"pr"]+agg[,"prse"]
  
  if(scale)
  {
    plotdata[,"pr"] = 1-exp(log(1-plotdata[,"pr"])/plotdata[,"dt"])
    plotdata[,"prlowse"] = 1-exp(log(1-plotdata[,"prlowse"])/plotdata[,"dt"])
    plotdata[,"prhighse"] = 1-exp(log(1-plotdata[,"prhighse"])/plotdata[,"dt"])
    
    agg[,"pr"] = 1-exp(log(1-agg[,"pr"])/agg[,"dt"])
    agg[,"prlowse"] = 1-exp(log(1-agg[,"prlowse"])/agg[,"dt"])
    agg[,"prhighse"] = 1-exp(log(1-agg[,"prhighse"])/agg[,"dt"])
  }
  
  #if(!is.na(ylim[[i]][2])) agg[agg[,"prhighse"] > ylim[[i]][2],"prhighse"] = ylim[[i]][2]
  
  #drop 0 zero points, 0 sd means probably no data
  agg = subset(agg,prse > 0)
  
  #frequencies
  if(length(include)>1) 
  {
    g = ggplot(plotdata,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=model))
  } else 
  {
    g = ggplot(plotdata,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=dataset))
  }
  g = g+
    geom_line(size=gLineWidth)+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=fi,y=pr,ymin=prlowse,ymax=prhighse,shape=dataset,colour=dataset),inherit.aes=F,size=1)+
    geom_errorbarh(data=agg,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=pr,colour=dataset),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="FI",y=bquote("Probability of dying"),title="")+
    #scale_y_continuous(limits=c(0,1))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize),
          legend.background = element_rect(fill="white",colour=NA),
          legend.key.size = unit(3,"line")
          )


#clean up legends
  #drop them all - use labels instead
cols = gg_color_hue(2)[1:2]
g = g + theme(legend.position=c(.2,.7),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")

#g = g + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
#g = g + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
if(length(include)>1) g = g + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))



#labels
#library(ggrepel)
if(length(include)>1) g = g + labs(x=bquote("FI,"~f),y=bquote("Probability of dying,"~p))

#standardize scale
g = g +scale_y_continuous(limits=c(0,.75))

#add title
g = g + ggtitle("(a) FI")

g


save=T
if(save)
{
  nm = "death_prevalence"
  if(scale) nm = "death_prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  ggsave(sprintf("%s/results/%s.pdf",outputDir,nm),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s.png",outputDir,nm),g,width=10,height=8,dpi=300)
  

}
```


age - death prevalence

```{r}
library(splines2)
testage = seq(60,100,by=1)
ttest = 4 #followup time
age_cuts = c(seq(60,100,by=5))



  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~age,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~age,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testage,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(age),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testage),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(age=testage,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(age=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    agec = cut(stst[[ii]][[1]][,"age"],age_cuts,include.lowest=T)
    temp = data.frame(age_cut=levels(agec))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = agec == temp[jj,"age_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = pr[["prhigh"]]/2-pr[["prlow"]]/2
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"age"] = mean(stst[[ii]][[1]][logi,"age"],na.rm=T)
      temp[jj,"agese"] = SEM(stst[[ii]][[1]][logi,"age"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("age","pr")])
    lse[[ii]] = as.matrix(temp[,c("agese","prse")])
    
    logitmod = lm(log(pr/(1-pr))~age,temp)#,weights=1/(temp[,"prse"]^2+temp[,"agese"]^2))
    pr = predict(logitmod,data.frame(age=testage),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(age=testage,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(age=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g = ggplot(plotdata,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme()
  

  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/age_death_prevalence_hrs_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/age_death_prevalence_hrs_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/age_death_prevalence_hrs_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/age_death_prevalence_hrs_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/age_death_prevalence_hrs.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/age_death_prevalence_hrs.png",outputDir),g,width=8,height=8,dpi=300)
  

}
#plot(log(pr/(1-pr))~age,agg) #non-linear even here!
```

```{r}
plot(agg[,"age"],log(agg[,"pr"])-log(1-agg[,"pr"]))
abline(lm(log(pr/(1-pr))~age,agg))

plot(sqrt(agg[,"age"]),log(agg[,"pr"])-log(1-agg[,"pr"]))
abline(lm(log(pr/(1-pr))~sqrt(age),agg))
```

combined plot with NHANES - age death prevalence
```{r}
library(splines2)
files = c("hrs","nhanes")
#include = c("linear","sqrt")
include = c("logit") #sqrt
#include = c("linear")
scale=F #scale prevalence assuming exponential (by dt)


  pr_agg = list()
  pr_agg_sq = list()
  #pr_agg_sp = list()
  pr_agg_logit = list()
  agg = list()
  for (ii in 1:length(files))
  {
    pr_agg[[ii]] = read.csv(sprintf("%s/data/age_death_prevalence_%s_logit_pragg.csv",outputDir,files[ii]))
    pr_agg_sq[[ii]] = read.csv(sprintf("%s/data/age_death_prevalence_%s_logit_pragg_sq.csv",outputDir,files[ii]))
    pr_agg_logit[[ii]] = read.csv(sprintf("%s/data/age_death_prevalence_%s_logit_pragg_logit.csv",outputDir,files[ii]))
    #pr_agg_sp[[ii]] = read.csv(sprintf("%s/data/age_death_prevalence_%s_logit_pragg_sp.csv",outputDir,files[ii]))
    agg[[ii]] = read.csv(sprintf("%s/data/age_death_prevalence_%s_logit_agg.csv",outputDir,files[ii]))
    pr_agg[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sq[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_logit[[ii]][,"dataset"] = toupper(files[ii])
    #pr_agg_sp[[ii]][,"dataset"] = toupper(files[ii])
    agg[[ii]][,"dataset"] = toupper(files[ii])
  }
  agg = do.call(rbind,agg)
  pr_agg = do.call(rbind,pr_agg)
  pr_agg_sq = do.call(rbind,pr_agg_sq)
  #pr_agg_sp = do.call(rbind,pr_agg_sp)
  pr_agg_logit = do.call(rbind,pr_agg_logit)

  plotdata = list(pr_agg_sq)
  plotdata[[1]][,"model"] = "sqrt"
  plotdata[[2]] = pr_agg
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]] = pr_agg_logit
  plotdata[[3]][,"model"] = "logit"
  #plotdata[[4]] = pr_agg_sp
  #plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  plotdata[,"prlowse"] = plotdata[,"pr"]-plotdata[,"prse"]
  plotdata[,"prhighse"] = plotdata[,"pr"]+plotdata[,"prse"]
  agg[,"prlowse"] = agg[,"pr"]-agg[,"prse"]
  agg[,"prhighse"] = agg[,"pr"]+agg[,"prse"]
  
  if(scale)
  {
    plotdata[,"pr"] = 1-exp(log(1-plotdata[,"pr"])/plotdata[,"dt"])
    plotdata[,"prlowse"] = 1-exp(log(1-plotdata[,"prlowse"])/plotdata[,"dt"])
    plotdata[,"prhighse"] = 1-exp(log(1-plotdata[,"prhighse"])/plotdata[,"dt"])
    
    agg[,"pr"] = 1-exp(log(1-agg[,"pr"])/agg[,"dt"])
    agg[,"prlowse"] = 1-exp(log(1-agg[,"prlowse"])/agg[,"dt"])
    agg[,"prhighse"] = 1-exp(log(1-agg[,"prhighse"])/agg[,"dt"])
  }
  
 # if(!is.na(ylim[[i]][2])) agg[agg[,"prhighse"] > ylim[[i]][2],"prhighse"] = ylim[[i]][2]
  
  #drop 0 zero points, 0 sd means probably no data
  agg = subset(agg,prse > 0)
  
  #frequencies
  if(length(include)>1) 
  {
    g = ggplot(plotdata,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=model))
  } else 
  {
    g = ggplot(plotdata,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=dataset))
  }
  g = g+
    geom_line(size=gLineWidth)+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=age,y=pr,ymin=prlowse,ymax=prhighse,shape=dataset,colour=dataset),inherit.aes=F,size=1)+
    geom_errorbarh(data=agg,aes(x=age,xmin=age-agese,xmax=age+agese,y=pr,colour=dataset),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x="Age",y=bquote("Probability of dying"),title="Death")+
    #scale_y_continuous(limits=c(0,1))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize),
          legend.key.size=unit(3,"line")
          )


#clean up legends
  #drop them all - use labels instead
cols = gg_color_hue(2)[1:2]
g = g + theme(legend.position=c(.2,.7),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")

#g = g + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
#g = g + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
if(length(include)>1) g = g + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))



#labels
#library(ggrepel)
if(length(include)>1) g = g + labs(x=bquote("FI,"~f),y=bquote("Probability of dying,"~p))



g


save=T
if(save)
{
  nm = "age_death_prevalence"
  if(scale) nm = "age_death_prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  ggsave(sprintf("%s/results/%s.pdf",outputDir,nm),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s.png",outputDir,nm),g,width=10,height=8,dpi=300)
  

}
```

stratify by age - can't get a decent fit :(


Nfp - death prevalence
Should we use data (every 4 years) or stst (every 2 years)?
-if we use data we'll get real measurements for gait and grip
-if we use stst we may have a more fair comparison to FI
-according to our results gait and grip don't change often --- but I didn't impute using markov!
  -shouldn't matter since we included the other deficits and FI; we already show FI is decent proxy for gait/grip
```{r}
library(splines2)
testNfp = seq(0,5,by=.1)
ttest = 4 #followup time
t0 = 0
Nfp_cuts = 0:5


  #linear
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~Nfp,data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=testNfp,N = 1000,fit=md,errorScale=1,ttest=ttest)
    #md = phreg(s2~Nfp,data=stst[[ii]][[1]],dist="weibull") #looks same
    #pr = PHConfInt2VecX.weibull(x=testNfp,N = 1000,fit=md,errorScale=1,ttest=ttest)
    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg = RubinMat(l,lse)
  pr_agg[[1]] = data.frame(pr_agg[[1]])
  pr_agg[[1]][,sprintf("%sse",colnames(pr_agg[[2]]))] = pr_agg[[2]]
  pr_agg = pr_agg[[1]]
  rm(l)
  rm(lse)
  
  
  #glm - sqrt
  l = list()
  lse = list()
  for(ii in 1:length(stst))
  {
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age

    md = phreg(s2~sqrt(Nfp),data=stst[[ii]][[1]],dist="gompertz",param="rate")
    pr = PHConfInt2VecX(x=sqrt(testNfp),N = 1000,fit=md,errorScale=1,ttest=ttest)

    l[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1-pr[["S"]]))
    lse[[ii]] = as.matrix(data.frame(Nfp=0,pr=-pr[["Smax"]]/2+pr[["Smin"]]/2))
  }
  pr_agg_sq = RubinMat(l,lse)
  pr_agg_sq[[1]] = data.frame(pr_agg_sq[[1]])
  pr_agg_sq[[1]][,sprintf("%sse",colnames(pr_agg_sq[[2]]))] = pr_agg_sq[[2]]
  pr_agg_sq = pr_agg_sq[[1]]
  rm(l)
  rm(lse)
  
  

  #population stats
  #this is the empirical frequency - how do we compute the odds ratio?
    #update: include logit model
  l = list()
  lse = list()
  llogit = list()
  llogitse = list()
  for(ii in 1:length(stst))
  {
    Nfpc = cut(stst[[ii]][[1]][,"Nfp"],Nfp_cuts,include.lowest=T)
    temp = data.frame(Nfp_cut=levels(Nfpc))
    s2 = stst[[ii]][[2]]
    s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
    
    for (jj in 1:nrow(temp))
    {
      logi = Nfpc == temp[jj,"Nfp_cut"]
      pr = NonParSurv(s2[logi,],ttest,conf.int=pnorm(1)-pnorm(-1))
      temp[jj,"pr"] = 1-pr[["pr"]]
      temp[jj,"prse"] = pr[["prhigh"]]/2-pr[["prlow"]]/2
      temp[jj,"prhigh"] = 1-pr[["prhigh"]]
      temp[jj,"prlow"] = 1-pr[["prlow"]]
      temp[jj,"Nfp"] = mean(stst[[ii]][[1]][logi,"Nfp"],na.rm=T)
      temp[jj,"Nfpse"] = SEM(stst[[ii]][[1]][logi,"Nfp"],na.rm=T)
    }

    l[[ii]] = as.matrix(temp[,c("Nfp","pr")])
    lse[[ii]] = as.matrix(temp[,c("Nfpse","prse")])
    
    logitmod = lm(log(pr/(1-pr))~Nfp,temp)#,weights=1/(temp[,"prse"]^2+temp[,"Nfpse"]^2))
    pr = predict(logitmod,data.frame(Nfp=testNfp),se.fit=T)
    llogit[[ii]] = as.matrix(data.frame(Nfp=testNfp,pr=1/(1+exp(-pr[[1]]))))
    llogitse[[ii]] = as.matrix(data.frame(Nfp=0,pr=pr[[2]]*pr[[1]]/(1+exp(-pr[[1]]))^2))
  }
  agg = RubinMat(l,lse)
  agg[[1]] = data.frame(agg[[1]])
  agg[[1]][,colnames(agg[[2]])] = agg[[2]]
  agg = agg[[1]]
  pr_agg_logit = RubinMat(llogit,llogitse)
  pr_agg_logit[[1]] = data.frame(pr_agg_logit[[1]])
  pr_agg_logit[[1]][,sprintf("%sse",colnames(pr_agg_logit[[2]]))] = pr_agg_logit[[2]]
  pr_agg_logit = pr_agg_logit[[1]]

  plotdata = list(pr_agg,pr_agg_sq,pr_agg_logit)
  plotdata[[1]][,"model"] = "linear"
  plotdata[[2]][,"model"] = "sqrt"
  plotdata[[3]][,"model"] = "logit"
  plotdata = do.call(rbind,plotdata)
  
  #frequencies
  g = ggplot(plotdata,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse,colour=model,fill=model,linetype=model))+
    geom_line()+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=Nfp,y=pr,ymin=pr-prse,ymax=pr+prse),inherit.aes=F)+
    geom_errorbarh(data=agg,aes(x=Nfp,xmin=Nfp-Nfpse,xmax=Nfp+Nfpse,y=pr),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x=gFab5Name,y=bquote("Probability of dying"),title="Death")+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()
  

  
  
  pr_agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_sq[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  pr_agg_logit[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dt"] = mean(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)
  agg[,"dtse"] = SEM(data[[1]][,"age_next"]-data[[1]][,"age"],na.rm=T)

  if(save)
  {
    write.csv(pr_agg,sprintf("%s/data/Nfp_death_prevalence_hrs_logit_pragg.csv",outputDir),row.names=F)
    write.csv(pr_agg_sq,sprintf("%s/data/Nfp_death_prevalence_hrs_logit_pragg_sq.csv",outputDir),row.names=F)
    write.csv(pr_agg_logit,sprintf("%s/data/Nfp_death_prevalence_hrs_logit_pragg_logit.csv",outputDir),row.names=F)
    write.csv(agg,sprintf("%s/data/Nfp_death_prevalence_hrs_logit_agg.csv",outputDir),row.names=F)
  }

g


save=T
if(save)
{
  ggsave(sprintf("%s/results/Nfp_death_prevalence_hrs.pdf",outputDir),g,width=8,height=8,dpi=300)
  ggsave(sprintf("%s/results/Nfp_death_prevalence_hrs.png",outputDir),g,width=8,height=8,dpi=300)
  

}
#plot(log(pr/(1-pr))~Nfp,agg) #non-linear even here!
```
combined plot with NHANES
```{r}
library(splines2)
files = c("hrs","nhanes")
#include = c("linear","sqrt")
include = c("logit") #sqrt
#include = c("linear")
scale=F #scale prevalence assuming exponential (by dt)
outcomes = fpNames


  pr_agg = list()
  pr_agg_sq = list()
  #pr_agg_sp = list()
  pr_agg_logit = list()
  agg = list()
  for (ii in 1:length(files))
  {
    pr_agg[[ii]] = read.csv(sprintf("%s/data/Nfp_death_prevalence_%s_logit_pragg.csv",outputDir,files[ii]))
    pr_agg_sq[[ii]] = read.csv(sprintf("%s/data/Nfp_death_prevalence_%s_logit_pragg_sq.csv",outputDir,files[ii]))
    pr_agg_logit[[ii]] = read.csv(sprintf("%s/data/Nfp_death_prevalence_%s_logit_pragg_logit.csv",outputDir,files[ii]))
    #pr_agg_sp[[ii]] = read.csv(sprintf("%s/data/Nfp_death_prevalence_%s_logit_pragg_sp.csv",outputDir,files[ii]))
    agg[[ii]] = read.csv(sprintf("%s/data/Nfp_death_prevalence_%s_logit_agg.csv",outputDir,files[ii]))
    pr_agg[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_sq[[ii]][,"dataset"] = toupper(files[ii])
    pr_agg_logit[[ii]][,"dataset"] = toupper(files[ii])
    #pr_agg_sp[[ii]][,"dataset"] = toupper(files[ii])
    agg[[ii]][,"dataset"] = toupper(files[ii])
  }
  agg = do.call(rbind,agg)
  pr_agg = do.call(rbind,pr_agg)
  pr_agg_sq = do.call(rbind,pr_agg_sq)
  #pr_agg_sp = do.call(rbind,pr_agg_sp)
  pr_agg_logit = do.call(rbind,pr_agg_logit)

  plotdata = list(pr_agg_sq)
  plotdata[[1]][,"model"] = "sqrt"
  plotdata[[2]] = pr_agg
  plotdata[[2]][,"model"] = "linear"
  plotdata[[3]] = pr_agg_logit
  plotdata[[3]][,"model"] = "logit"
  #plotdata[[4]] = pr_agg_sp
  #plotdata[[4]][,"model"] = "spline"
  plotdata = do.call(rbind,plotdata)
  plotdata = plotdata[plotdata[,"model"]%in%include,]
  
  plotdata[,"prlowse"] = plotdata[,"pr"]-plotdata[,"prse"]
  plotdata[,"prhighse"] = plotdata[,"pr"]+plotdata[,"prse"]
  agg[,"prlowse"] = agg[,"pr"]-agg[,"prse"]
  agg[,"prhighse"] = agg[,"pr"]+agg[,"prse"]
  
  if(scale)
  {
    plotdata[,"pr"] = 1-exp(log(1-plotdata[,"pr"])/plotdata[,"dt"])
    plotdata[,"prlowse"] = 1-exp(log(1-plotdata[,"prlowse"])/plotdata[,"dt"])
    plotdata[,"prhighse"] = 1-exp(log(1-plotdata[,"prhighse"])/plotdata[,"dt"])
    
    agg[,"pr"] = 1-exp(log(1-agg[,"pr"])/agg[,"dt"])
    agg[,"prlowse"] = 1-exp(log(1-agg[,"prlowse"])/agg[,"dt"])
    agg[,"prhighse"] = 1-exp(log(1-agg[,"prhighse"])/agg[,"dt"])
  }
  
  #if(!is.na(ylim[[i]][2])) agg[agg[,"prhighse"] > ylim[[i]][2],"prhighse"] = ylim[[i]][2]
  
  #drop 0 zero points, 0 sd means probably no data
  agg = subset(agg,prse > 0)
  
  #frequencies
  if(length(include)>1) 
  {
    g = ggplot(plotdata,aes(x=Nfp,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=model))
  } else 
  {
    g = ggplot(plotdata,aes(x=Nfp,y=pr,ymin=prlowse,ymax=prhighse,colour=dataset,fill=dataset,fill=model,linetype=dataset))
  }
  g = g+
    geom_line(size=gLineWidth)+
    geom_ribbon(alpha=.15,colour=NA)+
    geom_pointrange(data=agg,aes(x=Nfp,y=pr,ymin=prlowse,ymax=prhighse,shape=dataset,colour=dataset),inherit.aes=F,size=1)+
    geom_errorbarh(data=agg,aes(x=Nfp,xmin=Nfp-Nfpse,xmax=Nfp+Nfpse,y=pr,colour=dataset),inherit.aes=F,height=0)+  #error in FI is small enough to ignore
    labs(x=gFab5Name,y=bquote("Probability of dying"),title="")+
    scale_y_continuous(limits=c(0,NA))+
    #scale_y_log10()+
    #annotation_logticks(sides="l")+
    theme_minimal()+
    theme(text=element_text(size=gTextSize),
          legend.background = element_rect(fill="white",colour=NA),
          legend.key.size = unit(3,"line"),
          legend.position="none"
          )


#clean up legends
  #drop them all - use labels instead
#cols = gg_color_hue(2)[1:2]
#g = g + theme(legend.position=c(.2,.7),legend.title=element_blank(),legend.background=element_rect(fill="white",colour=NA)) #,legend.key.width = unit(3,"line")

#g = g + scale_colour_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
#g = g + scale_fill_manual(values=cols,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))
if(length(include)>1) g = g + scale_linetype_manual(values=1:2,breaks=c("linear","sqrt"),labels=c(bquote(logit(p)*"~"*f),bquote(logit(p)*"~"*sqrt(f))))



#labels
#library(ggrepel)
if(length(include)>1) g = g + labs(x=bquote("FI,"~f),y=bquote("Probability of dying,"~p))

#standardize scale
g = g + scale_y_continuous(limits=c(0,.75))

#add title
g = g + ggtitle(sprintf("(b) %s",gFab5Name))

g


save=T
if(save)
{
  nm = "Nfp_death_prevalence"
  if(scale) nm = "Nfp_death_prevalence_scaled"
  if("linear"%in%include) nm = sprintf("%s_linear",nm)
  if("sqrt"%in%include) nm = sprintf("%s_sqrt",nm)
  ggsave(sprintf("%s/results/%s.pdf",outputDir,nm),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/%s.png",outputDir,nm),g,width=10,height=8,dpi=300)
  

}
```

################
# Cox models for death
################
Could also do Gompertz or spline...
```{r}
preds = c("sex","age","fi",fpVar)

names(preds)=c("Female","Age per 10","FI per 0.1",names(fpVar))
use = list()
use[[1]] = preds %in% c("fi")
use[[2]] = preds %in% c("age","sex")
use[[3]] = preds %in% c("age","sex","fi")
use[[4]] = preds == preds


C = list()
Cse = list()
for (ii in 1:length(stst))
{
  s2 = stst[[ii]][[2]]
  s2 = Surv(s2[,1]-stst[[ii]][[1]][,"start"],s2[,2]-stst[[ii]][[1]][,"start"],s2[,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]]))
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][[1]][,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]=="female")
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    #Cse[[ii]][j,"p"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
      #print(anova(prevMod,mod))
      #print(C[[ii]][j,"p"])
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2 = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2) = dimnames(C[[1]])
for (j in 1:length(preds)) C2[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2[is.na(C[[1]])] = ""
C2[,"BIC"] = sprintf("%.0f",C[[1]][,"BIC"])
C2[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2)[colnames(C2)==preds[j]] = names(preds)[j]

write.csv(C2,sprintf("%s/results/hrs_cox.csv",outputDir),row.names=FALSE)
```

# Cox by sex
```{r}
#MALES
#MALES
#MALES
preds = c("age","fi","fp1_weight","fp2_grip","fp3_gait","fp4_exhaustion","fp5_low_activity" )

names(preds)=c("Age per 10","FI per 0.1","Low BMI","Slow","Weakness","Exhaustion","Low activity")
use = list()
use[[1]] = preds %in% c("age")
use[[2]] = preds %in% c("fi")
use[[3]] = preds %in% c("age","fi")
use[[4]] = preds == preds


C = list()
Cse = list()
for (ii in 1:length(stst))
{
  logi = stst[[ii]][[1]][,"sex"] == "male"
  s2 = stst[[ii]][[2]]
  s2 = Surv(s2[logi,1]-stst[[ii]][[1]][logi,"start"],s2[logi,2]-stst[[ii]][[1]][logi,"start"],s2[logi,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]])-1)
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][[1]][logi,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2M = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2M) = dimnames(C[[1]])
for (j in 1:length(preds)) C2M[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2M[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2M[is.na(C[[1]])] = ""
colnames(C2M)[colnames(C2M)=="BIC"] = "deltaBIC"
C2M[,"deltaBIC"] = sprintf("%.0f",C[[1]][,"BIC"]-C[[1]][1,"BIC"])
C2M[1,"deltaBIC"] = "Ref."
C2M[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2M)[colnames(C2M)==preds[j]] = names(preds)[j]

write.csv(C2M,sprintf("%s/results/hrs_male_cox.csv",outputDir),row.names=FALSE)

#FEMALE
#FEMALE
#FEMALE
#FEMALE
C = list()
Cse = list()
for (ii in 1:length(stst))
{
  logi = stst[[ii]][[1]][,"sex"] == "female"
  s2 = stst[[ii]][[2]]
  s2 = Surv(s2[logi,1]-stst[[ii]][[1]][logi,"start"],s2[logi,2]-stst[[ii]][[1]][logi,"start"],s2[logi,3]) #subtract baseline age
  
  C[[ii]] = matrix(NA,ncol=length(preds)+3,nrow=length(use))
  colnames(C[[ii]]) = c("C","BIC","p",preds)
  rownames(C[[ii]]) = sprintf("model%d",1:nrow(C[[ii]])-1)
  Cse[[ii]] = C[[ii]]
  prevMod=NULL
  for (j in 1:length(use))
  {
    temp = stst[[ii]][[1]][logi,preds[use[[j]]],drop=F]
    if("fi"%in%colnames(temp)) temp[,"fi"] = temp[,"fi"]*10 #want big enough to have >> 1 for easier plotting
    if("fifp"%in%colnames(temp)) temp[,"fifp"] = temp[,"fifp"]*10 #want big enough to have >> 1 for easier plotting
    if("age"%in%colnames(temp)) temp[,"age"] = temp[,"age"]/10
    if("sex"%in%colnames(temp)) temp[,"sex"] = as.integer(temp[,"sex"]==1)
    mod = coxph(s2~.,temp)
    C[[ii]][j,"C"] = concordance(mod)$concordance
    #C[[ii]][j,"loglik"] = logLik(mod)[1]
    C[[ii]][j,"BIC"] = BIC(mod)[1]
    C[[ii]][j,names(coef(mod))] = coef(mod)
    
    Cse[[ii]][j,"C"] = sqrt(concordance(mod)$var)
    #Cse[[ii]][j,"loglik"] = NA
    Cse[[ii]][j,"BIC"] = NA
    Cse[[ii]][j,rownames(summary(mod)$coefficients)] = summary(mod)$coefficients[,"se(coef)"]
    if(!is.null(prevMod))
    {
      C[[ii]][j,"p"] = anova(prevMod,mod)[2,4]
    }
    prevMod = mod
  }
}
C = RubinMat(C,Cse)
for (k in 1:length(C)) 
{
  C[[k]] = as.data.frame(C[[k]])
}

#convert to table
C2F = matrix(sprintf("%.2f",as.matrix(C[[1]])),nrow=nrow(C[[1]]),ncol=ncol(C[[1]]))
dimnames(C2F) = dimnames(C[[1]])
for (j in 1:length(preds)) C2F[,preds[j]] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(C[[1]][,preds[j]]),exp(C[[1]][,preds[j]]-qnorm(.975)*C[[2]][,preds[j]]),exp(C[[1]][,preds[j]]+qnorm(.975)*C[[2]][,preds[j]]))
C2F[,"C"] = sprintf("$%.2f_{%.2f}^{%.2f}$",(C[[1]][,"C"]),(C[[1]][,"C"]-qnorm(.975)*C[[2]][,"C"]),(C[[1]][,"C"]+qnorm(.975)*C[[2]][,"C"]))
C2F[is.na(C[[1]])] = ""
colnames(C2F)[colnames(C2F)=="BIC"] = "deltaBIC"
C2F[,"deltaBIC"] = sprintf("%.0f",C[[1]][,"BIC"]-C[[1]][1,"BIC"])
C2F[1,"deltaBIC"] = "Ref."
C2F[,"p"] = sprintf("%.0e",C[[1]][,"p"])

for (j in 1:length(preds)) colnames(C2F)[colnames(C2F)==preds[j]] = names(preds)[j]

write.csv(C2F,sprintf("%s/results/hrs_female_cox.csv",outputDir),row.names=FALSE)
C2 = cbind(t(C2M),t(C2F))
C2 = rbind("",C2)
rownames(C2)[1] = "Predictor or measure"
C2[1,1] = "HRS - Males"
C2[1,5] = "HRS - Females"
write.csv(C2,sprintf("%s/results/hrs_sex_cox.csv",outputDir),row.names=TRUE)
```

# Cox diagnostics
# Cox assumption
```{r}
prname="fi"
#cuts = c(0,.05,seq(.15,.65,by=.1),1)
cuts = c(seq(0,.65,by=.1),1)
ytest = seq(0,.8,by=.01)
labs = unique(cut(seq(0,1,by=.1),cuts,include.lowest=T))
fitdata = list()
fitdatase = list()
for (i in 1:length(stst))
{
  pr = stst[[i]][[1]][,prname]
  pr = cut(pr,cuts,labels=labs,include.lowest=T)
  #pr = factor(pr,sortedlabs) #refactor so that middle quantile is first
  vals = aggregate(stst[[i]][[1]][,prname],by=list(q=pr),mean,na.rm=T)
  vals_se = aggregate(stst[[i]][[1]][,prname],by=list(q=pr),SEM,na.rm=T)
  
  mod = coxph(stst[[i]][[2]]~pr)
  C = summary(mod)$coefficients
  
  fitdata[[i]] = data.frame(beta=c(0,C[,"coef"]),y=vals[,"x"])
  colnames(fitdata[[i]]) = gsub("y",prname,colnames(fitdata[[i]]))
  #colnames(fitdata[[i]]) = gsub("beta","pr",colnames(fitdata[[i]]))
  fitdata[[i]] = as.matrix(fitdata[[i]])
  
  fitdatase[[i]] = data.frame(beta=c(0,C[,"se(coef)"]),y=vals_se[,"x"])
  colnames(fitdatase[[i]]) = gsub("y",prname,colnames(fitdatase[[i]]))
  #colnames(fitdatase[[i]]) = gsub("beta","pr,colnames(fitdatase[[i]]))
  fitdatase[[i]] = as.matrix(fitdatase[[i]])
  
}
fitdata = RubinMat(fitdata,fitdatase)
fitdata[[1]] = as.data.frame(fitdata[[1]])
fitdata[[1]][,sprintf("%sse",colnames(fitdata[[1]]))] = fitdata[[2]]
fitdata = fitdata[[1]]


save=T
if(save)
{
  write.csv(fitdata,sprintf("%s/data/cox_ph_test_hrs.csv",outputDir))
}
```
combine
```{r}
files = c("hrs","elsa","nhanes")
fitdata = list()
linfit = list()
sqrtfit = list()
testfi = seq(0,.73,by=.01)
for (i in 1:length(files))
{
   fitdata[[i]] = read.csv(sprintf("%s/data/cox_ph_test_%s.csv",outputDir,files[i]))
   fitdata[[i]][,"dataset"] = toupper(files[i])
   
   mod = lm(beta~fi,fitdata[[i]])#,weights=1/(fitdata[[i]][,"betase"]^2+fitdata[[i]][,"fise"]^2))
   linfit[[i]] = data.frame(fi=testfi)
   pr = predict(mod,newdata=linfit[[i]],se.fit=T)
   linfit[[i]][,"beta"] = pr[[1]]
   linfit[[i]][,"betase"] = pr[[2]]
   linfit[[i]][,"dataset"] = toupper(files[i])
   
   mod = lm(beta~sqrt(fi),fitdata[[i]])#,weights=1/(fitdata[[i]][,"betase"]^2+fitdata[[i]][,"fise"]^2))
   sqrtfit[[i]] = data.frame(fi=testfi)
   pr = predict(mod,newdata=sqrtfit[[i]],se.fit=T)
   sqrtfit[[i]][,"beta"] = pr[[1]]
   sqrtfit[[i]][,"betase"] = pr[[2]]
   sqrtfit[[i]][,"dataset"] = toupper(files[i])
}
fitdata = do.call(rbind,fitdata)
linfit = do.call(rbind,linfit)
sqrtfit = do.call(rbind,sqrtfit)

linfit[,"model"] = "Linear"
sqrtfit[,"model"] = "Squareroot"
lmfits = rbind(linfit,sqrtfit)


g = ggplot(fitdata,aes(x=fi,xmin=fi-fise,xmax=fi+fise,y=beta,ymin=beta-betase,ymax=beta+betase,colour=dataset,fill=dataset,shape=dataset))+ #,linetype=dataset
  #geom_smooth(method="lm",alpha=.15,se=F)+
  #geom_smooth(method="lm",formula=y~sqrt(x),alpha=.15,se=F,lty=2)+
  geom_line(data=lmfits,aes(x=fi,y=beta,linetype=model,colour=dataset),inherit.aes=F)+
  geom_point(size=gPointSize)+
  geom_errorbar(width=0)+
  geom_errorbarh(height=0)+
  labs(x="FI",y=bquote("Proportional hazard coefficient"))+
  annotation_logticks(sides="l")+
  #guides(colour=guide_legend(ncol=2,byrow=FALSE))+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="white"),
        legend.key.size=unit(3,"line"),
        legend.position="right" #c(.2,.8)
        )

g = g + scale_y_continuous(limits=c(-.5,NA))

if(save)
{
  ggsave(sprintf("%s/results/cox_ph_assumption.pdf",outputDir),g,width=12,height=8,dpi=300)
  ggsave(sprintf("%s/results/cox_ph_assumption.png",outputDir),g,width=12,height=8,dpi=300)
}
```

################
# Predicting FUTURE fab-5 deficits (and frailty phenotype)
################
```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAcc = temp$acc
  agePredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAcc = RubinMat(metrics,lse=metricsSE)
  agePredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAcc,roc=agePredROC),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_male_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccM = temp$acc
  agePredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccM = RubinMat(metrics,lse=metricsSE)
  agePredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccM,roc=agePredROCM),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_female_agefpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  agePredAccF = temp$acc
  agePredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"age"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  agePredAccF = RubinMat(metrics,lse=metricsSE)
  agePredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=agePredAccF,roc=agePredROCF),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_fifpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAcc = temp$acc
  fiPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAcc = RubinMat(metrics,lse=metricsSE)
  fiPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAcc,roc=fiPredROC),file)
  }
}

```


```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_male_fifpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccM = temp$acc
  fiPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccM = RubinMat(metrics,lse=metricsSE)
  fiPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccM,roc=fiPredROCM),file)
  }
}

```


```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_female_fifpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fiPredAccF = temp$acc
  fiPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fi"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fiPredAccF = RubinMat(metrics,lse=metricsSE)
  fiPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fiPredAccF,roc=fiPredROCF),file)
  }
}

```



```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}
#plotdata[[length(vars)+1]] = as.data.frame(fiROC[[1]])
#colnames(plotdata[[length(vars)+1]])[1] = "specificities"
#specificity is user-specific so has no error
#plotdata[[length(vars)+1]][,"sensitivity_se"] = fiROC[[2]][,"sensitivity"]
#plotdata[[length(vars)+1]][,"variable"] = "FP"
#plotdata[[length(vars)+1]][,"max_youden"] = #max(plotdata[[length(vars)+1]][,"sensitivity"]+plotdata[[length(vars)+1]][,"specificities"],na.rm=T)
plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()
```
If we include fab-5 in the fi...

```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAcc = temp$acc
  fifpPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {

      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAcc = RubinMat(metrics,lse=metricsSE)
  fifpPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAcc,roc=fifpPredROC),file)
  }
}

```

```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_male_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAccM = temp$acc
  fifpPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAccM = RubinMat(metrics,lse=metricsSE)
  fifpPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAccM,roc=fifpPredROCM),file)
  }
}

```



```{r}
file = sprintf("%s/data/fi_vs_fp_hrs_female_fifpfpvar_next_roc.rds",outputDir)
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fifpPredAccF = temp$acc
  fifpPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities
  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"fifp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fifpPredAccF = RubinMat(metrics,lse=metricsSE)
  fifpPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fifpPredAccF,roc=fifpPredROCF),file)
  }
}

```


```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAcc = temp$acc
  fpPredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      r = roc(data[[i]][,fpNames[j]]~data[[i]][,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAcc = RubinMat(metrics,lse=metricsSE)
  fpPredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAcc,roc=fpPredROC),file)
  }
}
```


```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_male_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccM = temp$acc
  fpPredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==0
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccM = RubinMat(metrics,lse=metricsSE)
  fpPredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccM,roc=fpPredROCM),file)
  }
}
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_female_fpfpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fpPredAccF = temp$acc
  fpPredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      logi = data[[i]][,"sex"]==1
      r = roc(data[[i]][logi,fpNames[j]]~data[[i]][logi,"Nfp"],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fpPredAccF = RubinMat(metrics,lse=metricsSE)
  fpPredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fpPredAccF,roc=fpPredROCF),file)
  }
}
```

```{r}
vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()
```
Leave-one-out...

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAcc = temp$acc
  fp4PredROC = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      r = roc(data[[i]][,fpNames[j]]~Nfpexcl,ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAcc = RubinMat(metrics,lse=metricsSE)
  fp4PredROC = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAcc,roc=fp4PredROC),file)
  }
}
```

```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_male_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAccM = temp$acc
  fp4PredROCM = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      
      logi = data[[i]][,"sex"]==0
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl[logi],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAccM = RubinMat(metrics,lse=metricsSE)
  fp4PredROCM = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAccM,roc=fp4PredROCM),file)
  }
}
```


```{r}
library(pROC)
file = sprintf("%s/data/fi_vs_fp_hrs_female_fp4fpvar_next_roc.rds",outputDir) 
load = T
save = T
if(load & file.exists(file))
{
  temp = readRDS(file)
  fp4PredAccF = temp$acc
  fp4PredROCF = temp$roc
  rm(temp)
} else
{
  metrics = list()
  metricsSE = list()
  curve = list()
  curveSE = list()
  specs = seq(0,1,length=101) #specificities

  for (i in 1:length(data))
  {
    curve[[i]] = data.frame(specificities=specs)
    rownames(curve[[i]]) = specs
    curveSE[[i]] = data.frame(specificities=0*specs)
    rownames(curveSE[[i]]) = specs
    metrics[[i]] = data.frame(auc=rep(NA,length(fpNames)))
    rownames(metrics[[i]])=fpNames
    metricsSE[[i]] = metrics[[i]]
    for (j in 1:length(fpNames))
    {
      
      logi = data[[i]][,"sex"]==1
      #fpNames = sprintf("%s_next",c("fp_frail",fpVar))
      thisVar = strsplit(fpNames[j],"_next")[[1]]
      Nfpexcl = apply(data[[i]][,setdiff(fpVar,thisVar)],1,sum) #N FP excluding jth
      r = roc(data[[i]][logi,fpNames[j]]~Nfpexcl[logi],ci.method="boot",ci=T,direction="<")
  
      #extract curve
      ciobj = ci.se(r, specificities=specs,conf.level=pnorm(1)-pnorm(-1))
      curve[[i]][rownames(ciobj),fpNames[j]] = ciobj[,2]
      curveSE[[i]][rownames(ciobj),fpNames[j]] =  ciobj[, 3]/2-ciobj[, 1]/2
  
      a = ci.auc(r,method="bootstrap",conf.level=pnorm(1)-pnorm(-1))
      cut = ci.coords(r,x="best",method="bootstrap",conf.level=pnorm(1)-pnorm(-1),
                  ret=c("threshold","specificity","sensitivity","accuracy","youden","tn","tp","fn","fp"),best.policy="random")
      metrics[[i]][j,"auc"] = a[2]
      for (k in 1:length(cut)) metrics[[i]][j,names(cut)[k]] = cut[[k]][2]
      metricsSE[[i]][j,"auc"] = auc=a[3]/2-a[1]/2
      for (k in 1:length(cut)) metricsSE[[i]][j,names(cut)[k]] = cut[[k]][3]/2 - cut[[k]][1]/2
    }
    curve[[i]] = as.matrix(curve[[i]])
    curveSE[[i]] = as.matrix(curveSE[[i]])
    metrics[[i]] = as.matrix(metrics[[i]])
    metricsSE[[i]] = as.matrix(metricsSE[[i]])
  }
  
  fp4PredAccF = RubinMat(metrics,lse=metricsSE)
  fp4PredROCF = RubinMat(curve,lse=curveSE)
  if(save)
  {
    saveRDS(list(acc=fp4PredAccF,roc=fp4PredROCF),file)
  }
}
```

```{r}
g = list()
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g[[1]] = ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.7,.3))


vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata[,"variable"] = factor(plotdata[,"variable"],unique(plotdata[sort.list(plotdata[,"max_youden"],decreasing=T),"variable"]))
cols = gg_color_hue(length(levels(plotdata[,"variable"]))-1)
ind = which(levels(plotdata[,"variable"])=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g[[2]] = ggplot(plotdata,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable))+
  geom_line()+
  geom_point(data=plotdata[rep(c(T,rep(F,4)),length=nrow(plotdata)),])+
  geom_ribbon(alpha=.2)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_fill_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_colour_manual(breaks=levels(plotdata[,"variable"]),values = cols)+
  scale_x_reverse()+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.7,.3))

marrangeGrob(g,nrow=1,ncol=2,top=NULL)
```

```{r}
vars = colnames(fiPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fiPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fiPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)


plotdata0 = plotdata
plotdata2 = list(plotdata)

vars = colnames(fpPredROC[[1]])[-1]
plotdata = list()
for (j in 1:length(vars))
{
  plotdata[[j]] = as.data.frame(fpPredROC[[1]][,c(1,j+1)])
  colnames(plotdata[[j]])[2] = "sensitivity"
  #specificity is user-specific so has no error
  plotdata[[j]][,"sensitivity_se"] = fpPredROC[[2]][,j+1]
  plotdata[[j]][,"variable"] = vars[j]
  plotdata[[j]][,"max_youden"] = max(plotdata[[j]][,"sensitivity"]+plotdata[[j]][,"specificities"],na.rm=T)
}

plotdata = do.call(rbind,plotdata)

plotdata2[[2]] = plotdata
plotdata2[[1]][,"group"] = "FI"
plotdata2[[2]][,"group"] = "NFab5"

#avant guard idea: make symmetrical about x=y
#plotdata2[[2]][,"sensitivity"] = 1-plotdata2[[2]][,"sensitivity"]
#plotdata2[[2]][,"specificities"] = 1-plotdata2[[2]][,"specificities"]
plotdata2 = do.call(rbind,plotdata2)
fpNamesSorted = fpNames[c("FP","Slow gait","Low activity","Exhaustion","Weakness","Weight loss")]

cols = gg_color_hue(length(fpNamesSorted)-1)
ind = which(fpNamesSorted=="fp_frail_next")
if(ind > 1 & ind < length(cols))
{
  cols = c(cols[1:(ind-1)],"black",cols[ind:length(cols)])
} else if (ind == length(cols)) 
{
  cols = c(cols,"black")
} else cols = c("black",cols)

g = ggplot(plotdata2,aes(x=specificities,y=sensitivity,ymin=sensitivity-sensitivity_se,ymax=sensitivity+sensitivity_se,
                    colour=variable,fill=variable,shape=variable,linetype=group))+
  geom_line()+
  geom_point(data=plotdata2[rep(c(T,rep(F,4)),length=nrow(plotdata2)),],aes(alpha=group))+
  geom_ribbon(alpha=.2,col=NA)+
  geom_abline(slope=1,intercept=1,lty=3)+
  #annotate("label",x=.75,y=.75,label=sprintf("AUC: %.3f \U00B1 %.3f",fiPredAcc[[1]][varToUse,"auc"],fiPredAcc[[2]][varToUse,"auc"]))+
  scale_shape_manual(breaks=fpNamesSorted,values = 1:length(fpNamesSorted),labels=names(fpNamesSorted))+
  scale_fill_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_colour_manual(breaks=fpNamesSorted,values = cols,labels=names(fpNamesSorted))+
  scale_alpha_manual(breaks=c("FI","NFab5"),values=c(1,0))+
  scale_x_reverse()+
  labs(x="Specificity",y="Sensitivity")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.84,.38))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_roc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_roc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

### performance measures
```{r}
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAcc[[1]]),auc=fiPredAcc[[1]][,"auc"],auc_se=fiPredAcc[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAcc[[1]]),auc=fpPredAcc[[1]][,"auc"],auc_se=fpPredAcc[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAcc[[1]]),auc=fifpPredAcc[[1]][,"auc"],auc_se=fifpPredAcc[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAcc[[1]]),auc=fp4PredAcc[[1]][,"auc"],auc_se=fp4PredAcc[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"

plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5","NFab5","Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_point(position=position_dodge(.1),size=1)+
  #geom_errorbar(position=position_dodge(.1),size=1,width=0)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g



#############
#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAcc[[1]][inds,"auc"][1:2]),
      mean(fp4PredAcc[[1]][inds,"auc"][1:2]),
      mean(fifpPredAcc[[1]][inds,"auc"][1:2]),
      mean(fpPredAcc[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=F
textSize=8
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.875,.975) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(.75,1.5)
  ybox = c(.85,.95) #c(.725,.775)-0.05
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAcc[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) # c(3.5,4.25)
  ybox = c(.75,.85) #c(.82,.86)-0.05
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=bquote("Test 3.\nFI ~"~.(gFab5Name)),size=textSize)
  a2 = fiPredAcc[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAcc[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}

#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))


#add chronological age
#ageData = data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Age")
#g2 = g2 + geom_line(data=ageData,colour="black",fill=NA)
#g2 = g2 + geom_ribbon(data=ageData,colour=NA,fill="black",alpha=.15)

#fix font & legend
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position=c(.775,.8),legend.key.size = unit(2.5,"line"))
#g2 = g2 + guides(shape=guide_legend(ncol=2,byrow=FALSE))
g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(a) HRS")
  
g2

save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc.png",outputDir),g,width=10,height=8,dpi=300)
  

  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc_wline.pdf",outputDir),g2,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc_wline.png",outputDir),g2,width=10,height=8,dpi=300)
}
```



```{r}
# MALES
# MALES
# MALES
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAccM[[1]]),auc=fiPredAccM[[1]][,"auc"],auc_se=fiPredAccM[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAccM[[1]]),auc=fpPredAccM[[1]][,"auc"],auc_se=fpPredAccM[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAccM[[1]]),auc=fifpPredAccM[[1]][,"auc"],auc_se=fifpPredAccM[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAccM[[1]]),auc=fp4PredAccM[[1]][,"auc"],auc_se=fp4PredAccM[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAccM[[1]]),auc=agePredAccM[[1]][,"auc"],auc_se=agePredAccM[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"

#plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))
plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(fiPredAcc[[1]][,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5","NFab5","Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_point(position=position_dodge(.1),size=1)+
  #geom_errorbar(position=position_dodge(.1),size=1,width=0)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g



#############
#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAccM[[1]][inds,"auc"][1:2]),
      mean(fp4PredAccM[[1]][inds,"auc"][1:2]),
      mean(fifpPredAccM[[1]][inds,"auc"][1:2]),
      mean(fpPredAccM[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=F
textSize=7
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.875,.975) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fifpPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(.75,1.5)
  ybox = c(.85,.95) #c(.725,.775)-0.05
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAccM[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) # c(3.5,4.25)
  ybox = c(.75,.85) #c(.82,.86)-0.05
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=bquote("Test 3.\nFI ~"~.(gFab5Name)),size=textSize)
  a2 = fiPredAccM[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccM[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}

#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))


#add chronological age
#ageData = data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Age")
#g2 = g2 + geom_line(data=ageData,colour="black",fill=NA)
#g2 = g2 + geom_ribbon(data=ageData,colour=NA,fill="black",alpha=.15)

#fix font & legend
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position=c(.775,.8),legend.key.size = unit(2.5,"line"))
#g2 = g2 + guides(shape=guide_legend(ncol=2,byrow=FALSE))
g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(a) HRS - Males")
  
g2


gl = list(g2)

# FEMALES
# FEMALES
# FEMALES
# FEMALES
# FEMALES
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAccF[[1]]),auc=fiPredAccF[[1]][,"auc"],auc_se=fiPredAccF[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fpPredAccF[[1]]),auc=fpPredAccF[[1]][,"auc"],auc_se=fpPredAccF[[2]][,"auc"],group=gFab5Name)
plotdata[[3]] = data.frame(variable=rownames(fifpPredAccF[[1]]),auc=fifpPredAccF[[1]][,"auc"],auc_se=fifpPredAccF[[2]][,"auc"],group=sprintf("FI - including %s",gFab5NameNoN))
plotdata[[4]] = data.frame(variable=rownames(fp4PredAccF[[1]]),auc=fp4PredAccF[[1]][,"auc"],auc_se=fp4PredAccF[[2]][,"auc"],group=sprintf("%s - leave-one-out",gFab5Name))
plotdata[[5]] =  data.frame(variable=rownames(agePredAccF[[1]]),auc=agePredAccF[[1]][,"auc"],auc_se=agePredAccF[[2]][,"auc"],group="Chronological age")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

#relabel FP as FP frailty
plotdata[plotdata[,"name"]=="FP","name"] = "FP frailty"

#plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))
plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(fiPredAcc[[1]][,"auc"],decreasing=T),"name"]))

#plotdata[,"group"] = factor(plotdata[,"group"],c("FI",sprintf("%s - leave-one-out",gFab5Name),"FI - including fab-5","NFab5","Chronological age"))
#cols= c(gg_color_hue(2),gg_color_hue(4)[c(2,4)],"grey40")
plotdata[,"group"] = factor(plotdata[,"group"],c(sprintf("FI - including %s",gFab5NameNoN),"FI",gFab5Name,sprintf("%s - leave-one-out",gFab5Name),"Chronological age"))
cols= c(gg_color_hue(4)[2],gg_color_hue(2)[1],gg_color_hue(4)[4],gg_color_hue(2)[2],"grey40")

#shapes = 14 + 1:length(cols)
#shapes[shapes==19] = 25 #looks like 16 #25: big upsidedown triangle #3: cross #4: x #8: star
#shapes = c(17,15,25,16,18)
shapes = c(25,17,16,15,18)
#alphas = c(rep(1,4),.5)

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group,fill=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_point(position=position_dodge(.1),size=1)+
  #geom_errorbar(position=position_dodge(.1),size=1,width=0)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  scale_shape_manual(values=shapes)+
  scale_colour_manual(values=cols)+
  scale_fill_manual(values=cols)+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g



#############
#with line - easier to compare
#could add labels...
g2 = g + geom_line(data=plotdata,aes(x=as.numeric(name),linetype=group),size=1) #
g2 = g2 + geom_ribbon(data=plotdata,aes(x=as.numeric(name)),alpha=.15,colour=NA) #,linetype=group
inds = sort.list(-fiPredAcc[[1]][,"auc"])
library(ggrepel)
labelLines = F
if(labelLines)
{
  #y position should be average between first two points
  y = c(mean(fiPredAccF[[1]][inds,"auc"][1:2]),
      mean(fp4PredAccF[[1]][inds,"auc"][1:2]),
      mean(fifpPredAccF[[1]][inds,"auc"][1:2]),
      mean(fpPredAccF[[1]][inds,"auc"][1:2])
  )
  labeldata = data.frame(x = c(1.5,1.5,2.5,2.5),
                       y = y, 
                       l = c("FI","NFab5","FI v2","NFab5 v2"),
                       group = levels(plotdata[,"group"])
                       )
  g2 = g2 + geom_text_repel(data=labeldata,aes(x=x,y=y,label=l,colour=group),inherit.aes=F) 
}

labelComparison=T
textSize=7
if(labelComparison)
{
  #Test 1. annotate FI > NFab5 (full predict)
  xbox = c(.6,2.1) # c(2.5,3.25)
  ybox = c(.9,1) #c(.875,.925)-0.05
  xend = mean(xbox) #1.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 1.\nFI > %s",gFab5Name),size=textSize)
  a2 = fifpPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.01,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2+.035,xend=xend,y=a2,yend = yend) #to NFab5

  #Test 2. annotate FI > NFab5 (leave one out)
  xbox = c(2.25,3.75) #c(.75,1.5)
  ybox = c(.85,.95) #c(.725,.775)-0.05
  xend = mean(xbox) # 2.5
  yend = min(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 2.\nFI > %s",gFab5Name),size=textSize)
  a2 = fiPredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fp4PredAccF[[1]][inds,"auc"][2]
  g2 = g2 + annotate("segment",x=2-.01,xend=xend,y=a2,yend = yend) #to NFab5
    
  #Test 3. annotate FI ~= NFab5 (full vs left out)
  xbox = c(4,5.6) # c(3.5,4.25)
  ybox = c(.75,.85) #c(.82,.86)-0.05
  xend = min(xbox) #3.5
  yend = mean(ybox)
  g2 = g2 + annotate("rect",xmin=xbox[1],xmax=xbox[2],ymin=ybox[1],ymax=ybox[2],fill="white",colour="gray90")
  #g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label="FI > NFab5")
  g2 = g2 + annotate("text",x=mean(xbox),y=mean(ybox),label=sprintf("Test 3.\nFI ~ %s",gFab5Name),size=textSize)
  a2 = fiPredAccF[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3-.035,xend=xend,y=a2,yend = yend)  #to FI
  a2 = fpPredAccF[[1]][inds,"auc"][3]
  g2 = g2 + annotate("segment",x=3+.035,xend=xend,y=a2,yend = yend) #to NFab5
}

#annotate the "guess" line
g2 = g2 + geom_hline(yintercept=.5,lty=3,size=1) #guess line
#g2 = g2 + annotate("text",x=1.5,y=.52,label="Guess",size=textSize)

#standardize y-axis
g2 = g2 + scale_y_continuous(limits=c(0.45,1),breaks=seq(.5,1,by=.1))


#add chronological age
#ageData = data.frame(variable=rownames(agePredAcc[[1]]),auc=agePredAcc[[1]][,"auc"],auc_se=agePredAcc[[2]][,"auc"],group="Age")
#g2 = g2 + geom_line(data=ageData,colour="black",fill=NA)
#g2 = g2 + geom_ribbon(data=ageData,colour=NA,fill="black",alpha=.15)

#fix font & legend
g2 = g2 + theme(text=element_text(size=gTextSize),legend.background = element_rect(fill="white",colour="white"),legend.position=c(.775,.8),legend.key.size = unit(2.5,"line"))
#g2 = g2 + guides(shape=guide_legend(ncol=2,byrow=FALSE))
g2 = g2 + theme(axis.text.x=element_text(size=18,angle=0),axis.text.y=element_text(size=18,angle=0),axis.title.y=element_text(size=20,angle=90,hjust=.54))


#add title
g2 = g2 + ggtitle("(b) HRS - Female")
  
g2

save = T
if(save)
{

  
  gl[[2]] = g2+ggtitle("(b) HRS - Females")
  gl[[1]] = gl[[1]]+ggtitle("(a) HRS - Males")
  #for (i in 1:length(gl)) gl[[i]] = gl[[i]] + scale_y_continuous(limits=c(.39,1))
  gl[[2]] = gl[[2]]+theme(legend.position="none")

    #fix font
  for (i in 1:length(gl)) gl[[i]] = gl[[i]] + theme(axis.text.x=element_text(size=16,angle=0),axis.text.y=element_text(size=16,angle=0),axis.title.y=element_text(size=18,angle=90,hjust=.54))

  gl[[1]] = gl[[1]] + guides(shape=guide_legend(ncol=2,byrow=FALSE))+theme(legend.position=c(.6,.875))
  
    ggsave(sprintf("%s/results/fi_vs_fp_hrs_sex_auc_wline.pdf",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=6,dpi=300)
    ggsave(sprintf("%s/results/fi_vs_fp_hrs_sex_auc_wline.png",outputDir),marrangeGrob(gl,nrow=1,ncol=2,top=NULL),width=16,height=6,dpi=300)
}
```

```{r}
plotdata =  list()
plotdata[[1]] =  data.frame(variable=rownames(fifpPredAcc[[1]]),auc=fifpPredAcc[[1]][,"auc"],auc_se=fifpPredAcc[[2]][,"auc"],group="FI - including fab-5")
plotdata[[2]] = data.frame(variable=rownames(fpPredAcc[[1]]),auc=fpPredAcc[[1]][,"auc"],auc_se=fpPredAcc[[2]][,"auc"],group="NFab5")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))

g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc1.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc1.png",outputDir),g,width=10,height=8,dpi=300)
}
```

```{r}
plotdata =  list()
plotdata[[1]] = data.frame(variable=rownames(fiPredAcc[[1]]),auc=fiPredAcc[[1]][,"auc"],auc_se=fiPredAcc[[2]][,"auc"],group="FI")
plotdata[[2]] = data.frame(variable=rownames(fp4PredAcc[[1]]),auc=fp4PredAcc[[1]][,"auc"],auc_se=fp4PredAcc[[2]][,"auc"],group="NFab5 - leave-one-out")
plotdata = do.call(rbind,plotdata)

plotdata[,"name"] = "x"
for (i in 1:length(fpNames))
{
  plotdata[plotdata[,"variable"]==fpNames[i],"name"] = names(fpNames)[i]
}

plotdata[,"name"] = factor(plotdata[,"name"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"name"]))


g = ggplot(plotdata,aes(x=name,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,
                    colour=group,shape=group))+
  geom_pointrange(position=position_dodge(.1),size=1)+
  #geom_hline(yintercept=.5,lty=3)+
  scale_y_continuous(limits=c(.5,1))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(text=element_text(size=gTextSize),
        #axis.text.x = element_text(size=gAxisTextSize),
        #axis.text.y=element_text(size=gAxisTextSize),
        legend.title=element_blank(),
        legend.box.background = element_rect(fill = "white",colour="gray"),
        legend.position=c(.8,.8))
g
```

```{r}
save = T
if(save)
{
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc2.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/fi_vs_fp_hrs_auc2.png",outputDir),g,width=10,height=8,dpi=300)
}
```

### Multi-roc
```{r}
file = sprintf("%s/data/fi_multiroc_hrs.rds",outputDir)

load=T
save=T
nboot=2000
if(file.exists(file) & load)
{
  print("file found, loading...")
  rocFit = readRDS(file)
  predROCFI = rocFit[["pr"]]
  cutsFI = rocFit[["cuts"]]
} else
{
  pred = list()
  predLow = list()
  predHigh = list()
  predSE = list()
  cuts = list()
  cutsSE = list()
  for (i in 1:length(data))
  {
    rocFit = OrdinalROC(y=data[[i]][,"Nfp_next_ord"],x=data[[i]][,"fi"],best.policy="random",nboot=nboot,direction="<")
    pr = predict.OrdinalROC(rocFit,x=seq(0,1,length=101),fast=F,CI=pnorm(c(-1,1)))
    pred[[i]] = as.matrix(pr[,c("x","ymed")])
    predLow[[i]] = as.matrix(pr[,c("x","ylow")])
    predHigh[[i]] = as.matrix(pr[,c("x","yhigh")])
    predSE[[i]] = matrix(0,nrow=nrow(pr),ncol=2)
    predSE[[i]][,2] = pr[,"yhigh"]/2-pr[,"ylow"]/2
    colnames(predSE[[i]]) = colnames(pred[[i]])
    cuts[[i]] = apply(rocFit$cuts,2,median,na.rm=T)
    cuts[[i]] = matrix(cuts[[i]],nrow=1,ncol=length(cuts[[i]]))
    colnames(cuts[[i]]) = sprintf("%d",1:5)
    cutsSE[[i]] = apply(rocFit$cuts,2,quantile,probs=pnorm(1),na.rm=T)/2 - apply(rocFit$cuts,2,quantile,probs=pnorm(-1),na.rm=T)/2    
    cutsSE[[i]] = matrix(cutsSE[[i]],nrow=1,ncol=length(cutsSE[[i]]))
    colnames(cutsSE[[i]]) = sprintf("%d",1:5)
  }
  predROCFI = RubinMat(pred,lse=predSE)
  predROCFILow = RubinMat(predLow)
  predROCFIHigh = RubinMat(predHigh)
  for (i in 1:2) predROCFI[[i]] = data.frame(predROCFI[[i]])
  for (i in 1:2) predROCFI[[i]][,"ylow"] = predROCFILow[[i]][,"ylow"]
  for (i in 1:2) predROCFI[[i]][,"yhigh"] = predROCFIHigh[[i]][,"yhigh"]
  cutsFI = RubinMat(cuts,lse=cutsSE)
  
  if(save) saveRDS(list(cuts=cutsFI,pr=predROCFI,prhigh=predROCFIHigh,prlow=predROCFILow),file)
}
```

```{r}
file = sprintf("%s/data/fp_multiroc_hrs.rds",outputDir)

load=T
save=T
nboot=2000
if(file.exists(file) & load)
{
  print("file found, loading...")
  rocFit = readRDS(file)
  predROCFP = rocFit[["pr"]]
  cutsFP = rocFit[["cuts"]]
} else
{
  pred = list()
  predLow = list()
  predHigh = list()
  predSE = list()
  cuts = list()
  cutsSE = list()
  for (i in 1:length(data))
  {
    rocFit = OrdinalROC(y=data[[i]][,"Nfp_next_ord"],x=data[[i]][,"Nfp"],best.policy="random",nboot=nboot,direction="<")
    pr = predict.OrdinalROC(rocFit,x=seq(0,5,length=101),fast=F,CI=pnorm(c(-1,1)))
    pred[[i]] = as.matrix(pr[,c("x","ymed")])
    predLow[[i]] = as.matrix(pr[,c("x","ylow")])
    predHigh[[i]] = as.matrix(pr[,c("x","yhigh")])
    predSE[[i]] = matrix(0,nrow=nrow(pr),ncol=2)
    predSE[[i]][,2] = pr[,"yhigh"]/2-pr[,"ylow"]/2
    colnames(predSE[[i]]) = colnames(pred[[i]])
    cuts[[i]] = apply(rocFit$cuts,2,median,na.rm=T)
    cuts[[i]] = matrix(cuts[[i]],nrow=1,ncol=length(cuts[[i]]))
    colnames(cuts[[i]]) = sprintf("%d",1:5)
    cutsSE[[i]] = apply(rocFit$cuts,2,quantile,probs=pnorm(1),na.rm=T)/2 - apply(rocFit$cuts,2,quantile,probs=pnorm(-1),na.rm=T)/2    
    cutsSE[[i]] = matrix(cutsSE[[i]],nrow=1,ncol=length(cutsSE[[i]]))
    colnames(cutsSE[[i]]) = sprintf("%d",1:5)
  }
  predROCFP = RubinMat(pred,lse=predSE)
  predROCFPLow = RubinMat(predLow)
  predROCFPHigh = RubinMat(predHigh)
  for (i in 1:2) predROCFP[[i]] = data.frame(predROCFP[[i]])
  for (i in 1:2) predROCFP[[i]][,"ylow"] = predROCFPLow[[i]][,"ylow"]
  for (i in 1:2) predROCFP[[i]][,"yhigh"] = predROCFPHigh[[i]][,"yhigh"]
  cutsFP = RubinMat(cuts,lse=cutsSE)
  
  if(save) saveRDS(list(cuts=cutsFP,pr=predROCFP,prhigh=predROCFPHigh,prlow=predROCFPLow),file)
}
```

```{r}
plotdata = list()
plotdata[[1]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[1]][,"y"] = fifpNextData[[1]][,"fi_mean"]
plotdata[[1]][,"se"] = fifpNextData[[2]][,"fi_mean"]
plotdata[[1]][,"weights"] = 1/plotdata[[1]][,"se"]^2
plotdata[[1]][,"model"] = "FI"
plotdata[[2]] = data.frame(fifpNextData[[1]][,"Nfp_next",drop=F])
plotdata[[2]][,"y"] = fifpNextData[[1]][,"Nfp_mean"]/5
plotdata[[2]][,"se"] = fifpNextData[[2]][,"Nfp_mean"]/5
plotdata[[2]][,"weights"] = 1/plotdata[[2]][,"se"]^2
plotdata[[2]][,"model"] = "NFab5"
plotdata = do.call(rbind,plotdata)

rocPlotDataFI = data.frame(x=predROCFI[[1]][,"x"],y=predROCFI[[1]][,"ymed"],se=predROCFI[[2]][,"ymed"],
                      ymin=predROCFI[[1]][,"ylow"],ymax=predROCFI[[1]][,"yhigh"],model="FI"
                      )
rocPlotDataFP = data.frame(x=predROCFP[[1]][,"x"]/5,y=predROCFP[[1]][,"ymed"],se=predROCFP[[2]][,"ymed"],
                      ymin=predROCFP[[1]][,"ylow"],ymax=predROCFP[[1]][,"yhigh"],model="NFab5"
                      )
rocPlotData = rbind(rocPlotDataFI,rocPlotDataFP)
#fix boundaries
#Rubin's rules take symmetrical errors
  #could just pass upper/lower to Rubin...
#plotdata[,"ymin"] = plotdata[,"y"] - plotdata[,"se"]
#plotdata[plotdata[,"ymin"] < 0,"ymin"] = 0
#plotdata[,"ymin"] = plotdata[,"y"] + plotdata[,"se"]
#plotdata[plotdata[,"ymin"] >5,"ymin"] = 5
cols = gg_color_hue(2)
g = ggplot(plotdata,aes(x=y,y=Nfp_next,xmin=y-se,xmax=y+se,colour=model))+
  geom_pointrange()+
  geom_line(data=rocPlotData,inherit.aes=F,mapping=aes(x=x,y=y,ymin=ymin,ymax=ymax,colour=model))+
  geom_ribbon(data=rocPlotData,inherit.aes=F,mapping=aes(x=x,y=y,ymin=ymin,ymax=ymax,fill=model),alpha=.2)+
  scale_x_continuous(sec.axis=sec_axis(~ . * 5, name = "Number of fab-5 deficits (NFab5)",breaks=0:5))+
  labs(x="FI",y="Number of fab-5 deficits at followup")+
  theme_minimal()+
  theme(legend.title=element_blank(),
        legend.position=c(.8,.2),
        axis.line.x = element_line(color = cols[1]), 
       axis.ticks.x = element_line(color = cols[1]),
        axis.line.x.top = element_line(color = cols[2]), 
       axis.ticks.x.top = element_line(color = cols[2]))

g
```

################
# Predicting FUTURE fab-5 deficits and FP using logistic regression
################
Note: calc requires repeats > 1 otherwise it'll crash with a "Error in dn[[2L]] : subscript out of bounds"
```{r}
Nreps = 10
Nfolds = 10
mc.cores = 1
print(fpNames)
outTypes = rep("binary",length(fpNames))
names(outTypes) = fpNames
gLoad=T
gSave=T
```
```{r}
fits = list()
```

```{r}
baseName = "hrs_age_sex_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$age_sex = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$age_sex = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```


```{r}
baseName = "hrs_barefi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$barefi = readRDS(file)
} else
{
  dataTypes = c(fi="continuous",fi="continuous") #trick to get it to run without error
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes),drop=F],outcomes=data[[i]][,names(outTypes),drop=F])
  fits$barefi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "hrs_fi_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$fi = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "hrs_fifp_calc" #uses fifp i.e. fi including FP deficits
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fifp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fifp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$fifp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "hrs_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "hrs_onehot_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$onehotNfp = readRDS(file)
} else
{
  subdata = OneHotVecOrdinal(data[[1]][,"Nfp_ord"],rootname="Nfp")
  NfpTypes = rep("binary",ncol(subdata))
  names(NfpTypes) = colnames(subdata)
  dataTypes = c(age="continuous",sex="binary",NfpTypes)
  reshapedData = list()
  for (i in 1:length(data)) 
  {
    subdata = OneHotVecOrdinal(data[[i]][,"Nfp_ord"],rootname="Nfp")
    subdata = data.frame(data[[i]][,setdiff(names(dataTypes),colnames(subdata))],subdata)
    reshapedData[[i]] = list(data=subdata[,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  }
  fits$onehotNfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "hrs_fi_Nfp_calc"

file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi_Nfp = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])

  fits$fi_Nfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "hrs_fi_onehot_Nfp_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$fi_onehotNfp = readRDS(file)
} else
{
  subdata = OneHotVecOrdinal(data[[1]][,"Nfp_ord"],rootname="Nfp")
  NfpTypes = rep("binary",ncol(subdata))
  names(NfpTypes) = colnames(subdata)
  dataTypes = c(age="continuous",sex="binary",fi="continuous",NfpTypes)
  reshapedData = list()
  for (i in 1:length(data)) 
  {
    subdata = OneHotVecOrdinal(data[[i]][,"Nfp_ord"],rootname="Nfp")
    subdata = data.frame(data[[i]][,setdiff(names(dataTypes),colnames(subdata))],subdata)
    reshapedData[[i]] = list(data=subdata[,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  }
  fits$fi_onehotNfp = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
baseName = "hrs_fi_Nfp_fpvar_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$all = readRDS(file)
} else
{
  fpTypes = rep("binary",length(fpVar))
  names(fpTypes)=fpVar
  dataTypes = c(age="continuous",sex="binary",fi="continuous",Nfp="continuous")
  dataTypes = c(dataTypes,fpTypes)
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])

  fits$all = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}
```

```{r}
scores = list()
for (i in 1:length(fits))
{
  scores[[i]] = fits[[i]]$score
  scores[[i]][,sprintf("%s_se",colnames(fits[[i]]$scoreSE))] = fits[[i]]$scoreSE
  scores[[i]][,"outcome"] = rownames(fits[[i]]$score)
  scores[[i]][,"model"] = names(fits)[i]
}
scores = do.call(rbind,scores)

scores[,"clean_name"] = gsub("age_sex","Covariates only (age and sex)",scores[,"model"])
scores[,"clean_name"] = gsub("all","All predictors",scores[,"clean_name"])
scores[,"clean_name"] = gsub("fi_Nfp","FI and NFab5",scores[,"clean_name"])
scores[scores[,"model"]=="fi_onehotNfp","clean_name"] = "FI and NFab5 (onehot encoded)"
scores[scores[,"model"]=="fi","clean_name"] = "FI"
scores[scores[,"model"]=="Nfp","clean_name"] = "NFab5"
scores[scores[,"model"]=="fifp","clean_name"] = "FI - including fab-5 varibles"
```

```{r}
plotdata = subset(scores,model%in%c("fi","Nfp","all","fi_Nfp","fifp","age_sex"))
plotdata[,"outcome"] = factor(plotdata[,"outcome"],unique(plotdata[sort.list(plotdata[,"auc"],decreasing=T),"outcome"]))
g = ggplot(plotdata,aes(x=outcome,y=auc,ymin=auc-auc_se,ymax=auc+auc_se,colour=clean_name,shape=clean_name))+
  geom_pointrange(position=position_dodge(.2))+
  labs(x="",y="AUC")+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```
```{r}
save=T
if(save)
{
  ggsave(sprintf("%s/results/hrs_glm_auc.pdf",outputDir),g,width=10,height=8,dpi=300)
  ggsave(sprintf("%s/results/hrs_glm_auc.png",outputDir),g,width=10,height=8,dpi=300)
}
```

make a table
should add survival too; maybe make its own table
```{r}
bestFit = fits[["fi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/hrs_glm.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/hrs_glm_v2.csv",outputDir),row.names=FALSE)
```

```{r}
bestFit = fits[["barefi"]]
sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
#sc = c(AUC="auc", Accuracy="acc")
C = bestFit$score[,sc]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    s = 100
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/hrs_glm_bare.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/hrs_glm_bare_v2.csv",outputDir),row.names=FALSE)
```

what if we use everything we know about the current health state? kitchen skin model
```{r}
baseName = "hrs_fi_fab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$sink = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",fi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$sink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "hrs_fi_barefab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$baresink = readRDS(file)
} else
{
  dataTypes = c(fi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$baresink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

```{r}
baseName = "hrs_barefab5_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$barefab5 = readRDS(file)
} else
{
  dataTypes = c(fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$barefab5 = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

sqrt better fits the linearity assumption but... really not practical for clinical use etc
```{r}
for (i in 1:length(data)) data[[i]][,"sqrtfi"] = sqrt(data[[i]][,"fi"])
baseName = "hrs_fi_fab5_sqrt_calc"
file = sprintf("%s/data/%s_glm_nonedimred_10x10x10x10cv_calc.rds",outputDir,baseName)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  fits$sqrtsink = readRDS(file)
} else
{
  dataTypes = c(age="continuous",sex="binary",sqrtfi="continuous",fp1_weight="binary",
                fp2_grip="binary", fp3_gait="binary", fp4_exhaustion="binary", fp5_low_activity="binary")
  reshapedData = list()
  for (i in 1:length(data)) reshapedData[[i]] = list(data=data[[i]][,names(dataTypes)],outcomes=data[[i]][,names(outTypes)])
  fits$sqrtsink = Calc.mi(reshapedData,outcomeType=outTypes,dataType=dataTypes,dataCols=names(dataTypes),
              outputCols=names(outTypes),useCond=F,useSurvival=F,save=save,
              saveRoot = sprintf("%s/data", outputDir), baseName=baseName,
               featureSelection =  F, 
              mc.cores=mc.cores,folds=Nfolds,repeats=Nreps)
}

```

kitchen sink tileplot
qualitative structure seems more important than quantitative
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()
Clow = list()
Chigh =  list()
for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  Clow[[k]] = C[[k]]
  Chigh[[k]] = C[[k]]
  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s)
        Clow[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s-errorScale*subFitSE[jj,"Coef"]/s)
        Chigh[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = exp(subFit[jj,"Coef"]/s+errorScale*subFitSE[jj,"Coef"]/s)
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"])
        Clow[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]-errorScale*subFitSE[jj,"Coef"])
        Chigh[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = exp(subFit[jj,"Coef"]+errorScale*subFitSE[jj,"Coef"])
      }
    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
  Clow[[k]][,setdiff(vars,colnames(Clow[[k]]))] = NA
  Chigh[[k]][,setdiff(vars,colnames(Chigh[[k]]))] = NA
}
C = do.call(rbind,C)
Clow = do.call(rbind,Clow)
Chigh = do.call(rbind,Chigh)
Clow = Clow[sort.list(C[,"sort_column"]),]
Chigh = Chigh[sort.list(C[,"sort_column"]),]
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]
Clow = C[,setdiff(colnames(Clow),"sort_column")]
Chigh = Chigh[,setdiff(colnames(Chigh),"sort_column")]
#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]
  Clow = C[,setdiff(colnames(Clow),"fi.1")]
  Chigh = Chigh[,setdiff(colnames(Chigh),"fi.1")]
}


#sort columns
ord = rev(c(2:4,5:ncol(C),1))
C = C[,ord]
Clow = Clow[,ord]
Chigh = Chigh[,ord]


#cover ugly x:
#Clow[is.na(C)] = 1-1/10^6
#Chigh[is.na(C)] = 1+1/10^6
#C[is.na(C)] = 1

#scale
vars = setdiff(colnames(C),"auc")
C[,vars] = log(C[,vars],10)
Clow[,vars] = log(Clow[,vars],10)
Chigh[,vars] = log(Chigh[,vars],10)

g = TilePlot(C,mcilow=Clow,mcihigh=Chigh,na.value="white",pointSize=8,dropNonSig = F)
#fix labels
nms = colnames(C)
nms = gsub("auc","AUC",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
for (j in 1:length(fpVar)) nms = gsub(fpVar[j],names(fpVar)[j],nms,fixed=T)
g = g + scale_y_discrete(breaks=colnames(C),labels=nms)
nms = rownames(C)
for (j in 1:2) nms = gsub(sprintf("next%d",j),"next",nms)
for (j in 1:length(fpVar)) nms = gsub(sprintf("%s_next",fpVar[j]),names(fpVar)[j],nms,fixed=T)
nms = gsub(sprintf("fp_frail_next"),"FP frailty",nms,fixed=T)
nms = sprintf("%d. %s",rep(1:3,times=length(nms)/3),nms)
g = g + scale_x_discrete(breaks=rownames(C),labels=nms)
#fix scale
g = g + scale_colour_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0, limit = c(-.3,1.3),
                               name="Odds Ratio", na.value="white",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=c("0.5","1","2","5","10"))
g = g + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0, limit =  c(-.3,1.3),
                               name="Odds Ratio", na.value="white",breaks=c(-.3,0,log(2,10),log(5,10),1),labels=c("0.5","1","2","5","10"))
g = g + theme(legend.title=element_text())
g = g + theme(text=element_text(size=gTextSize))

#fix font
g = g + theme(axis.text.x=element_text(size=18,angle=90),axis.text.y=element_text(size=18,angle=0))

#add x/y labels
g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=20),axis.title.y=element_text(size=20,angle=90))
#g = g +labs(x="Followup",y="Current") + theme(axis.title.x=element_text(size=16))

#add title
g = g + ggtitle("(a) HRS") + theme(title =element_text(size=gTextSize))

#scale up key
g = g + theme(legend.key.width = unit(4,"line"))

#clean up background
g = g + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
g = g + theme(panel.background = element_rect(fill = 'grey90',colour=NA))

#separate AUC
g = g + geom_rect(xmin=-2.1,xmax=18.5,ymin=.5,ymax=1.5,color="grey40",fill=NA,size=1,lty=1)+ coord_cartesian(clip = 'off') 
#g = g + geom_segment(x=-2,xend=18.5,y=1.5,yend=1.5,color="grey",fill=NA,size=1)+ coord_cartesian(clip = 'off') 

#add second legend for AUC
#strategy: make a second plot and stick it below current plot
library(cowplot)
#g2 =  TilePlot(log(C[,"auc",drop=F],10),mcilow=log(Clow[,"auc",drop=F],10),mcihigh=log(Chigh[,"auc",drop=F],10),na.value="grey90",pointSize=8,dropNonSig = T)
g2 =  TilePlot(C[,"auc",drop=F],mcilow=Clow[,"auc",drop=F],mcihigh=Chigh[,"auc",drop=F],na.value="grey90",pointSize=8,dropNonSig = T)
g2 = g2 + scale_colour_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0.5, limit = c(0.5,1),
                               name="AUC", na.value="white")
g2 = g2 + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                               space = "Lab", midpoint = 0.5, limit = c(0.5,1),
                               name="AUC", na.value="white")
g2 = g2 + theme(legend.title=element_text()) + theme(text=element_text(size=gTextSize))+ theme(legend.key.width = unit(4,"line"))

#3 plots now
layout = matrix(1,2,2)
layout[1,] = 1
#layout[2,] = 2:3

g3 = ggdraw(cowplot::get_legend(g))
g = g +theme(legend.position="none")

gl = list(g,ggdraw(cowplot::get_legend(g2)),g3)




g
save=T
if(save)
{
  #ggsave(sprintf("%s/results/fp_next_tileplot_hrs.pdf",outputDir),g,width=12,height=8,dpi=300)
  #ggsave(sprintf("%s/results/fp_next_tileplot_hrs.png",outputDir),g,width=12,height=8,dpi=300)
  
  #temp: for combining with ELSA
  layout[2,] = 2
  gl = gl[c(1,3)]

  
  ggsave(sprintf("%s/results/fp_next_tileplot_hrs.pdf",outputDir),marrangeGrob(gl,nrow=2,ncol=2,layout_matrix=layout,top=NULL,heights=c(.9,.1)),width=12,height=8,dpi=300)
  ggsave(sprintf("%s/results/fp_next_tileplot_hrs.png",outputDir),marrangeGrob(gl,nrow=2,ncol=2,layout_matrix=layout,top=NULL,heights=c(.9,.1)),width=12,height=8,dpi=300)
}
```

tabular form
```{r}
theseFits = fits[c("barefi","fi","sink")]
errorScale = qnorm(.975)
sc= c(AUC="auc")
C = list()

for (k in 1:length(theseFits))
{
  C[[k]] = theseFits[[k]][["score"]][,sc,drop=F]
  for (j in 1:length(sc)) C[[k]][,sc[j]] = sprintf("$%.3f_{%.3f}^{%.3f}$",theseFits[[k]][["score"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]-qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]],theseFits[[k]][["score"]][,sc[j]]+qnorm(.975)*theseFits[[k]][["scoreSE"]][,sc[j]])

  for (j in 1:nrow(C[[k]]))
  {
    logi = theseFits[[k]][["importance"]][,"Outcome"] == rownames(C[[k]])[j]
    subFit = theseFits[[k]][["importance"]][logi,]
    subFitSE = theseFits[[k]][["importanceSE"]][logi,]
  
    for(jj in 1:nrow(subFit))
    {
      
          #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
      if("fi"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 10
        C[[k]][j,sprintf("%s per %.2f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else if("age"%in%tolower(subFit[jj,"Feature"])) 
      {
        s = 0.1
        C[[k]][j,sprintf("%s per %.0f",subFit[jj,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]/s),exp(subFit[jj,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[jj,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      }
      else #standard case
      {
        C[[k]][j,sprintf("%s",subFit[jj,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[jj,"Coef"]),exp(subFit[jj,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[jj,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      }

    }
  }
  C[[k]][,"sort_column"] = sprintf("%02d_%02d",1:nrow(C[[k]]),k)
}
#make sure everybody has same columns
vars = colnames(C[[length(C)]])
for (k in 1:length(C)) vars = c(vars,colnames(C[[k]]))
vars = unique(vars)
for (k in 1:length(C))
{
  C[[k]][,setdiff(vars,colnames(C[[k]]))] = NA
}
C = do.call(rbind,C)
C = C[sort.list(C[,"sort_column"]),]
#drop sort column
C = C[,setdiff(colnames(C),"sort_column")]

#drop OR
colnames(C) = gsub(" OR","",colnames(C))
#clean up names
nms = colnames(C)
nms = gsub("auc","AUC",nms)
nms = gsub("sex","Female",nms)
nms = gsub("age","Age",nms)
nms = gsub("fi per 0.10","FI per 0.1",nms)
for (j in 1:length(fpVar)) nms = gsub(fpVar[j],names(fpVar)[j],nms,fixed=T)
colnames(C) = nms

#drop weird extra column from barefi
if("fi.1"%in%colnames(C)) 
{
  C = C[,setdiff(colnames(C),"fi.1")]

}

#add outcome column
C[,"Outcome"] = rownames(C)
C[grep("frail",C[,"Outcome"] ),"Outcome"]      = "FP frailty"
C[grep("weight",C[,"Outcome"] ),"Outcome"]     = "Weight loss"
C[grep("grip",C[,"Outcome"] ),"Outcome"]       = "Weakness"
C[grep("gait",C[,"Outcome"] ),"Outcome"]       = "Slow gait"
C[grep("exhaustion",C[,"Outcome"] ),"Outcome"] = "Exhaustion"
C[grep("activity",C[,"Outcome"] ),"Outcome"]   = "Low activity"

#sort columns
ord = c("Outcome",setdiff(colnames(C),"Outcome"))
C = C[,ord]

#drop NAs
C[is.na(C)] = ""


write.csv(C,sprintf("%s/results/fp_next_hrs.csv",outputDir),row.names=FALSE)
```



kitchen sink model
```{r}
bestFit = fits[["sink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 10
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else if("age"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 0.1
      C[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/hrs_glm_sink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/hrs_glm_sink_v2.csv",outputDir),row.names=FALSE)
C0 = C
C20 = C2
```

```{r}
bestFit = fits[["baresink"]]
#sc = c(AUC="auc",Sensitivity="sensitivity",Specificity="specificity") #Accuracy="acc",
sc = c(AUC="auc")
C = bestFit$score[,sc,drop=F]
C2 = C #different encoding
#for (j in 1:length(sc)) C[,j] = sprintf("%.3f pm %.3f",bestFit$score[,sc[j]],bestFit$scoreSE[,sc[j]])
for (j in 1:length(sc)) C[,j] = sprintf("%.2f (%.2f-%.2f)",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C)=names(sc)
for (j in 1:length(sc)) C2[,j] = sprintf("$%.2f_{%.2f}^{%.2f}$",bestFit$score[,sc[j]],bestFit$score[,sc[j]]-qnorm(.975)*bestFit$scoreSE[,sc[j]],bestFit$score[,sc[j]]+qnorm(.975)*bestFit$scoreSE[,sc[j]])
colnames(C2)=names(sc)
#add coefficients and/or odds ratios
for (j in 1:nrow(C))
{
  logi = bestFit[["importance"]][,"Outcome"] == rownames(C)[j]
  subFit = bestFit[["importance"]][logi,]
  subFitSE = bestFit[["importanceSE"]][logi,]
  for (k in 1:nrow(subFit))
  {

    #special case for FI - scale to per 0.01 #Kojima meta analysis says 0.01 normal
    
    if("fi"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 10
      C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #s = 10
      #C[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      #C2[j,sprintf("%s per %.2f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else if("age"%in%tolower(subFit[k,"Feature"])) 
    {
      s = 0.1
      C[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
      C2[j,sprintf("%s per %.0f OR",subFit[k,"Feature"],1/s)] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]/s),exp(subFit[k,"Coef"]/s-subFitSE[k,"Coef"]/s),exp(subFit[k,"Coef"]/s+qnorm(.975)*subFitSE[k,"Coef"]/s))
    }
    else #standard case
    {
      #C[j,sprintf("%s coef",subFit[k,"Feature"])] = sprintf("%.3f pm %.3f",subFit[k,"Coef"],subFitSE[k,"Coef"])
      C[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("%.2f (%.2f-%.2f)",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
      C2[j,sprintf("%s OR",subFit[k,"Feature"])] = sprintf("$%.2f_{%.2f}^{%.2f}$",exp(subFit[k,"Coef"]),exp(subFit[k,"Coef"]-subFitSE[k,"Coef"]),exp(subFit[k,"Coef"]+qnorm(.975)*subFitSE[k,"Coef"]))
    }

  }

}
C[,"Outcome"] = rownames(C)
for (i in 1:nrow(C)) C[i,"Outcome"] = strsplit(C[i,"Outcome"],"_")[[1]][[2]]
C = C[,c("Outcome",setdiff(colnames(C),"Outcome"))]

C2[,"Outcome"] = rownames(C2)
for (i in 1:nrow(C2)) C2[i,"Outcome"] = strsplit(C2[i,"Outcome"],"_")[[1]][[2]]
C2 = C2[,c("Outcome",setdiff(colnames(C2),"Outcome"))]

write.csv(C,sprintf("%s/results/hrs_glm_baresink.csv",outputDir),row.names=FALSE)
write.csv(C2,sprintf("%s/results/hrs_glm_baresink_v2.csv",outputDir),row.names=FALSE)

C2[,setdiff(colnames(C20),colnames(C2))]=""
C2 = C2[,colnames(C20)]
C3 = rbind(C2,C20)[rep(1:nrow(C2),each=2)+rep(c(0,nrow(C2)),times=nrow(C2)),]
for (j in 1:length(fpVar)) colnames(C3) = gsub(fpVar[j],names(fpVar)[j],colnames(C3),fixed=T)
write.csv(C3,sprintf("%s/results/hrs_glm_sink_combined.csv",outputDir),row.names=FALSE)
```



################
# Predicting future Nfp
################


```{r}
gLoad=F
warning("temp - need to compute these")
```

#train a bunch of models

### FI as sole predictor

Models: 1: RF, 2: gam, 3: polr
```{r}
file = sprintf("%s/data/train_nfp_fi_hrs.rds",outputDir)
load=gLoad
save=gSave
Nreps = 10
Nfolds = 10
rfGrid = expand.grid(mtry=1)
if(file.exists(file) & load)
{
  print("file found, loading...")
  accFI = readRDS(file)
} else
{
  print("file not found, computing...")
  mat = list()
  matSE = list()
  pred = list() #expected class
  predSE = list()
  predCl = list() #predicted class
  newdata = data.frame(fi=seq(0,1,length=101))
  for (i in 1:length(data))
  {
    pred[[i]] = newdata
    predCl[[i]] = newdata
    predSE[[i]] = newdata*0
    #thisData = data[[i]][sample(1:nrow(data[[i]]),100),] #for debugging, take small sample
    thisData = data[[i]]
    thisData[,"Nfp_next_ord"] = ordered(thisData[,"Nfp_next_ord"]) #drop any empty factors
    
    weights = rep(1,nrow(thisData))
    for (j in 0:5) weights[thisData[,"Nfp_next"]==j] = 1/mean(thisData[,"Nfp_next"]==j,na.rm=T)

    fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = Nfolds,
                           repeats = Nreps,
                           summaryFunction = SummaryNfp
                           )
    l = list()
    l$rf =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                 tuneGrid = rfGrid)
    l$rf$results[,"model"] = 1
    l$rf$results[,"weighted"] = F
    l$rf$pred = ExpectationPr(predict(l$rf,newdata=newdata,type="prob"))
  
    #l$mars =  train(Nfp_next ~ fi, data = thisData, 
    #             method = c("earth"), 
    #             trControl = fitControl
    #             )
    #l$mars$results[,"model"] = 2
    #l$mars$results[,"weighted"] = F
    #pr = predict(l$mars,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    #cl = pr
    #cl[cl < 0] = 0
    #cl[cl > 5] = 5
    #l$mars$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    #rm(pr)
  
    l$gam =  train(Nfp_next ~ fi, data = thisData, 
                 method = c("gam"), 
                 trControl = fitControl
                 )
    l$gam$results[,"model"] = 2
    l$gam$results[,"weighted"] = F
    pr = predict(l$gam,newdata=newdata)[,1] 
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$gam$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
      

    l$polr =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("polr"), 
                 trControl = fitControl)
    l$polr$results[,"model"] = 3
    l$polr$results[,"weighted"] = F
    l$polr$pred = ExpectationPr(predict(l$polr,newdata=newdata,type="prob"))
  
    l$rfW =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6),
                tuneGrid = rfGrid)
    l$rfW$results[,"model"] = 1
    l$rfW$results[,"weighted"] = T
    l$rfW$pred = ExpectationPr(predict(l$rfW,newdata=newdata,type="prob")) 
      
    l$marsW =  train(Nfp_next ~ fi, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
    l$marsW$results[,"model"] = 2
    l$marsW$results[,"weighted"] = T
    pr = predict(l$marsW,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$marsW$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
  
    l$polrW =  train(Nfp_next_ord ~ fi, data = thisData, 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
    l$polrW$results[,"model"] = 3
    l$polrW$results[,"weighted"] = T
    l$polrW$pred = ExpectationPr(predict(l$polrW,newdata=newdata,type="prob"))
     
    #label best-performing hyperparameters
      #makes plotting easier
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
      results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
      results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
      l[[j]]$results = results
    }
  
    uncols = character()
    for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
    uncols = unique(uncols)
    #fill in empty columns (tune paramters)
    lres = list()
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,setdiff(uncols,colnames(results))] = NA
      rest = setdiff(colnames(results),c("model","weighted"))
      lres[[j]] = results[,c("model","weighted",rest)]
      lres[[j]][,"method"] = as.numeric(factor(lres[[j]][,"method"]))
      rm(rest)
      
      #add predictions
      pred[[i]][,names(l)[j]] = l[[j]]$pred[,c("Epr")]
      predCl[[i]][,names(l)[j]] = l[[j]]$pred[,c("class")]
      predSE[[i]][,names(l)[j]] = l[[j]]$pred[,c("sd")]
    }
  
    mat[[i]] = do.call(rbind,lres)
    seCols = colnames(mat[[i]])[grep("SD",colnames(mat[[i]]))]
    metCols = seCols
    for (jj in 1:length(metCols)) metCols[jj] = strsplit(metCols[jj],"SD",fixed=T)[[1]][1]
    sharedCols = setdiff(colnames(mat[[i]]),c(seCols,metCols))
    matSE[[i]] = mat[[i]][,c(sharedCols,seCols)]
    matSE[[i]] = as.matrix(matSE[[i]])
    mat[[i]] = mat[[i]][,c(sharedCols,metCols)] 
    mat[[i]] = as.matrix(mat[[i]])
    colnames(matSE[[i]]) = colnames(mat[[i]])

    pred[[i]] = as.matrix(pred[[i]])
    predCl[[i]] = as.matrix(predCl[[i]])
    predSE[[i]] = as.matrix(predSE[[i]])
    colnames(predSE[[i]]) = colnames(pred[[i]])
    rm(l)
  }
  
  acc = RubinMat(mat,lse=matSE)
  for (i in 1:length(acc))
  {
    acc[[i]] = data.frame(acc[[i]])
    acc[[i]][,"metrics"] = "fi"
    acc[[i]][,"outcome"] = "Nfp"
  }
  pred = RubinMat(pred,lse=predSE)
  for (i in 1:length(pred)) pred[[i]] = data.frame(pred[[i]])
  predCl = RubinMat(predCl)  
  for (i in 1:length(predCl)) predCl[[i]] = data.frame(predCl[[i]])
  
  if(save)
  {
    saveRDS(list(acc=acc,pred=pred,predCl=predCl,results=results),file)
  }
  
  
}
```

```{r}
plotdata = subset(accFI,best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
file = sprintf("%s/data/train_nfp_nfp_hrs.rds",outputDir)
load=gLoad
save=gSave
Nreps = 10
Nfolds = 10
rfGrid = expand.grid(mtry=1)
if(file.exists(file) & load)
{
  print("file found, loading...")
  accFI = readRDS(file)
} else
{
  print("file not found, computing...")
  mat = list()
  matSE = list()
  pred = list() #expected class
  predSE = list()
  predCl = list() #predicted class
  newdata = data.frame(Nfp=seq(0,5,length=101))
  for (i in 1) #:length(data))
  {
    pred[[i]] = newdata
    predCl[[i]] = newdata
    predSE[[i]] = newdata*0
    #thisData = data[[i]][sample(1:nrow(data[[i]]),100),] #for debugging, take small sample
    thisData = data[[i]]
    thisData[,"Nfp_next_ord"] = ordered(thisData[,"Nfp_next_ord"]) #drop any empty factors
    thisData[,"Nfp_ord"] = ordered(thisData[,"Nfp_ord"]) #drop any empty factors
    
    #encode with onehot for polr
    ordData = as.data.frame(OneHotVecOrdinal(thisData[,"Nfp_ord"]))
    ordData[,"Nfp_next_ord"] = data[,"Nfp_next_ord"]
    
    weights = rep(1,nrow(thisData))
    for (j in 0:5) weights[thisData[,"Nfp_next"]==j] = 1/mean(thisData[,"Nfp_next"]==j,na.rm=T)

    fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = Nfolds,
                           repeats = Nreps,
                           summaryFunction = SummaryNfp
                           )
    l = list()
    l$rf =  train(Nfp_next_ord ~ Nfp_ord, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                 tuneGrid = rfGrid)
    l$rf$results[,"model"] = 1
    l$rf$results[,"weighted"] = F
    l$rf$pred = ExpectationPr(predict(l$rf,newdata=newdata,type="prob"))
  
    l$mars =  train(Nfp_next ~ Nfp, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl
                 )
    l$mars$results[,"model"] = 2
    l$mars$results[,"weighted"] = F
    pr = predict(l$mars,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$mars$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
    l$polr =  train(Nfp_next_ord ~ ., data = ordData,
                 method = c("polr"), 
                 trControl = fitControl)
    l$polr$results[,"model"] = 3
    l$polr$results[,"weighted"] = F
    l$polr$pred = ExpectationPr(predict(l$polr,newdata=newdata,type="prob"))
  
    l$rfW =  train(Nfp_next_ord ~ Nfp_ord, data = thisData, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6),
                tuneGrid = rfGrid)
    l$rfW$results[,"model"] = 1
    l$rfW$results[,"weighted"] = T
    l$rfW$pred = ExpectationPr(predict(l$rfW,newdata=newdata,type="prob")) 
      
    l$marsW =  train(Nfp_next ~ Nfp, data = thisData, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
    l$marsW$results[,"model"] = 2
    l$marsW$results[,"weighted"] = T
    pr = predict(l$marsW,newdata=newdata)[,1]  #doesn't seem to work to get SE #http://www.milbo.org/doc/earth-varmod.pdf
    cl = pr
    cl[cl < 0] = 0
    cl[cl > 5] = 5
    l$marsW$pred = data.frame(newdata=newdata,data.frame(class=cl,Epr=pr,sd=NA))
    rm(pr)
  
  
    l$polrW =  train(Nfp_next_ord ~ ., data = ordData,
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
    l$polrW$results[,"model"] = 3
    l$polrW$results[,"weighted"] = T
    l$polrW$pred = ExpectationPr(predict(l$polrW,newdata=newdata,type="prob"))
     
    #label best-performing hyperparameters
      #makes plotting easier
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
      results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
      results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
      l[[j]]$results = results
    }
  
    uncols = character()
    for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
    uncols = unique(uncols)
    #fill in empty columns (tune paramters)
    lres = list()
    for (j in 1:length(l))
    {
      results = l[[j]]$results
      results[,setdiff(uncols,colnames(results))] = NA
      rest = setdiff(colnames(results),c("model","weighted"))
      lres[[j]] = results[,c("model","weighted",rest)]
      lres[[j]][,"method"] = as.numeric(factor(lres[[j]][,"method"]))
      rm(rest)
      
      #add predictions
      pred[[i]][,names(l)[j]] = l[[j]]$pred[,c("Epr")]
      predCl[[i]][,names(l)[j]] = l[[j]]$pred[,c("class")]
      predSE[[i]][,names(l)[j]] = l[[j]]$pred[,c("sd")]
    }
  
    mat[[i]] = do.call(rbind,lres)
    seCols = colnames(mat[[i]])[grep("SD",colnames(mat[[i]]))]
    metCols = seCols
    for (jj in 1:length(metCols)) metCols[jj] = strsplit(metCols[jj],"SD",fixed=T)[[1]][1]
    sharedCols = setdiff(colnames(mat[[i]]),c(seCols,metCols))
    matSE[[i]] = mat[[i]][,c(sharedCols,seCols)]
    matSE[[i]] = as.matrix(matSE[[i]])
    mat[[i]] = mat[[i]][,c(sharedCols,metCols)] 
    mat[[i]] = as.matrix(mat[[i]])
    colnames(matSE[[i]]) = colnames(mat[[i]])

    pred[[i]] = as.matrix(pred[[i]])
    predCl[[i]] = as.matrix(predCl[[i]])
    predSE[[i]] = as.matrix(predSE[[i]])
    colnames(predSE[[i]]) = colnames(pred[[i]])
    rm(l)
  }
  
  acc = RubinMat(mat,lse=matSE)
  for (i in 1:length(acc))
  {
    acc[[i]] = data.frame(acc[[i]])
    acc[[i]][,"metrics"] = "fi"
    acc[[i]][,"outcome"] = "Nfp"
  }
  pred = RubinMat(pred,lse=predSE)
  for (i in 1:length(pred)) pred[[i]] = data.frame(pred[[i]])
  predCl = RubinMat(predCl)  
  for (i in 1:length(predCl)) predCl[[i]] = data.frame(predCl[[i]])
  
  if(save)
  {
    saveRDS(list(acc=acc,pred=pred,predCl=predCl,results=results),file)
  }
  
  
}
```

### Nfp as sole predictor

```{r}
file = sprintf("%s/data/train_nfp_nfp.rds",outputDir)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  lFP = readRDS(file)
  accFP = lFP$acc
} else
{
  print("file not found, computing...")
  
  weights = rep(1,nrow(data))
  for (j in 0:5) weights[data[,"Nfp_next"]==j] = 1/mean(data[,"Nfp_next"]==j,na.rm=T)

  #encode with onehot for polr
  ordData = as.data.frame(OneHotVecOrdinal(data[,"Nfp_ord"]))
  ordData[,"Nfp_next_ord"] = data[,"Nfp_next_ord"]
  
  fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           summaryFunction = SummaryNfp
                           )
  l = list()
  l$rf =  train(Nfp_next_ord ~ Nfp_ord, data = data, 
                 method = c("rf"), 
                 trControl = fitControl)
  l$rf$results[,"model"] = "rf"
  l$rf$results[,"weighted"] = F
  
  l$mars =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("earth"), 
                 trControl = fitControl
                 )
  l$mars$results[,"model"] = "mars"
  l$mars$results[,"weighted"] = F
  
  l$lo =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("gamLoess"), 
                 trControl = fitControl)
  l$lo$results[,"model"] = "loess"
  l$lo$results[,"weighted"] = F
  
  l$polr =  train(Nfp_next_ord ~ ., data = ordData, 
                 method = c("polr"), 
                 trControl = fitControl)
  l$polr$results[,"model"] = "polr"
  l$polr$results[,"weighted"] = F
  
  l$rfW =  train(Nfp_next_ord ~ Nfp_ord, data = data, 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6))
  l$rfW$results[,"model"] = "rf"
  l$rfW$results[,"weighted"] = T

  l$marsW =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
  l$marsW$results[,"model"] = "mars"
  l$marsW$results[,"weighted"] = T
  
  l$loW =  train(Nfp_next ~ Nfp, data = data, 
                 method = c("gamLoess"), 
                 trControl = fitControl,
                 weights=weights)
  l$loW$results[,"model"] = "loess"
  l$loW$results[,"weighted"] = T
  
  l$polrW =  train(Nfp_next_ord ~ ., data = ordData, 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
  l$polrW$results[,"model"] = "polr"
  l$polrW$results[,"weighted"] = T

  
  #label best-performing hyperparameters
    #makes plotting easier
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
    results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
    results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
    l[[j]]$results = results
  }
  
  uncols = character()
  for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
  uncols = unique(uncols)
  #fill in empty columns (tune paramters)
  lres = list()
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,setdiff(uncols,colnames(results))] = NA
    rest = setdiff(colnames(results),c("model","metrics","weighted"))
    lres[[j]] = results
    rm(rest)
  }
  
  accFP = do.call(rbind,lres)
  
  accFP[,"metrics"] = "Nfp"
  accFP[,"outcome"] = "Nfp"
  
  #rearrange
  rest = setdiff(colnames(accFP),c("outcome","model","metrics","weighted"))
  accFP = accFP[,c("outcome","model","metrics","weighted",rest)]
  
  if(save)
  {
    saveRDS(list(acc=accFP,l=l),file)
  }
}
```

```{r}
plotdata = subset(accFP,best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
plotdata = subset(rbind(accFI[,cols],accFP[,cols]),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```


### Using all of the binary FP vars aspredictors

```{r}
file = sprintf("%s/data/train_nfp_fpvar.rds",outputDir)
load=gLoad
save=gSave
if(file.exists(file) & load)
{
  print("file found, loading...")
  lFPVar = readRDS(file)
  accFPVar = lFPVar$acc
} else
{
  print("file not found, computing...")
  
  weights = rep(1,nrow(data))
  for (j in 0:5) weights[data[,"Nfp_next"]==j] = 1/mean(data[,"Nfp_next"]==j,na.rm=T)

  fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           summaryFunction = SummaryNfp
                           )
  l = list()
  l$rf =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("rf"), 
                 trControl = fitControl)
  l$rf$results[,"model"] = "rf"
  l$rf$results[,"weighted"] = F
  
  l$mars =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("earth"), 
                 trControl = fitControl
                 )
  l$mars$results[,"model"] = "mars"
  l$mars$results[,"weighted"] = F
  
  l$lo =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("gamLoess"), 
                 trControl = fitControl)
  l$lo$results[,"model"] = "loess"
  l$lo$results[,"weighted"] = F
  
  l$polr =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("polr"), 
                 trControl = fitControl)
  l$polr$results[,"model"] = "polr"
  l$polr$results[,"weighted"] = F
  
  l$rfW =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("rf"), 
                 trControl = fitControl,
                classwt=rep(1,6))
  l$rfW$results[,"model"] = "rf"
  l$rfW$results[,"weighted"] = T

  l$marsW =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("earth"), 
                 trControl = fitControl,
                 weights=weights
                 )
  l$marsW$results[,"model"] = "mars"
  l$marsW$results[,"weighted"] = T
  
  l$loW =  train(Nfp_next ~ ., data = data[,c("Nfp_next",fpVar)], 
                 method = c("gamLoess"), 
                 trControl = fitControl,
                 weights=weights)
  l$loW$results[,"model"] = "loess"
  l$loW$results[,"weighted"] = T
  
  l$polrW =  train(Nfp_next_ord ~ ., data = data[,c("Nfp_next_ord",fpVar)], 
                 method = c("polr"), 
                 trControl = fitControl,
                 weights=weights)
  l$polrW$results[,"model"] = "polr"
  l$polrW$results[,"weighted"] = T

  
  #label best-performing hyperparameters
    #makes plotting easier
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,"best_rmse"] = rank(results[,"RMSE"],ties="first") == 1
    results[,"best_youden"] = rank(-results[,"Mean_Youden"],ties="first") == 1
    results[,"best_accuracy"] = rank(-results[,"Accuracy"],ties="first") == 1
    l[[j]]$results = results
  }
  
  uncols = character()
  for (j in 1:length(l)) uncols = c(uncols,colnames(l[[j]]$results))
  uncols = unique(uncols)
  #fill in empty columns (tune paramters)
  lres = list()
  for (j in 1:length(l))
  {
    results = l[[j]]$results
    results[,setdiff(uncols,colnames(results))] = NA
    lres[[j]] = results
    rm(rest)
  }
  
  acc = do.call(rbind,lres)
  
  acc[,"metrics"] = "fpVar"
  acc[,"outcome"] = "Nfp"
  
  #rearrange
  rest = setdiff(colnames(acc),c("outcome","model","metrics","weighted"))
  accFPVar = acc[,c("outcome","model","metrics","weighted",rest)]
  
  if(save)
  {
    saveRDS(list(acc=accFPVar,l=l),file)
  }
}
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"Mean_Youden"],decreasing=F),"model"]))
g = ggplot(plotdata,aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_youden)
plotdata[,"model"] = factor(plotdata[,"model"],unique(accFPVar[sort.list(accFPVar[,"Mean_Youden"],decreasing=T),"model"]))
g = ggplot(subset(plotdata,weighted),aes(x=model,y=Mean_Youden,ymin=Mean_Youden-Mean_YoudenSD,ymax=Mean_Youden+Mean_YoudenSD,color=metrics,shape=metrics))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()+
  theme(legend.title=element_blank())
g
```

```{r}
cols = intersect(colnames(accFI),colnames(accFP))
cols = intersect(cols,colnames(accFPVar))
plotdata = subset(do.call(rbind,list(accFI[,cols],accFP[,cols],accFPVar[,cols])),best_rmse)
plotdata[,"model"] = factor(plotdata[,"model"],unique(plotdata[sort.list(plotdata[,"RMSE"],decreasing=F),"model"]))
g = ggplot(plotdata,aes(x=model,y=RMSE,ymin=RMSE-RMSESD,ymax=RMSE+RMSESD,color=metrics,shape=weighted))+
  geom_pointrange(position=position_dodge(.05))+
  theme_minimal()
g
```

# AUC - prediction - frailty

How well does FI predict frailty in the CURRENT wave? - AUC

```{r}
library(pROC)
fp = c(data[,"fp_frail"],data[,"fp_frail_next"])
fi = c(data[,"fi"],data[,"fi_next"])
r = roc(fp~fi,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the CURRENT wave? Should be perfect

```{r}
fp = c(data[,"fp_frail"],data[,"fp_frail_next"])
Nfp = c(data[,"Nfp"],data[,"Nfp_next"])
r = roc(fp~Nfp,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

# AUC - prognostication - frailty

How well does FI predict frailty in the next wave? - AUC

```{r}
library(pROC)
r = roc(data[,"fp_frail_next"]~data[,"fi"],ci.method="boot")
rfi = r
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the next wave?

```{r}
r = roc(data[,"fp_frail_next"]~data[,"Nfp"],ci.method="boot")
rfp = r
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```
```{r}
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
legend("topleft",c("FI","NFP"),col=1:2,lty=1:2)
```

# AUC - prediction - pre-frail or worse

How well does FI predict frailty in the CURRENT wave? - AUC

```{r}
library(pROC)
Nfp = c(data[,"Nfp"],data[,"Nfp"])
fi = c(data[,"fi"],data[,"fi_next"])
r = roc(I(Nfp>0)~fi,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

# AUC - prognostication - pre-frail or worse

How well does FI predict frailty in the next wave? - AUC

```{r}
library(pROC)
r = roc(I(Nfp_next > 0)~fi,data,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```

How well does number of FP deficits predict frailty in the next wave?

```{r}
r = roc(I(Nfp_next > 0)~Nfp,data,ci.method="boot")
a = ci.auc(r,method="bootstrap")
print(a)
#coords(r,x="best",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
cut = ci.coords(r,x="best",method="bootstrap",ret=c("threshold","specificity","sensitivity","accuracy","youden"))
print(cut)
```
# POLR
```{r}
library(MASS)
data[,"Nfp_next_ord"] = ordered(data[,"Nfp_next"],0:5)
m = polr(Nfp_next_ord~fi,data)
pr = predict(m,data)
C = xtabs(~data[,'Nfp_next']+pr)
print(sprintf("Accuracy: %.2f",sum(diag(C))/sum(C)))

pr = as.numeric(as.character(pr))
cor(data[,'Nfp_next'],pr,use='pairwise.complete')
ggplot(data.frame(Nfp=data[,'Nfp_next'],pr=pr),aes(x=Nfp,y=pr))+geom_jitter(width=.1,height=.1)
```

```{r}
data[,"Nfp_next_ord"] = ordered(data[,"Nfp_next"],0:5)
m = polr(Nfp_next_ord~.,data[,c("Nfp_next_ord",fpVar)])
pr = predict(m,data)
C = xtabs(~data[,'Nfp_next']+pr)
print(sprintf("Accuracy: %.2f",sum(diag(C))/sum(C)))

pr = as.numeric(as.character(pr))
cor(data[,'Nfp_next'],pr,use='pairwise.complete')
ggplot(data.frame(Nfp=data[,'Nfp_next'],pr=pr),aes(x=Nfp,y=pr))+geom_jitter(width=.1,height=.1)
```

# GLM
```{r}
prevalenceRatio = mean(1-data[,"fp_frail_next"],na.rm=T)/mean(data[,"fp_frail_next"]) #odds ratio?
weights = rep(1,nrow(data))
weights[data[,"fp_frail_next"] > 0.01] = ratio
m = glm(fp_frail_next~fi,data,family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

```{r}
m = glm(fp_frail_next~.,data[,c("fp_frail_next",fpVar)],family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

```{r}
m = glm(fp_frail_next~Nfp,data,family="binomial",weights=weights)
C = xtabs(~data[,'fp_frail_next']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

# Damage and repair
```{r}
data[,"dfp"] = data[,"Nfp_next"] - data[,"Nfp"]
print(table(data[,"dfp"]))
data[,"damage"] = 1*(data[,"dfp"] > 0)
data[,"repair"] = 1*(data[,"dfp"] < 0)
data[,"dfp_trinary"] = data[,"dfp"]
data[data[,"dfp"] < 0,"dfp_trinary"] = -1
data[data[,"dfp"] > 0,"dfp_trinary"] = 1
```

Damage seems to be the most important thing to predict.

Nfp clearly better than FI. Although both are quite poor.
```{r}
rfi = roc(damage~fi,data)
rfi_next = roc(damage~fi_next,data)
#rfi_next = roc(damage~I(fi*length(fiVar)+Nfp),data) #~FI with FP variables included #doesn't help
rfp = roc(damage~Nfp,data)
print(auc(rfi))
print(auc(rfp))
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
lines(rfi_next,col=3,lty=3)
legend("topleft",c("FI","NFP","FI next"),col=1:3,lty=1:3)
```

```{r}
rfi = roc(repair~fi,data)
rfp = roc(repair~Nfp,data)
print(auc(rfi))
print(auc(rfp))
print(roc.test(rfi,rfp))
plot(rfi)
lines(rfp,col=2,lty=2)
legend("topleft",c("FI","NFP"),col=1:2,lty=1:2)
```

#GLM - Damage

```{r}
prevalenceRatio = mean(1-data[,"damage"],na.rm=T)/mean(data[,"damage"]) #odds ratio?
weights = rep(1,nrow(data))
weights[data[,"damage"] > 0.01] = ratio
m = glm(damage~fi,data,family="binomial",weights=weights)
C = xtabs(~data[,'damage']+I(predict(m,data)>=0))
print(C)
print(Assess(C))
```

# Random Forest - should use cross-validation for more precise estimate

How well does FI predict frailty in the next wave? - Random Forest

Problem seems to be that RF doesn't like continuous variables, wants to make too many cuts.

```{r}
library(randomForest)
classwt = c(1,1)
#classwt = 1/c(mean(data[,"fp_frail_next"],na.rm=T),mean(1-data[,"fp_frail_next"],na.rm=T)) #not right
rf = randomForest(factor(fp_frail_next,c(0,1))~fi,data,classwt=classwt)
#rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt) #does way better
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
classwt = c(1,1)
rf = randomForest(factor(fp_frail_next,c(0,1))~.,data[,c("fp_frail_next",fpVar)],classwt=classwt)
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
classwt = c(1,1)
rf = randomForest(factor(fp_frail_next,c(0,1))~Nfp,data,classwt=classwt)
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```

FI + FP
```{r}
classwt = c(1,1)
#classwt = 1/c(mean(data[,"fp_frail_next"],na.rm=T),mean(1-data[,"fp_frail_next"],na.rm=T)) #not right
rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt)
#rf = randomForest(factor(fp_frail_next,c(0,1))~fi+Nfp,data,classwt=classwt) #does way better
print(rf$confusion)
print(Assess(rf$confusion[,1:2]))
```

# Random Forest - multiple classes

How well does FI predict frailty in the next wave? - Random Forest
Looks like it has too much flexibility, wants to put multiple cuts instead of just one

```{r}
library(randomForest)
classwt = c(1,1,1)
print(table(data[,"fpclass_next"]))
rf = randomForest(fpclass_next~fi,data,classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2])) #assess is for only 2x2
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
rf = randomForest(fpclass_next~.,data[,c(fpVar,"fpclass_next")],classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2]))
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
rf = randomForest(fpclass_next~Nfp,data,classwt=classwt)
print(rf$confusion)
print(fisher.test(rf$confusion[,1:2]))
```
# Random Forest - regression for Nfp

How well does FI predict frailty in the next wave? - Random Forest
Looks like it has too much flexibility, wants to put multiple cuts instead of just one

```{r}
library(randomForest)
rf = randomForest(Nfp_next~fi,data)
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.01)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```
How well does the Fav-5 predict frailty in the next wave?

```{r}
rf = randomForest(Nfp_next~.,data[,c(fpVar,"Nfp_next")])
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.01)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```
How well does number of FP deficits predict frailty in the next wave?

```{r}
rf = randomForest(Nfp_next~Nfp,data)
pr = predict(rf,data)
ggplot(data.frame(gt=data[,"Nfp_next"],pr=pr),aes(x=gt,y=pr))+geom_jitter(width=.05,height=.05)+geom_smooth(method='lm',formula=y~x+I(x^2))
pr[pr < 0] = 0
pr[pr > 5] = 5
C = xtabs(~data[,"Nfp_next"]+round(pr))
print(C)
print(chisq.test(C)) 
```
